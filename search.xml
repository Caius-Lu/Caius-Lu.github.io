<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[knn手写数字识别]]></title>
    <url>%2F2019%2F10%2F20%2Fknn%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[K近邻算法算法的核心思想是，给定一个训练数据集，对于新的输入实例，在训练集中找到与该实例最近的K个实例，这K个实例的多数属于某个类，就把这个输入归为哪个类中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# 1 重要# 2 KNN CNN 2种# 3 样本 # 4 旧瓶装新酒 ：数字识别的不同# 4.1 网络 4。2 每一级 4.3 先原理 后代码 # 本质：knn test 样本 K个 max4 3个1 -》1# 1 load Data 1.1 随机数 1.2 4组 训练 测试 （图片 和 标签）# 2 knn test train distance 5*500 = 2500 784=28*28# 3 knn k个最近的图片5 500 1-》500train （4）# 4 k个最近的图片-&gt; parse centent label# 5 label -》 数字 p9 测试图片-》数据# 6 检测概率统计import tensorflow as tfimport numpy as npimport random from tensorflow.examples.tutorials.mnist import input_data# load data 2 one_hot : 1 0000 1 fileName mnist = input_data.read_data_sets('MNIST_data',one_hot=True)# 属性设置trainNum = 55000testNum = 10000trainSize = 500testSize = 5k = 4# data 分解 1 trainSize 2范围0-trainNum 3 replace=False trainIndex = np.random.choice(trainNum,trainSize,replace=False)testIndex = np.random.choice(testNum,testSize,replace=False)trainData = mnist.train.images[trainIndex]# 训练图片trainLabel = mnist.train.labels[trainIndex]# 训练标签testData = mnist.test.images[testIndex]testLabel = mnist.test.labels[testIndex]# 28*28 = 784print('trainData.shape=',trainData.shape)#500*784 1 图片个数 2 784?print('trainLabel.shape=',trainLabel.shape)#500*10print('testData.shape=',testData.shape)#5*784print('testLabel.shape=',testLabel.shape)#5*10print('testLabel=',testLabel)# 4 :testData [0] 3:testData[1] 6 # tf input 784-&gt;imagetrainDataInput = tf.placeholder(shape=[None,784],dtype=tf.float32)trainLabelInput = tf.placeholder(shape=[None,10],dtype=tf.float32)testDataInput = tf.placeholder(shape=[None,784],dtype=tf.float32)testLabelInput = tf.placeholder(shape=[None,10],dtype=tf.float32)#knn distance 5*785. 5*1*784# 5 500 784 (3D) 2500*784f1 = tf.expand_dims(testDataInput,1) # 维度扩展 (?, 1, 784) # 0其实代表的第一维度，那么1代表第二维度，2代表第三维度。以此类推。print()f2 = tf.subtract(trainDataInput,f1)# 784 sum(784) 返回 x-y 的元素.f3 = tf.reduce_sum(tf.abs(f2),reduction_indices=2)# 完成数据累加 784 abs # axis=0时，按第一个维度求和，# 5*500f4 = tf.negative(f3)# 取反 取负值print('f1.shape=',f1.shape)#500*784 1 图片个数 2 784?print('f2.shape=',f2.shape)#500*10 (?, ?, 784)print('f3.shape=',f3.shape)#5*784 (?, ?)print('f4.shape=',f4.shape)#5*10 (?, ?)f5,f6 = tf.nn.top_k(f4,k=4) # 选取f4 最大的四个值 返回值和其索引位置# f3 最小的四个值# f6 index-&gt;trainLabelInputf7 = tf.gather(trainLabelInput,f6) # 根据索引抽取其中的张量# f8 num reduce_sum reduction_indices=1 '竖直'f8 = tf.reduce_sum(f7,reduction_indices=1)# tf.argmax 选取在某一个最大的值 indexf9 = tf.argmax(f8,dimension=1)# f9 -&gt; test5 image -&gt; 5 numwith tf.Session() as sess: # f1 &lt;- testData 5张图片 p1 = sess.run(f1,feed_dict=&#123;testDataInput:testData[0:5]&#125;) print('p1=',p1.shape)# p1= (5, 1, 784) p2 = sess.run(f2,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5]&#125;) print('p2=',p2.shape)#p2= (5, 500, 784) (1,100) p3 = sess.run(f3,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5]&#125;) print('p3=',p3.shape)#p3= (5, 500) print('p3[0,0]=',p3[0,0]) #130.451 knn distance p3[0,0]= 155.812 p4 = sess.run(f4,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5]&#125;) print('p4=',p4.shape) print('p4[0,0]',p4[0,0]) p5,p6 = sess.run((f5,f6),feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5]&#125;) #p5= (5, 4) 每一张测试图片（5张）分别对应4张最近训练图片 #p6= (5, 4) print('p5=',p5.shape) print('p6=',p6.shape) print('p5[0,0]',p5[0]) print('p6[0,0]',p6[0])# p6 index p7 = sess.run(f7,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel&#125;) print('p7=',p7.shape)#p7= (5, 4, 10) print('p7[]',p7) p8 = sess.run(f8,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel&#125;) print('p8=',p8.shape) print('p8[]=',p8) p9 = sess.run(f9,feed_dict=&#123;trainDataInput:trainData,testDataInput:testData[0:5],trainLabelInput:trainLabel&#125;) print('p9=',p9.shape) print('p9[]=',p9) p10 = np.argmax(testLabel[0:5],axis=1) print('p10[]=',p10)j = 0for i in range(0,5): if p10[i] == p9[i]: j = j+1print('ac=',j*100/5) 参考链接：OpenCV+TensorFlow 入门人工智能图像处理 手写数字识别]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow自定义网络模型]]></title>
    <url>%2F2019%2F10%2F17%2Ftensorflow%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[SlimTF-Slim 模块是 TensorFlow 中最好用的 API 之一。尤其是里面引入的 arg_scope、model_variables、repeat、stack。TF-Slim 是 TensorFlow 中一个用来构建、训练、评估复杂模型的轻量化库。TF-Slim 模块可以和 TensorFlow 中其它API混合使用。 Slim模块的导入1import tensorflow.contrib.slim as slim Slim 构建模型可以用 slim、variables、layers 和 scopes 来十分简洁地定义模型。下面对各个部分进行了详细描述： Slim变量（Variables）123456weights = slim.variable('weights', shape=[10, 10, 3 , 3], initializer=tf.truncated_normal_initializer(stddev=0.1), regularizer=slim.l2_regularizer(0.05), device='/CPU:0')~ Slim 层（Layers）使用基础（plain）的 TensorFlow 代码：123456789input = ...with tf.name_scope('conv1_1') as scope: kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32, stddev=1e-1), name='weights') conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], padding='SAME') biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32), trainable=True, name='biases') bias = tf.nn.bias_add(conv, biases) conv1 = tf.nn.relu(bias, name=scope) 为了避免代码的重复。Slim 提供了很多方便的神经网络 layers 的高层 op。例如：与上面的代码对应的 Slim 版的代码：12input = ...net = slim.conv2d(input, 128, [3, 3], scope='conv1_1') slim.arg_scope（） 函数的使用这个函数的作用是给list_ops中的内容设置默认值。但是每个list_ops中的每个成员需要用@add_arg_scope修饰才行。所以使用slim.arg_scope（）有两个步骤： 使用@slim.add_arg_scope修饰目标函数 用 slim.arg_scope（）为目标函数设置默认参数.例如如下代码；首先用@slim.add_arg_scope修饰目标函数fun1（），然后利用slim.arg_scope（）为它设置默认参数。12345678910import tensorflow as tfslim =tf.contrib.slim @slim.add_arg_scopedef fun1(a=0,b=0): return (a+b) with slim.arg_scope([fun1],a=10): x=fun1(b=30) print(x) 运行结果:40参考链接：https://blog.csdn.net/u013921430/article/details/80915696 其他用法见参考链接https://blog.csdn.net/wanttifa/article/details/90208398 查看ckpt中变量的几种方法查看ckpt中变量的方法有三种： 在有model的情况下，使用tf.train.Saver进行restore 使用tf.train.NewCheckpointReader直接读取ckpt文件，这种方法不需要model。 使用tools里的freeze_graph来读取ckptTips: 如果模型保存为.ckpt的文件，则使用该文件就可以查看.ckpt文件里的变量。ckpt路径为 model.ckpt 如果模型保存为.ckpt-xxx-data (图结构)、.ckpt-xxx.index (参数名)、.ckpt-xxx-meta (参数值)文件，则需要同时拥有这三个文件才行。并且ckpt的路径为 model.ckpt-xxx1.基于model来读取ckpt文件里的变量1.首先建立起model2.从ckpt中恢复变量12345678910with tf.Graph().as_default() as g: #建立model images, labels = cifar10.inputs(eval_data=eval_data) logits = cifar10.inference(images) top_k_op = tf.nn.in_top_k(logits, labels, 1) #从ckpt中恢复变量 sess = tf.Session() saver = tf.train.Saver() #saver = tf.train.Saver(...variables...) # 恢复部分变量时，只需要在Saver里指定要恢复的变量 save_path = 'ckpt的路径' saver.restore(sess, save_path) # 从ckpt中恢复变量 注意：基于model来读取ckpt中变量时，model和ckpt必须匹配。 2.使用tf.train.NewCheckpointReader直接读取ckpt文件里的变量，使用tools.inspect_checkpoint里的print_tensors_in_checkpoint_file函数打印ckpt里的东西12345678910111213141516#使用NewCheckpointReader来读取ckpt里的变量from tensorflow.python import pywrap_tensorflowcheckpoint_path = os.path.join(model_dir, "model.ckpt")reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path) #tf.train.NewCheckpointReadervar_to_shape_map = reader.get_variable_to_shape_map()for key in var_to_shape_map: print("tensor_name: ", key) #print(reader.get_tensor(key))#使用print_tensors_in_checkpoint_file打印ckpt里的内容from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_fileprint_tensors_in_checkpoint_file(file_name, #ckpt文件名字 tensor_name, # 如果为None,则默认为ckpt里的所有变量 all_tensors, # bool 是否打印所有的tensor，这里打印出的是tensor的值，一般不推荐这里设置为False all_tensor_names) # bool 是否打印所有的tensor的name#上面的打印ckpt的内部使用的是pywrap_tensorflow.NewCheckpointReader所以要掌握NewCheckpointReader 3.使用tools里的freeze_graph来读取ckpt12345678910111213141516171819from tensorflow.python.tools import freeze_graphfreeze_graph(input_graph, #=some_graph_def.pb input_saver, input_binary, input_checkpoint, #=model.ckpt output_node_names, #=softmax restore_op_name, filename_tensor_name, output_graph, #='./tmp/frozen_graph.pb' clear_devices, initializer_nodes, variable_names_whitelist='', variable_names_blacklist='', input_meta_graph=None, input_saved_model_dir=None, saved_model_tags='serve', checkpoint_version=2)#freeze_graph_test.py讲述了怎么使用freeze_grapg。 参考链接：https://www.jb51.net/article/142183.htm control_dependenciestf.control_dependencies(control_inputs)Wrapper for Graph.control_dependencies() using the default graph.See Graph.control_dependencies() for more details.此函数指定某些操作执行的依赖关系返回一个控制依赖的上下文管理器，使用 with 关键字可以让在这个上下文环境中的操作都在 control_inputs 执行1231 with tf.control_dependencies([a, b]):2 c = ....3 d = ... 在执行完 a，b 操作之后，才能执行 c，d 操作。意思就是 c，d 操作依赖 a，b 操作121 with tf.control_dependencies([train_step, variable_averages_op]):2 train_op = tf.no_op(name='train') tf.no_op()表示执行完 train_step, variable_averages_op 操作之后什么都不做参考链接：http://www.tensorfly.cn/tfdoc/api_docs/python/framework.html#Graph.control_dependencies TensorBoard在TensorBoard中可视化图形构建您的网络，创建一个会话(session)，然后创建一个TensorFlow File Writer对象File Writer定义存储TensorBoard文件的路径，以及TensorFlow graph对象sess.graph是第二个参数。1writer = tf.summary.FileWriter(STORE_PATH, sess.graph) 当创建一个TensorFlow网络后，定义并运行File Writer时，就可以启动TensorBoard来可视化图形。要定义File Writer并将图形发送给它，运行以下命令:123# start the sessionwith tf.Session() as sess: writer = tf.summary.FileWriter(STORE_PATH, sess.graph) 启动TensorBoard1tensorboard --logdir=STORE_PATH 名称空间（Namespaces）名称空间是一种作用域，可以用它来包围图形组件，以便将它们组合在一起。通过这样的操作，名称空间中的细节将被折叠成TensorBoard计算图形可视化中的单个名称空间节点。要在TensorFlow中创建名称空间，可以使用Python with功能，如下所示：123456with tf.name_scope("layer_1"):# now declare the weights connecting the input to the hidden layer W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.01), name='W') b1 = tf.Variable(tf.random_normal([300]), name='b') hidden_logits = tf.add(tf.matmul(x_sc, W1), b1) hidden_out = tf.nn.sigmoid(hidden_logits) 还可以使用tf.variable_scope()代替tf.name_scope()。变量作用域是TensorFlow中的get_variable()变量共享机制的一部分。 标量总结（Scalar summaries）在网络中的任何位置，都可以记录标量(即单个实值)数量，以便在TensorBoard中显示。这对于跟踪诸如训练准确率的提高或损失函数的减少，或研究分布的标准差等方面都很有用。执行起来很容易。例如，下面的代码展示了如何在这个图中记录accuracy标量:12# add a summary to store the accuracytf.summary.scalar('acc_summary', accuracy) 第一个参数是要在TensorBoard可视化中给出标量的名称，第二个参数是要记录的操作(必须返回一个实值)。scalar()调用的输出是一个操作。在上面的代码中，我没有将这个操作分配给Python中的任何变量，但是如果用户愿意，可以这样做。然而，与TensorFlow中的其他操作一样，这些汇总操作在运行之前不会执行任何操作。根据开发人员想要观察的内容，在任何给定的图中通常都会运行许多可视化函数，因此有一个方便的助手函数merge_all()。这将把图中的所有函数调用合并在一起，这样您只需调用merge操作，它将为您收集所有其他函数操作并记录数据。它是这样的:1merged = tf.summary.merge_all() 图像可视化12345678910# add summaryif reuse_variables is None: tf.summary.image('input', images) tf.summary.image('score_map', score_maps) tf.summary.image('score_map_pred', f_score * 255) tf.summary.image('geo_map_0', geo_maps[:, :, :, 0:1]) tf.summary.image('geo_map_0_pred', f_geometry[:, :, :, 0:1]) tf.summary.image('training_masks', training_masks) tf.summary.scalar('model_loss', model_loss) tf.summary.scalar('total_loss', total_loss) 文本检测模型EAST的搭建数据加载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162def load_annoataion(p): ''' load annotation from the text file :param p: :return: ''' text_polys = [] text_tags = [] if not os.path.exists(p): return np.array(text_polys, dtype=np.float32) with open(p, 'r') as f: reader = csv.reader(f) for line in reader: label = line[-1] # strip BOM. \ufeff for python3, \xef\xbb\bf for python2 line = [i.strip('\ufeff').strip('\xef\xbb\xbf') for i in line] x1, y1, x2, y2, x3, y3, x4, y4 = list(map(float, line[:8])) text_polys.append([[x1, y1], [x2, y2], [x3, y3], [x4, y4]]) if label == '*' or label == '###': text_tags.append(True) else: text_tags.append(False) return np.array(text_polys, dtype=np.float32), np.array(text_tags, dtype=np.bool) def generator(input_size=512, batch_size=32, background_ratio=3./8, random_scale=np.array([0.5, 1, 2.0, 3.0]), vis=False): image_list = np.array(get_images()) print('&#123;&#125; training images in &#123;&#125;'.format( image_list.shape[0], FLAGS.training_data_path)) index = np.arange(0, image_list.shape[0]) while True: np.random.shuffle(index) images = [] image_fns = [] score_maps = [] geo_maps = [] training_masks = [] for i in index: try: im_fn = image_list[i] im = cv2.imread(im_fn) # print im_fn h, w, _ = im.shape txt_fn = im_fn.replace(os.path.basename(im_fn).split('.')[1], 'txt') if not os.path.exists(txt_fn): print('text file &#123;&#125; does not exists'.format(txt_fn)) continue text_polys, text_tags = load_annoataion(txt_fn) text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (h, w)) # if text_polys.shape[0] == 0: # continue # random scale this image rd_scale = np.random.choice(random_scale) im = cv2.resize(im, dsize=None, fx=rd_scale, fy=rd_scale) text_polys *= rd_scale # print rd_scale # random crop a area from image if np.random.rand() &lt; background_ratio: # crop background im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=True) if text_polys.shape[0] &gt; 0: # cannot find background continue # pad and resize image new_h, new_w, _ = im.shape max_h_w_i = np.max([new_h, new_w, input_size]) im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8) im_padded[:new_h, :new_w, :] = im.copy() im = cv2.resize(im_padded, dsize=(input_size, input_size)) score_map = np.zeros((input_size, input_size), dtype=np.uint8) geo_map_channels = 5 if FLAGS.geometry == 'RBOX' else 8 geo_map = np.zeros((input_size, input_size, geo_map_channels), dtype=np.float32) training_mask = np.ones((input_size, input_size), dtype=np.uint8) else: im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=False) if text_polys.shape[0] == 0: continue h, w, _ = im.shape # pad the image to the training input size or the longer side of image new_h, new_w, _ = im.shape max_h_w_i = np.max([new_h, new_w, input_size]) im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8) im_padded[:new_h, :new_w, :] = im.copy() im = im_padded # resize the image to input size new_h, new_w, _ = im.shape resize_h = input_size resize_w = input_size im = cv2.resize(im, dsize=(resize_w, resize_h)) resize_ratio_3_x = resize_w/float(new_w) resize_ratio_3_y = resize_h/float(new_h) text_polys[:, :, 0] *= resize_ratio_3_x text_polys[:, :, 1] *= resize_ratio_3_y new_h, new_w, _ = im.shape score_map, geo_map, training_mask = generate_rbox((new_h, new_w), text_polys, text_tags) if vis: fig, axs = plt.subplots(3, 2, figsize=(20, 30)) # axs[0].imshow(im[:, :, ::-1]) # axs[0].set_xticks([]) # axs[0].set_yticks([]) # for poly in text_polys: # poly_h = min(abs(poly[3, 1] - poly[0, 1]), abs(poly[2, 1] - poly[1, 1])) # poly_w = min(abs(poly[1, 0] - poly[0, 0]), abs(poly[2, 0] - poly[3, 0])) # axs[0].add_artist(Patches.Polygon( # poly * 4, facecolor='none', edgecolor='green', linewidth=2, linestyle='-', fill=True)) # axs[0].text(poly[0, 0] * 4, poly[0, 1] * 4, '&#123;:.0f&#125;-&#123;:.0f&#125;'.format(poly_h * 4, poly_w * 4), # color='purple') # axs[1].imshow(score_map) # axs[1].set_xticks([]) # axs[1].set_yticks([]) axs[0, 0].imshow(im[:, :, ::-1]) axs[0, 0].set_xticks([]) axs[0, 0].set_yticks([]) for poly in text_polys: poly_h = min(abs(poly[3, 1] - poly[0, 1]), abs(poly[2, 1] - poly[1, 1])) poly_w = min(abs(poly[1, 0] - poly[0, 0]), abs(poly[2, 0] - poly[3, 0])) axs[0, 0].add_artist(Patches.Polygon( poly, facecolor='none', edgecolor='green', linewidth=2, linestyle='-', fill=True)) axs[0, 0].text(poly[0, 0], poly[0, 1], '&#123;:.0f&#125;-&#123;:.0f&#125;'.format(poly_h, poly_w), color='purple') axs[0, 1].imshow(score_map[::, ::]) axs[0, 1].set_xticks([]) axs[0, 1].set_yticks([]) axs[1, 0].imshow(geo_map[::, ::, 0]) axs[1, 0].set_xticks([]) axs[1, 0].set_yticks([]) axs[1, 1].imshow(geo_map[::, ::, 1]) axs[1, 1].set_xticks([]) axs[1, 1].set_yticks([]) axs[2, 0].imshow(geo_map[::, ::, 2]) axs[2, 0].set_xticks([]) axs[2, 0].set_yticks([]) axs[2, 1].imshow(training_mask[::, ::]) axs[2, 1].set_xticks([]) axs[2, 1].set_yticks([]) plt.tight_layout() plt.show() plt.close() images.append(im[:, :, ::-1].astype(np.float32)) image_fns.append(im_fn) score_maps.append(score_map[::4, ::4, np.newaxis].astype(np.float32)) geo_maps.append(geo_map[::4, ::4, :].astype(np.float32)) training_masks.append(training_mask[::4, ::4, np.newaxis].astype(np.float32)) if len(images) == batch_size: yield images, image_fns, score_maps, geo_maps, training_masks images = [] image_fns = [] score_maps = [] geo_maps = [] training_masks = [] except Exception as e: import traceback traceback.print_exc() continue 网络模型的搭建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def model(images, weight_decay=1e-5, is_training=True): ''' define the model, we use slim's implemention of resnet ''' images = mean_image_subtraction(images) with slim.arg_scope(resnet_v1.resnet_arg_scope(weight_decay=weight_decay)): logits, end_points = resnet_v1.resnet_v1_50(images, is_training=is_training, scope='resnet_v1_50') with tf.variable_scope('feature_fusion', values=[end_points.values]): batch_norm_params = &#123; 'decay': 0.997, 'epsilon': 1e-5, 'scale': True, 'is_training': is_training &#125; with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_params, weights_regularizer=slim.l2_regularizer(weight_decay)): f = [end_points['pool5'], end_points['pool4'], end_points['pool3'], end_points['pool2']] for i in range(4): print('Shape of f_&#123;&#125; &#123;&#125;'.format(i, f[i].shape)) g = [None, None, None, None] h = [None, None, None, None] num_outputs = [None, 128, 64, 32] for i in range(4): if i == 0: h[i] = f[i] else: c1_1 = slim.conv2d(tf.concat([g[i-1], f[i]], axis=-1), num_outputs[i], 1) h[i] = slim.conv2d(c1_1, num_outputs[i], 3) if i &lt;= 2: g[i] = unpool(h[i]) else: g[i] = slim.conv2d(h[i], num_outputs[i], 3) print('Shape of h_&#123;&#125; &#123;&#125;, g_&#123;&#125; &#123;&#125;'.format(i, h[i].shape, i, g[i].shape)) # here we use a slightly different way for regression part, # we first use a sigmoid to limit the regression range, and also # this is do with the angle map F_score = slim.conv2d(g[3], 1, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) # 4 channel of axis aligned bbox and 1 channel rotation angle geo_map = slim.conv2d(g[3], 4, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) * FLAGS.text_scale angle_map = (slim.conv2d(g[3], 1, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) - 0.5) * np.pi/2 # angle is between [-45, 45] F_geometry = tf.concat([geo_map, angle_map], axis=-1) return F_score, F_geometry loss函数的设计12345678910111213141516171819202122232425262728293031323334def loss(y_true_cls, y_pred_cls, y_true_geo, y_pred_geo, training_mask): ''' define the loss used for training, contraning two part, the first part we use dice loss instead of weighted logloss, the second part is the iou loss defined in the paper :param y_true_cls: ground truth of text :param y_pred_cls: prediction os text :param y_true_geo: ground truth of geometry :param y_pred_geo: prediction of geometry :param training_mask: mask used in training, to ignore some text annotated by ### :return: ''' classification_loss = dice_coefficient(y_true_cls, y_pred_cls, training_mask) # scale classification loss to match the iou loss part classification_loss *= 0.01 # d1 -&gt; top, d2-&gt;right, d3-&gt;bottom, d4-&gt;left d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = tf.split(value=y_true_geo, num_or_size_splits=5, axis=3) d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = tf.split(value=y_pred_geo, num_or_size_splits=5, axis=3) area_gt = (d1_gt + d3_gt) * (d2_gt + d4_gt) area_pred = (d1_pred + d3_pred) * (d2_pred + d4_pred) w_union = tf.minimum(d2_gt, d2_pred) + tf.minimum(d4_gt, d4_pred) h_union = tf.minimum(d1_gt, d1_pred) + tf.minimum(d3_gt, d3_pred) area_intersect = w_union * h_union area_union = area_gt + area_pred - area_intersect L_AABB = -tf.log((area_intersect + 1.0)/(area_union + 1.0)) L_theta = 1 - tf.cos(theta_pred - theta_gt) tf.summary.scalar('geometry_AABB', tf.reduce_mean(L_AABB * y_true_cls * training_mask)) tf.summary.scalar('geometry_theta', tf.reduce_mean(L_theta * y_true_cls * training_mask)) L_g = L_AABB + 20 * L_theta return tf.reduce_mean(L_g * y_true_cls * training_mask) + classification_loss train123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112def main(argv=None): import os os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu_list config = None config.batch_size = FLAGS.batch_size_per_gpu * FLAGS.num_gpus if not tf.gfile.Exists(FLAGS.checkpoint_path): tf.gfile.MkDir(FLAGS.checkpoint_path) else: if not FLAGS.restore: tf.gfile.DeleteRecursively(FLAGS.checkpoint_path) tf.gfile.MkDir(FLAGS.checkpoint_path) input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_images') input_score_maps = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='input_score_maps') if FLAGS.geometry == 'RBOX': input_geo_maps = tf.placeholder(tf.float32, shape=[None, None, None, 5], name='input_geo_maps') else: input_geo_maps = tf.placeholder(tf.float32, shape=[None, None, None, 8], name='input_geo_maps') input_training_masks = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='input_training_masks') global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False) learning_rate = tf.train.exponential_decay(FLAGS.learning_rate, global_step, decay_steps=10000, decay_rate=0.94, staircase=True) # add summary tf.summary.scalar('learning_rate', learning_rate) opt = tf.train.AdamOptimizer(learning_rate) # opt = tf.train.MomentumOptimizer(learning_rate, 0.9) # split input_images_split = tf.split(input_images, len(gpus)) input_score_maps_split = tf.split(input_score_maps, len(gpus)) input_geo_maps_split = tf.split(input_geo_maps, len(gpus)) input_training_masks_split = tf.split(input_training_masks, len(gpus)) tower_grads = [] reuse_variables = None for i, gpu_id in enumerate(gpus): with tf.device('/gpu:%d' % gpu_id): with tf.name_scope('model_%d' % gpu_id) as scope: iis = input_images_split[i] isms = input_score_maps_split[i] igms = input_geo_maps_split[i] itms = input_training_masks_split[i] total_loss, model_loss = tower_loss(iis, isms, igms, itms, reuse_variables) batch_norm_updates_op = tf.group(*tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope)) reuse_variables = True grads = opt.compute_gradients(total_loss) tower_grads.append(grads) grads = average_gradients(tower_grads) apply_gradient_op = opt.apply_gradients(grads, global_step=global_step) summary_op = tf.summary.merge_all() # save moving average variable_averages = tf.train.ExponentialMovingAverage( FLAGS.moving_average_decay, global_step) variables_averages_op = variable_averages.apply(tf.trainable_variables()) # batch norm updates with tf.control_dependencies([variables_averages_op, apply_gradient_op, batch_norm_updates_op]): train_op = tf.no_op(name='train_op') saver = tf.train.Saver(tf.global_variables()) summary_writer = tf.summary.FileWriter(FLAGS.checkpoint_path, tf.get_default_graph()) init = tf.global_variables_initializer() if FLAGS.pretrained_model_path is not None: variable_restore_op = slim.assign_from_checkpoint_fn(FLAGS.pretrained_model_path, slim.get_trainable_variables(), ignore_missing_vars=True) with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess: if FLAGS.restore: print('continue training from previous checkpoint') ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_path) saver.restore(sess, ckpt) else: sess.run(init) if FLAGS.pretrained_model_path is not None: variable_restore_op(sess) # data_generator = icdar.get_batch(num_workers=FLAGS.num_readers, # input_size=FLAGS.input_size, # batch_size=FLAGS.batch_size_per_gpu * len(gpus)) train_data_generator = icdar_single.get_batch_seq(num_workers=FLAGS.num_readers, config=config, is_training=True) start = time.time() for step in range(FLAGS.max_steps): data = next(train_data_generator) ml, tl, _ = sess.run([model_loss, total_loss, train_op], feed_dict=&#123;input_images: data[0], input_score_maps: data[2], input_geo_maps: data[3], input_training_masks: data[4]&#125;) if np.isnan(tl): print('Loss diverged, stop training') break if step % 10 == 0: avg_time_per_step = (time.time() - start)/10 avg_examples_per_second = (10 * FLAGS.batch_size_per_gpu * len(gpus))/(time.time() - start) start = time.time() print('Step &#123;:06d&#125;, model loss &#123;:.4f&#125;, total loss &#123;:.4f&#125;, &#123;:.2f&#125; seconds/step, &#123;:.2f&#125; examples/second'.format( step, ml, tl, avg_time_per_step, avg_examples_per_second)) if step % FLAGS.save_checkpoint_steps == 0: saver.save(sess, FLAGS.checkpoint_path + 'model.ckpt', global_step=global_step) if step % FLAGS.save_summary_steps == 0: _, tl, summary_str = sess.run([train_op, total_loss, summary_op], feed_dict=&#123;input_images: data[0], input_score_maps: data[2], input_geo_maps: data[3], input_training_masks: data[4]&#125;) summary_writer.add_summary(summary_str, global_step=step) 参考链接：https://github.com/argman/EAST]]></content>
      <categories>
        <category>tensorflow</category>
        <category>python</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像增强常用函数]]></title>
    <url>%2F2019%2F10%2F14%2F%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[对目标检测一些常用的数据增强函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241# -*- coding: utf-8 -*-import cv2import numbersimport mathimport randomimport numpy as npfrom skimage.util import random_noise# 在原图上画出目标框def show_pic(img, bboxes=None, name=&apos;pic&apos;): &apos;&apos;&apos; 输入: img:图像array bboxes:图像的所有boudning box list, 格式为[[x_min, y_min, x_max, y_max]....] names:每个box对应的名称 &apos;&apos;&apos; show_img = img.copy() if not isinstance(bboxes, np.ndarray): bboxes = np.array(bboxes) for point in bboxes.astype(np.int): cv2.line(show_img, tuple(point[0]), tuple(point[1]), (255, 0, 0), 2) # tuple 是在原有数据上加小括号 cv2.line(show_img, tuple(point[1]), tuple(point[2]), (255, 0, 0), 2) cv2.line(show_img, tuple(point[2]), tuple(point[3]), (255, 0, 0), 2) cv2.line(show_img, tuple(point[3]), tuple(point[0]), (255, 0, 0), 2) # cv2.namedWindow(name, 0) # 1表示原图 # cv2.moveWindow(name, 0, 0) # cv2.resizeWindow(name, 1200, 800) # 可视化的图片大小 cv2.imshow(name, show_img)# 图像均为cv2读取class DataAugment(): def __init__(self): pass def add_noise(self, im: np.ndarray): &quot;&quot;&quot; 对图片加噪声 :param img: 图像array :return: 加噪声后的图像array,由于输出的像素是在[0,1]之间,所以得乘以255 &quot;&quot;&quot; return (random_noise(im, mode=&apos;gaussian&apos;, clip=True) * 255).astype(im.dtype) def random_scale(self, im: np.ndarray, text_polys: np.ndarray, scales: np.ndarray or list) -&gt; tuple: &quot;&quot;&quot; 从scales中随机选择一个尺度，对图片和文本框进行缩放 :param im: 原图 :param text_polys: 文本框 :param scales: 尺度 :return: 经过缩放的图片和文本 &quot;&quot;&quot; tmp_text_polys = text_polys.copy() rd_scale = float(np.random.choice(scales)) im = cv2.resize(im, dsize=None, fx=rd_scale, fy=rd_scale) tmp_text_polys *= rd_scale return im, tmp_text_polys def random_rotate_img_bbox(self, img, text_polys, degrees: numbers.Number or list or tuple or np.ndarray, same_size=False): &quot;&quot;&quot; 从给定的角度中选择一个角度，对图片和文本框进行旋转 :param img: 图片 :param text_polys: 文本框 :param degrees: 角度，可以是一个数值或者list :param same_size: 是否保持和原图一样大 :return: 旋转后的图片和角度 &quot;&quot;&quot; if isinstance(degrees, numbers.Number): if degrees &lt; 0: raise ValueError(&quot;If degrees is a single number, it must be positive.&quot;) degrees = (-degrees, degrees) elif isinstance(degrees, list) or isinstance(degrees, tuple) or isinstance(degrees, np.ndarray): if len(degrees) != 2: raise ValueError(&quot;If degrees is a sequence, it must be of len 2.&quot;) degrees = degrees else: raise Exception(&apos;degrees must in Number or list or tuple or np.ndarray&apos;) # ---------------------- 旋转图像 ---------------------- w = img.shape[1] h = img.shape[0] angle = np.random.uniform(degrees[0], degrees[1]) if same_size: nw = w nh = h else: # 角度变弧度 rangle = np.deg2rad(angle) # 计算旋转之后图像的w, h nw = (abs(np.sin(rangle) * h) + abs(np.cos(rangle) * w)) nh = (abs(np.cos(rangle) * h) + abs(np.sin(rangle) * w)) # 构造仿射矩阵 rot_mat = cv2.getRotationMatrix2D((nw * 0.5, nh * 0.5), angle, 1) # 计算原图中心点到新图中心点的偏移量 rot_move = np.dot(rot_mat, np.array([(nw - w) * 0.5, (nh - h) * 0.5, 0])) # 更新仿射矩阵 rot_mat[0, 2] += rot_move[0] rot_mat[1, 2] += rot_move[1] # 仿射变换 rot_img = cv2.warpAffine(img, rot_mat, (int(math.ceil(nw)), int(math.ceil(nh))), flags=cv2.INTER_LANCZOS4) # ---------------------- 矫正bbox坐标 ---------------------- # rot_mat是最终的旋转矩阵 # 获取原始bbox的四个中点，然后将这四个点转换到旋转后的坐标系下 rot_text_polys = list() for bbox in text_polys: point1 = np.dot(rot_mat, np.array([bbox[0, 0], bbox[0, 1], 1])) point2 = np.dot(rot_mat, np.array([bbox[1, 0], bbox[1, 1], 1])) point3 = np.dot(rot_mat, np.array([bbox[2, 0], bbox[2, 1], 1])) point4 = np.dot(rot_mat, np.array([bbox[3, 0], bbox[3, 1], 1])) rot_text_polys.append([point1, point2, point3, point4]) return rot_img, np.array(rot_text_polys, dtype=np.float32) def random_crop(self, imgs, img_size): h, w = imgs[0].shape[0:2] th, tw = img_size if w == tw and h == th: return imgs # label中存在文本实例，并且按照概率进行裁剪 if np.max(imgs[1][:, :, -1]) &gt; 0 and random.random() &gt; 3.0 / 8.0: # 文本实例的top left点 tl = np.min(np.where(imgs[1][:, :, -1] &gt; 0), axis=1) - img_size tl[tl &lt; 0] = 0 # 文本实例的 bottom right 点 br = np.max(np.where(imgs[1][:, :, -1] &gt; 0), axis=1) - img_size br[br &lt; 0] = 0 # 保证选到右下角点是，有足够的距离进行crop br[0] = min(br[0], h - th) br[1] = min(br[1], w - tw) i = random.randint(tl[0], br[0]) j = random.randint(tl[1], br[1]) else: i = random.randint(0, h - th) j = random.randint(0, w - tw) # return i, j, th, tw for idx in range(len(imgs)): if len(imgs[idx].shape) == 3: imgs[idx] = imgs[idx][i:i + th, j:j + tw, :] else: imgs[idx] = imgs[idx][i:i + th, j:j + tw] return imgs def resize(self, im: np.ndarray, text_polys: np.ndarray, input_size: numbers.Number or list or tuple or np.ndarray, keep_ratio: bool = False) -&gt; tuple: &quot;&quot;&quot; 对图片和文本框进行resize :param im: 图片 :param text_polys: 文本框 :param input_size: resize尺寸,数字或者list的形式，如果为list形式，就是[w,h] :param keep_ratio: 是否保持长宽比 :return: resize后的图片和文本框 &quot;&quot;&quot; if isinstance(input_size, numbers.Number): if input_size &lt; 0: raise ValueError(&quot;If input_size is a single number, it must be positive.&quot;) input_size = (input_size, input_size) elif isinstance(input_size, list) or isinstance(input_size, tuple) or isinstance(input_size, np.ndarray): if len(input_size) != 2: raise ValueError(&quot;If input_size is a sequence, it must be of len 2.&quot;) input_size = (input_size[0], input_size[1]) else: raise Exception(&apos;input_size must in Number or list or tuple or np.ndarray&apos;) if keep_ratio: # 将图片短边pad到和长边一样 h, w, c = im.shape max_h = max(h, input_size[0]) max_w = max(w, input_size[1]) im_padded = np.zeros((max_h, max_w, c), dtype=np.uint8) im_padded[:h, :w] = im.copy() im = im_padded text_polys = text_polys.astype(np.float32) h, w, _ = im.shape im = cv2.resize(im, input_size) w_scale = input_size[0] / float(w) h_scale = input_size[1] / float(h) text_polys[:, :, 0] *= w_scale text_polys[:, :, 1] *= h_scale return im, text_polys def horizontal_flip(self, im: np.ndarray, text_polys: np.ndarray) -&gt; tuple: &quot;&quot;&quot; 对图片和文本框进行水平翻转 :param im: 图片 :param text_polys: 文本框 :return: 水平翻转之后的图片和文本框 &quot;&quot;&quot; flip_text_polys = text_polys.copy() flip_im = cv2.flip(im, 1) h, w, _ = flip_im.shape flip_text_polys[:, :, 0] = w - flip_text_polys[:, :, 0] return flip_im, flip_text_polys def vertical_flip(self, im: np.ndarray, text_polys: np.ndarray) -&gt; tuple: &quot;&quot;&quot; 对图片和文本框进行竖直翻转 :param im: 图片 :param text_polys: 文本框 :return: 竖直翻转之后的图片和文本框 &quot;&quot;&quot; flip_text_polys = text_polys.copy() flip_im = cv2.flip(im, 0) h, w, _ = flip_im.shape flip_text_polys[:, :, 1] = h - flip_text_polys[:, :, 1] return flip_im, flip_text_polys def test(self, im: np.ndarray, text_polys: np.ndarray): print(&apos;随机尺度缩放&apos;) t_im, t_text_polys = self.random_scale(im, text_polys, [0.5, 1, 2, 3]) print(t_im.shape, t_text_polys.dtype) show_pic(t_im, t_text_polys, &apos;random_scale&apos;) print(&apos;随机旋转&apos;) t_im, t_text_polys = self.random_rotate_img_bbox(im, text_polys, 10) print(t_im.shape, t_text_polys.dtype) show_pic(t_im, t_text_polys, &apos;random_rotate_img_bbox&apos;) print(&apos;随机裁剪&apos;) t_im, t_text_polys = self.random_crop_img_bboxes(im, text_polys) print(t_im.shape, t_text_polys.dtype) show_pic(t_im, t_text_polys, &apos;random_crop_img_bboxes&apos;) print(&apos;水平翻转&apos;) t_im, t_text_polys = self.horizontal_flip(im, text_polys) print(t_im.shape, t_text_polys.dtype) show_pic(t_im, t_text_polys, &apos;horizontal_flip&apos;) print(&apos;竖直翻转&apos;) t_im, t_text_polys = self.vertical_flip(im, text_polys) print(t_im.shape, t_text_polys.dtype) show_pic(t_im, t_text_polys, &apos;vertical_flip&apos;) show_pic(im, text_polys, &apos;vertical_flip_ori&apos;) print(&apos;加噪声&apos;) t_im = self.add_noise(im) print(t_im.shape) show_pic(t_im, text_polys, &apos;add_noise&apos;) show_pic(im, text_polys, &apos;add_noise_ori&apos;)]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ocr答题卡识别]]></title>
    <url>%2F2019%2F10%2F13%2Focr%E7%AD%94%E9%A2%98%E5%8D%A1%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829import cv2def sort_contours(cnts, method="left-to-right"): reverse = False i = 0 if method == "right-to-left" or method == "bottom-to-top": reverse = True if method == "top-to-bottom" or method == "bottom-to-top": i = 1 boundingBoxes = [cv2.boundingRect(c) for c in cnts] #用一个最小的矩形，把找到的形状包起来x,y,h,w (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes), key=lambda b: b[1][i], reverse=reverse)) return cnts, boundingBoxesdef resize(image, width=None, height=None, inter=cv2.INTER_AREA): dim = None (h, w) = image.shape[:2] if width is None and height is None: return image if width is None: r = height / float(h) dim = (int(w * r), height) else: r = width / float(w) dim = (width, int(h * r)) resized = cv2.resize(image, dim, interpolation=inter) return resized 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183# 导入工具包from imutils import contoursimport numpy as npimport argparseimport cv2import myutils_beifen# # 设置参数# ap = argparse.ArgumentParser()# ap.add_argument("-i", "--image", required=True,# help="path to input image")# ap.add_argument("-t", "--template", required=True,# help="path to template OCR-A image")# args = vars(ap.parse_args())# 指定信用卡类型FIRST_NUMBER = &#123; "3": "American Express", "4": "Visa", "5": "MasterCard", "6": "Discover Card"&#125;# 绘图展示def cv_show(name,img): cv2.imshow(name, img) cv2.waitKey(0) cv2.destroyAllWindows()# 读取一个模板图像# img = cv2.imread(args["template"])img = cv2.imread('images/ocr_a_reference.png')cv_show('img',img)# 灰度图ref = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)cv_show('ref',ref)# 二值图像ref = cv2.threshold(ref, 10, 255, cv2.THRESH_BINARY_INV)[1]cv_show('ref',ref)# 计算轮廓#cv2.findContours()函数接受的参数为二值图，即黑白的（不是灰度图）,cv2.RETR_EXTERNAL只检测外轮廓，cv2.CHAIN_APPROX_SIMPLE只保留终点坐标#返回的list中每个元素都是图像中的一个轮廓ref_, refCnts, hierarchy = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)cv2.drawContours(img,refCnts,-1,(0,0,255),3) # -1表示画所有的轮廓cv_show('img',img)print (np.array(refCnts).shape)refCnts = myutils.sort_contours(refCnts, method="left-to-right")[0] #排序，从左到右，从上到下digits = &#123;&#125;# 遍历每一个轮廓for (i, c) in enumerate(refCnts): # 计算外接矩形并且resize成合适大小 (x, y, w, h) = cv2.boundingRect(c) roi = ref[y:y + h, x:x + w] roi = cv2.resize(roi, (57, 88)) # 每一个数字对应每一个模板 digits[i] = roi# 初始化卷积核rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3)) sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))#读取输入图像，预处理# image = cv2.imread(args["image"])image = cv2.imread('images/credit_card_02.png')cv_show('image',image)image = myutils.resize(image, width=300)gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)cv_show('gray',gray)#礼帽操作，突出更明亮的区域tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel) cv_show('tophat',tophat) # gradX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0, #ksize=-1相当于用3*3的 ksize=-1)gradX = np.absolute(gradX)(minVal, maxVal) = (np.min(gradX), np.max(gradX))gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))gradX = gradX.astype("uint8")print (np.array(gradX).shape)cv_show('gradX',gradX)#通过闭操作（先膨胀，再腐蚀）将数字连在一起gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel) cv_show('gradX',gradX)#THRESH_OTSU会自动寻找合适的阈值，适合双峰，需把阈值参数设置为0thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1] cv_show('thresh',thresh)#再来一个闭操作thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel) #再来一个闭操作cv_show('thresh',thresh)# 计算轮廓thresh_, threshCnts, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)cnts = threshCntscur_img = image.copy()cv2.drawContours(cur_img,cnts,-1,(0,0,255),3) cv_show('img',cur_img)locs = []# 遍历轮廓for (i, c) in enumerate(cnts): # 计算矩形 (x, y, w, h) = cv2.boundingRect(c) ar = w / float(h) # 选择合适的区域，根据实际任务来，这里的基本都是四个数字一组 if ar &gt; 2.5 and ar &lt; 4.0: if (w &gt; 40 and w &lt; 55) and (h &gt; 10 and h &lt; 20): #符合的留下来 locs.append((x, y, w, h))# 将符合的轮廓从左到右排序locs = sorted(locs, key=lambda x:x[0])output = []# 遍历每一个轮廓中的数字for (i, (gX, gY, gW, gH)) in enumerate(locs): # initialize the list of group digits groupOutput = [] # 根据坐标提取每一个组 group = gray[gY - 5:gY + gH + 5, gX - 5:gX + gW + 5] cv_show('group',group) # 预处理 group = cv2.threshold(group, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1] cv_show('group',group) # 计算每一组的轮廓 group_,digitCnts,hierarchy = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) digitCnts = contours.sort_contours(digitCnts, method="left-to-right")[0] # 计算每一组中的每一个数值 for c in digitCnts: # 找到当前数值的轮廓，resize成合适的的大小 (x, y, w, h) = cv2.boundingRect(c) roi = group[y:y + h, x:x + w] roi = cv2.resize(roi, (57, 88)) # 模板匹配要求大小一致 cv_show('roi',roi) # 计算匹配得分 scores = [] # 在模板中计算每一个得分 for (digit, digitROI) in digits.items(): # 模板匹配 result = cv2.matchTemplate(roi, digitROI, cv2.TM_CCOEFF) (_, score, _, _) = cv2.minMaxLoc(result) scores.append(score) # 得到最合适的数字 groupOutput.append(str(np.argmax(scores))) # 画出来 cv2.rectangle(image, (gX - 5, gY - 5), (gX + gW + 5, gY + gH + 5), (0, 0, 255), 1) cv2.putText(image, "".join(groupOutput), (gX, gY - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2) # 得到结果 output.extend(groupOutput)# 打印结果print("Credit Card Type: &#123;&#125;".format(FIRST_NUMBER[output[0]]))print("Credit Card #: &#123;&#125;".format("".join(output)))cv2.imshow("Image", image)cv2.waitKey(0) 参考资料： 唐宇迪 OpenCV计算机视觉实战(Python版)]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ocr透视变换]]></title>
    <url>%2F2019%2F10%2F13%2Focr%E9%80%8F%E8%A7%86%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128# 导入工具包import numpy as npimport argparseimport cv2# 设置参数ap = argparse.ArgumentParser()ap.add_argument("-i", "--image", required = False, help = "Path to the image to be scanned",default='images/page.jpg') args = vars(ap.parse_args())def order_points(pts): # 一共4个坐标点 rect = np.zeros((4, 2), dtype = "float32") # 按顺序找到对应坐标0123分别是 左上，右上，右下，左下 # 计算左上，右下 s = pts.sum(axis = 1) rect[0] = pts[np.argmin(s)] rect[2] = pts[np.argmax(s)] # 计算右上和左下 diff = np.diff(pts, axis = 1) rect[1] = pts[np.argmin(diff)] rect[3] = pts[np.argmax(diff)] return rectdef four_point_transform(image, pts): # 获取输入坐标点 rect = order_points(pts) (tl, tr, br, bl) = rect # 计算输入的w和h值 widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2)) widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2)) maxWidth = max(int(widthA), int(widthB)) heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2)) heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2)) maxHeight = max(int(heightA), int(heightB)) # 变换后对应坐标位置 dst = np.array([ [0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype = "float32") # 计算变换矩阵 M = cv2.getPerspectiveTransform(rect, dst) warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight)) # 返回变换后结果 return warpeddef resize(image, width=None, height=None, inter=cv2.INTER_AREA): dim = None (h, w) = image.shape[:2] if width is None and height is None: return image if width is None: r = height / float(h) dim = (int(w * r), height) else: r = width / float(w) dim = (width, int(h * r)) resized = cv2.resize(image, dim, interpolation=inter) return resized# 读取输入image = cv2.imread(args["image"])#坐标也会相同变化ratio = image.shape[0] / 500.0orig = image.copy()image = resize(orig, height = 500)# 预处理gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)gray = cv2.GaussianBlur(gray, (5, 5), 0)edged = cv2.Canny(gray, 75, 200)# 展示预处理结果print("STEP 1: 边缘检测")cv2.imshow("Image", image)cv2.imshow("Edged", edged)cv2.waitKey(0)cv2.destroyAllWindows()# 轮廓检测cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]# 遍历轮廓for c in cnts: # 计算轮廓近似 peri = cv2.arcLength(c, True) # C表示输入的点集 # epsilon表示从原始轮廓到近似轮廓的最大距离，它是一个准确度参数 # True表示封闭的 approx = cv2.approxPolyDP(c, 0.02 * peri, True)# 越小越精准，长度的百分之多少作为精度 # 4个点的时候就拿出来 if len(approx) == 4: screenCnt = approx break# 展示结果print("STEP 2: 获取轮廓")cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)cv2.imshow("Outline", image)cv2.waitKey(0)cv2.destroyAllWindows()# 透视变换warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)# 二值处理warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)ref = cv2.threshold(warped, 100, 255, cv2.THRESH_BINARY)[1]cv2.imwrite('scan.jpg', ref)# 展示结果print("STEP 3: 变换")cv2.imshow("Original", resize(orig, height = 650))cv2.imshow("Scanned", resize(ref, height = 650))cv2.waitKey(0) 参考资料： 唐宇迪 OpenCV计算机视觉实战(Python版)]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[park停车场项目实战]]></title>
    <url>%2F2019%2F10%2F13%2Fpark%E5%81%9C%E8%BD%A6%E5%9C%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[park 类对象123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326# coding=utf-8import matplotlib.pyplot as pltimport cv2import os, globimport numpy as npclass Parking: # 显示图片 def show_images(self, images, cmap=None): cols = 2 rows = (len(images)+1)//cols plt.figure(figsize=(15,12)) for i, image in enumerate(images): plt.subplot(rows, cols, i+1) cmap = 'gray' if len(image.shape)==2 else cmap plt.imshow(image, cmap=cmap) plt.xticks([]) plt.yticks([]) plt.tight_layout(pad=0, h_pad=0, w_pad=0) plt.show() def cv_show(self, name, img): cv2.imshow(name,img) cv2.waitKey(0) cv2.destroyAllWindows() def select_rgb_white_yello(self, image): # 过滤掉背景 lower = np.uint8([120,120,120]) upper = np.uint8([255,255,255]) # lower_red和高于upper_red的部分分别变成0，lower_red～upper_red之间的值变成255,相当于过滤背景 white_mask = cv2.inRange(image,lower, upper) self.cv_show('white_mask', white_mask) masked = cv2.bitwise_and(image, image, mask = white_mask) self.cv_show('masked', masked) return masked def convert_gray_sacle(self,image): return cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # 检测边缘 def detect_edges(self, image, low_threshold=50, high_threshold=200): return cv2.Canny(image, low_threshold, high_threshold) def filter_region(self, image, vertices): """ 剔除不需要的地方 """ mask = np.zeros_like(image) if len(mask.shape) == 2: cv2.fillPoly(mask, vertices, 255) self.cv_show('mask', mask) return cv2.bitwise_and(image, mask) # 手动选择区域 def select_region(self,image): """ 手动选择区域 """ # first, define the polygon by vertices rows, cols = image.shape[:2] pt_1 = [cols*0.05, rows*0.90] pt_2 = [cols*0.05, rows*0.70] pt_3 = [cols*0.30, rows*0.55] pt_4 = [cols*0.6, rows*0.15] pt_5 = [cols*0.90, rows*0.15] pt_6 = [cols*0.90, rows*0.90] vertices = np.array([[pt_1, pt_2, pt_3, pt_4, pt_5, pt_6]], dtype=np.int32) point_img = image.copy() point_img = cv2.cvtColor(point_img, cv2.COLOR_GRAY2RGB) for point in vertices[0]: cv2.circle(point_img, (point[0],point[1]), 10, (0,0,255), 4) self.cv_show('point_img',point_img) return self.filter_region(image, vertices) def hough_line(self, image): # 输入的图像需要是边缘检测后的结果 # minLineLengh(线的最短长度，比这个短的都被忽略)和MaxLineCap（两条直线之间的最大间隔，小于此值，认为是一条直线） # rho距离精度,theta角度精度,threshod超过设定阈值才被检测出线段 return cv2.HoughLinesP(image, rho=0.1, theta=np.pi/10, threshold=15, minLineLength=9, maxLineGap=4) def draw_lines(self, image, lines, color=[255,0,0], thickness=2, make_copy=True): # 过滤霍夫变换检测得到直线 if make_copy: image = np.copy(image) cleaned = [] for line in lines: for x1, y1, x2, y2 in line: if abs(y2-y1) &lt;=1 and abs(x2-x1) &gt;=25 and abs(x2-x1) &lt;= 55: cleaned.append((x1,y1,x2,y2)) cv2.line(image, (x1, y1), (x2, y2), color, thickness) print('No lines detected: ', len(cleaned)) return image def identify_blocks(self, image, lines, make_copy=True): if make_copy: new_image = np.copy(image) # step 1: 过滤部分直线 cleaned = [] for line in lines: for x1,y1,x2,y2 in line: if abs(y2-y1) &lt;=1 and abs(x2-x1) &gt;=25 and abs(x2-x1) &lt;= 55: cleaned.append((x1,y1,x2,y2)) # step 2: 对直线按照x1进行排序 import operator list1 = sorted(cleaned, key=operator.itemgetter(0,1)) # &gt;&gt;&gt; b=operator.itemgetter(1,0) //定义函数b，获取对象的第1个域和第0个的值 # &gt;&gt;&gt; b(a) # (2, 1) # step 3: 找到多个列，相当于每列是一排车 clusters = &#123;&#125; dIndex = 0 clus_dist = 10 for i in range(len(list1)-1): distance = abs(list1[i+1][0] - list1[i][0]) if distance &lt;= clus_dist: if not dIndex in clusters.keys(): clusters[dIndex] = [] clusters[dIndex].append(list1[i]) clusters[dIndex].append(list1[i + 1]) else: dIndex += 1 # step 4: 得到坐标 rects = &#123;&#125; i = 0 for key in clusters: all_list = clusters[key] cleaned = list(set(all_list)) if len(cleaned) &gt; 5: cleaned = sorted(cleaned, key=lambda tup: tup[1]) avg_y1 = cleaned[0][1] avg_y2 = cleaned[-1][1] avg_x1 = 0 avg_x2 = 0 for tup in cleaned: avg_x1 += tup[0] avg_x2 += tup[2] avg_x1 = avg_x1/len(cleaned) avg_x2 = avg_x2/len(cleaned) rects[i] = (avg_x1, avg_y1, avg_x2, avg_y2) i += 1 print("Num Parking Lanes: ", len(rects)) # step 5: 把矩形画出来 buff = 7 for key in rects: tup_topLeft = (int(rects[key][0] - buff), int(rects[key][1])) tup_botRight = (int(rects[key][2] + buff), int(rects[key][3])) cv2.rectangle(new_image, tup_topLeft,tup_botRight,(0,255,0),3) return new_image, rects def draw_parking(self, image, rects, make_copy=True, color=[255,0,0],thickness=2, save=True): if make_copy: new_image = np.copy(image) gap = 15.5 spot_dict = &#123;&#125; # 字典：一个车位对应一个位置 tot_spots = 0 #微调 adj_y1 = &#123;0: 20, 1:-10, 2:0, 3:-11, 4:28, 5:5, 6:-15, 7:-15, 8:-10, 9:-30, 10:9, 11:-32&#125; adj_y2 = &#123;0: 30, 1: 50, 2:15, 3:10, 4:-15, 5:15, 6:15, 7:-20, 8:15, 9:15, 10:0, 11:30&#125; adj_x1 = &#123;0: -8, 1:-15, 2:-15, 3:-15, 4:-15, 5:-15, 6:-15, 7:-15, 8:-10, 9:-10, 10:-10, 11:0&#125; adj_x2 = &#123;0: 0, 1: 15, 2:15, 3:15, 4:15, 5:15, 6:15, 7:15, 8:10, 9:10, 10:10, 11:0&#125; for key in rects: tup = rects[key] x1 = int(tup[0]+ adj_x1[key]) x2 = int(tup[2]+ adj_x2[key]) y1 = int(tup[1] + adj_y1[key]) y2 = int(tup[3] + adj_y2[key]) cv2.rectangle(new_image, (x1, y1),(x2,y2),(0,255,0),2) num_splits = int(abs(y2-y1)//gap) for i in range(0, num_splits+1): y = int(y1 + i*gap) cv2.line(new_image, (x1, y), (x2, y), color, thickness) if key &gt; 0 and key &lt; len(rects) -1 : #竖直线 x = int((x1 + x2)/2) cv2.line(new_image, (x, y1), (x, y2), color, thickness) # 计算数量 if key == 0 or key == (len(rects) -1): tot_spots += num_splits +1 else: tot_spots += 2*(num_splits +1) # 字典对应好 if key == 0 or key == (len(rects) -1): for i in range(0, num_splits+1): cur_len = len(spot_dict) y = int(y1 + i*gap) spot_dict[(x1, y, x2, y+gap)] = cur_len +1 else: for i in range(0, num_splits+1): cur_len = len(spot_dict) y = int(y1 + i*gap) x = int((x1 + x2)/2) spot_dict[(x1, y, x, y+gap)] = cur_len +1 spot_dict[(x, y, x2, y+gap)] = cur_len +2 print("total parking spaces: ", tot_spots, cur_len) if save: filename = 'with_parking.jpg' cv2.imwrite(filename, new_image) return new_image, spot_dict def assign_spots_map(self,image, spot_dict, make_copy = True, color=[255, 0, 0], thickness=2): if make_copy: new_image = np.copy(image) for spot in spot_dict.keys(): (x1, y1, x2, y2) = spot cv2.rectangle(new_image, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness) return new_image def save_images_for_cnn(self,image, spot_dict, folder_name ='cnn_data'): for spot in spot_dict.keys(): (x1, y1, x2, y2) = spot (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2)) #裁剪图像 spot_img = image[y1:y2, x1:x2] spot_img = cv2.resize(spot_img, (0,0), fx=2.0, fy=2.0) spot_id = spot_dict[spot] filename = 'spot' + str(spot_id) +'.jpg' print(spot_img.shape, filename, (x1,x2,y1,y2)) cv2.imwrite(os.path.join(folder_name, filename), spot_img) def make_prediction(self,image, model, class_dictionary): # 预处理 img = image/255. # 转换成4D tensor image = np.expand_dims(img,axis=0) # 用训练好的模型进行训练 class_predicted = model.predict(image) inID = np.argmax(class_predicted[0]) label = class_dictionary[inID] return label def predict_on_image(self, image, spot_dict, model, class_dictionary, make_copy=True, color = [0,255,0], alpha=0.5): if make_copy: new_image = np.copy(image) overlay = np.copy(image) self.cv_show('new_image',new_image) cnt_empty = 0 all_spots = 0 for spot in spot_dict.key(): all_spots += 1 (x1, y1, x2, y2) = spot (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2)) spot_img = image[y1:y2, x1:x2] spot_img = cv2.resize(spot_img, (48, 48)) label = self.make_prediction(spot_img,model,class_dictionary) if label == 'empty': cv2.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1) cnt_empty += 1 cv2.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image) # 图像融合 cv2.putText(new_image, "Available: %d spots" %cnt_empty, (30, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2) cv2.putText(new_image, "Total: %d spots" %all_spots, (30, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2) save = False if save: filename = 'with_marking.jpg' cv2.imwrite(filename, new_image) self.cv_show('new_image',new_image) return new_image def predict_on_video(self,video_name,final_spot_dict, model,class_dictionary,ret=True): cap = cv2.VideoCapture(video_name) count = 0 while ret: ret, image = cap.read() count += 1 if count == 5: count = 0 new_image = np.copy(image) overlay = np.copy(image) cnt_empty = 0 all_spots = 0 color = [0, 255, 0] alpha=0.5 for spot in final_spot_dict.keys(): all_spots += 1 (x1, y1, x2, y2) = spot (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2)) spot_img = image[y1:y2, x1:x2] spot_img = cv2.resize(spot_img, (48,48)) label = self.make_prediction(spot_img,model,class_dictionary) if label == 'empty': cv2.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1) cnt_empty += 1 cv2.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image) cv2.putText(new_image, "Available: %d spots" %cnt_empty, (30, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2) cv2.putText(new_image, "Total: %d spots" %all_spots, (30, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2) cv2.imshow('frame', new_image) if cv2.waitKey(10) &amp; 0xFF == ord('q'): break cv2.destroyAllWindows() cap.release() test模块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485from __future__ import divisionimport matplotlib.pyplot as pltimport cv2import os, globimport numpy as npfrom PIL import Imagefrom keras.applications.imagenet_utils import preprocess_inputfrom keras.models import load_modelfrom keras.preprocessing import imagefrom Parking import Parkingimport picklecwd = os.getcwd()def img_process(test_images,park): white_yellow_images = list(map(park.select_rgb_white_yellow, test_images)) park.show_images(white_yellow_images) gray_images = list(map(park.convert_gray_scale, white_yellow_images)) park.show_images(gray_images) edge_images = list(map(lambda image: park.detect_edges(image), gray_images)) park.show_images(edge_images) roi_images = list(map(park.select_region, edge_images)) park.show_images(roi_images) list_of_lines = list(map(park.hough_lines, roi_images)) line_images = [] for image, lines in zip(test_images, list_of_lines): line_images.append(park.draw_lines(image, lines)) park.show_images(line_images) rect_images = [] rect_coords = [] for image, lines in zip(test_images, list_of_lines): new_image, rects = park.identify_blocks(image, lines) rect_images.append(new_image) rect_coords.append(rects) park.show_images(rect_images) delineated = [] spot_pos = [] for image, rects in zip(test_images, rect_coords): new_image, spot_dict = park.draw_parking(image, rects) delineated.append(new_image) spot_pos.append(spot_dict) park.show_images(delineated) final_spot_dict = spot_pos[1] print(len(final_spot_dict)) with open('spot_dict.pickle', 'wb') as handle: pickle.dump(final_spot_dict, handle, protocol=pickle.HIGHEST_PROTOCOL) park.save_images_for_cnn(test_images[0],final_spot_dict) return final_spot_dictdef keras_model(weights_path): model = load_model(weights_path) return modeldef img_test(test_images,final_spot_dict,model,class_dictionary): for i in range (len(test_images)): predicted_images = park.predict_on_image(test_images[i],final_spot_dict,model,class_dictionary)def video_test(video_name,final_spot_dict,model,class_dictionary): name = video_name cap = cv2.VideoCapture(name) park.predict_on_video(name,final_spot_dict,model,class_dictionary,ret=True) if __name__ == '__main__': test_images = [plt.imread(path) for path in glob.glob('test_images/*.jpg')] weights_path = 'car1.h5' video_name = 'parking_video.mp4' class_dictionary = &#123;&#125; class_dictionary[0] = 'empty' class_dictionary[1] = 'occupied' park = Parking() park.show_images(test_images) final_spot_dict = img_process(test_images,park) model = keras_model(weights_path) img_test(test_images,final_spot_dict,model,class_dictionary) video_test(video_name,final_spot_dict,model,class_dictionary) 利用cnn训练出一个二分类网络123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import numpyimport osfrom keras import applicationsfrom keras.preprocessing.image import ImageDataGeneratorfrom keras import optimizersfrom keras.models import Sequential, Modelfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2Dfrom keras import backend as kfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStoppingfrom keras.models import Sequentialfrom keras.layers.normalization import BatchNormalizationfrom keras.layers.convolutional import Conv2Dfrom keras.layers.convolutional import MaxPooling2Dfrom keras.initializers import TruncatedNormalfrom keras.layers.core import Activationfrom keras.layers.core import Flattenfrom keras.layers.core import Dropoutfrom keras.layers.core import Densefiles_train = 0files_validation = 0cwd = os.getcwd()folder = 'train_data/train'for sub_folder in os.listdir(folder): path, dirs, files = next(os.walk(os.path.join(folder,sub_folder))) files_train += len(files)folder = 'train_data/test'for sub_folder in os.listdir(folder): path, dirs, files = next(os.walk(os.path.join(folder,sub_folder))) files_validation += len(files)print(files_train,files_validation)img_width, img_height = 48, 48train_data_dir = "train_data/train"validation_data_dir = "train_data/test"nb_train_samples = files_trainnb_validation_samples = files_validationbatch_size = 32epochs = 15num_classes = 2model = applications.VGG16(weights='imagenet', include_top=False, input_shape = (img_width, img_height, 3))for layer in model.layers[:10]: layer.trainable = Falsex = model.outputx = Flatten()(x)predictions = Dense(num_classes, activation="softmax")(x)model_final = Model(input = model.input, output = predictions)model_final.compile(loss = "categorical_crossentropy", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=["accuracy"]) train_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip = True,fill_mode = "nearest",zoom_range = 0.1,width_shift_range = 0.1,height_shift_range=0.1,rotation_range=5)test_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip = True,fill_mode = "nearest",zoom_range = 0.1,width_shift_range = 0.1,height_shift_range=0.1,rotation_range=5)train_generator = train_datagen.flow_from_directory(train_data_dir,target_size = (img_height, img_width),batch_size = batch_size,class_mode = "categorical")validation_generator = test_datagen.flow_from_directory(validation_data_dir,target_size = (img_height, img_width),class_mode = "categorical")checkpoint = ModelCheckpoint("car1.h5", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')history_object = model_final.fit_generator(train_generator,samples_per_epoch = nb_train_samples,epochs = epochs,validation_data = validation_generator,nb_val_samples = nb_validation_samples,callbacks = [checkpoint, early]) 参考资料： 唐宇迪 OpenCV计算机视觉实战(Python版)]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像处理-1]]></title>
    <url>%2F2019%2F10%2F13%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-1%2F</url>
    <content type="text"><![CDATA[灰度图123456789101112import cv2 #opencv读取的格式是BGRimport numpy as npimport matplotlib.pyplot as plt#Matplotlib是RGB%matplotlib inline img=cv2.imread('cat.jpg')img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)img_gray.shapecv2.imshow("img_gray", img_gray)cv2.waitKey(0) cv2.destroyAllWindows() HSV H - 色调（主波长）。 S - 饱和度（纯度/颜色的阴影）。 V值（强度）12345hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)cv2.imshow("hsv", hsv)cv2.waitKey(0) cv2.destroyAllWindows() 图像阈值ret, dst = cv2.threshold(src, thresh, maxval, type) src： 输入图，只能输入单通道图像，通常来说为灰度图 dst： 输出图 thresh： 阈值 maxval： 当像素值超过了阈值（或者小于阈值，根据type来决定），所赋予的值 type：二值化操作的类型，包含以下5种类型： cv2.THRESH_BINARY； cv2.THRESH_BINARY_INV； cv2.THRESH_TRUNC； cv2.THRESH_TOZERO； cv2.THRESH_TOZERO_INV cv2.THRESH_BINARY 超过阈值部分取maxval（最大值），否则取0 cv2.THRESH_BINARY_INV THRESH_BINARY的反转 cv2.THRESH_TRUNC 大于阈值部分设为阈值，否则不变 cv2.THRESH_TOZERO 大于阈值部分不改变，否则设为0 cv2.THRESH_TOZERO_INV THRESH_TOZERO的反转1234567891011121314ret, thresh1 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)ret, thresh2 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV) # INV 反转ret, thresh3 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TRUNC)ret, thresh4 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO)ret, thresh5 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO_INV)titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]for i in range(6): plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray') plt.title(titles[i]) plt.xticks([]), plt.yticks([])plt.show() 图像平滑12345678910111213141516171819202122232425262728293031323334353637383940414243444546img = cv2.imread('lenaNoise.png')cv2.imshow('img', img)cv2.waitKey(0)cv2.destroyAllWindows()# 均值滤波# 简单的平均卷积操作blur = cv2.blur(img, (3, 3))cv2.imshow('blur', blur)cv2.waitKey(0)cv2.destroyAllWindows()# 方框滤波# 基本和均值一样，可以选择归一化 ，-1表示颜色通道是一至的box = cv2.boxFilter(img,-1,(3,3), normalize=True) cv2.imshow('box', box)cv2.waitKey(0)cv2.destroyAllWindows()# 方框滤波# 基本和均值一样，可以选择归一化,容易越界 ，做归一化的结果跟均值滤波是一样的box = cv2.boxFilter(img,-1,(3,3), normalize=False) cv2.imshow('box', box)cv2.waitKey(0)cv2.destroyAllWindows()# 高斯滤波# 高斯模糊的卷积核里的数值是满足高斯分布，相当于更重视中间的aussian = cv2.GaussianBlur(img, (5, 5), 1) cv2.imshow('aussian', aussian)cv2.waitKey(0)cv2.destroyAllWindows()# 中值滤波# 相当于用中值代替median = cv2.medianBlur(img, 5) # 中值滤波cv2.imshow('median', median)cv2.waitKey(0)cv2.destroyAllWindows()# 展示所有的res = np.hstack((blur,aussian,median))#print (res)cv2.imshow('median vs average', res)cv2.waitKey(0)cv2.destroyAllWindows() 形态学-腐蚀操作1234567891011121314151617181920212223img = cv2.imread('dige.png')cv2.imshow('img', img)cv2.waitKey(0)cv2.destroyAllWindows()kernel = np.ones((3,3),np.uint8) erosion = cv2.erode(img,kernel,iterations = 1) # erode函数cv2.imshow('erosion', erosion)cv2.waitKey(0)cv2.destroyAllWindows()pie = cv2.imread('pie.png')cv2.imshow('pie', pie)cv2.waitKey(0)cv2.destroyAllWindows()kernel = np.ones((30,30),np.uint8) erosion_1 = cv2.erode(pie,kernel,iterations = 1)erosion_2 = cv2.erode(pie,kernel,iterations = 2)erosion_3 = cv2.erode(pie,kernel,iterations = 3)res = np.hstack((erosion_1,erosion_2,erosion_3))cv2.imshow('res', res)cv2.waitKey(0)cv2.destroyAllWindows() 形态学-膨胀操作1234567891011121314151617181920212223242526img = cv2.imread('dige.png')cv2.imshow('img', img)cv2.waitKey(0)cv2.destroyAllWindows()kernel = np.ones((3,3),np.uint8) dige_erosion = cv2.erode(img,kernel,iterations = 1)cv2.imshow('erosion', erosion)cv2.waitKey(0)cv2.destroyAllWindows()kernel = np.ones((3,3),np.uint8) dige_dilate = cv2.dilate(dige_erosion,kernel,iterations = 1)cv2.imshow('dilate', dige_dilate)cv2.waitKey(0)cv2.destroyAllWindows()pie = cv2.imread('pie.png')kernel = np.ones((30,30),np.uint8) dilate_1 = cv2.dilate(pie,kernel,iterations = 1)dilate_2 = cv2.dilate(pie,kernel,iterations = 2)dilate_3 = cv2.dilate(pie,kernel,iterations = 3)res = np.hstack((dilate_1,dilate_2,dilate_3))cv2.imshow('res', res)cv2.waitKey(0)cv2.destroyAllWindows() 开运算与闭运算12345678910111213141516171819# 开：先腐蚀，再膨胀img = cv2.imread('dige.png')kernel = np.ones((5,5),np.uint8) opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)cv2.imshow('opening', opening)cv2.waitKey(0)cv2.destroyAllWindows()# 闭：先膨胀，再腐蚀img = cv2.imread('dige.png')kernel = np.ones((5,5),np.uint8) closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)cv2.imshow('closing', closing)cv2.waitKey(0)cv2.destroyAllWindows() 梯度运算12345678910111213141516# 梯度=膨胀-腐蚀pie = cv2.imread('pie.png')kernel = np.ones((7,7),np.uint8) dilate = cv2.dilate(pie,kernel,iterations = 5)erosion = cv2.erode(pie,kernel,iterations = 5)res = np.hstack((dilate,erosion))cv2.imshow('res', res)cv2.waitKey(0)cv2.destroyAllWindows()gradient = cv2.morphologyEx(pie, cv2.MORPH_GRADIENT, kernel)cv2.imshow('gradient', gradient)cv2.waitKey(0)cv2.destroyAllWindows() 礼帽与黑帽 礼帽 = 原始输入-开运算结果 黑帽 = 闭运算-原始输入123456789101112#礼帽img = cv2.imread('dige.png')tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)cv2.imshow('tophat', tophat)cv2.waitKey(0)cv2.destroyAllWindows()#黑帽img = cv2.imread('dige.png')blackhat = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT, kernel)cv2.imshow('blackhat ', blackhat )cv2.waitKey(0)cv2.destroyAllWindows() 参考资料： 唐宇迪 OpenCV计算机视觉实战(Python版)]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zhongjie]]></title>
    <url>%2F2019%2F09%2F30%2Fzhongjie%2F</url>
    <content type="text"><![CDATA[一切终止于今天吧！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hungary算法]]></title>
    <url>%2F2019%2F09%2F16%2FHungary%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Sort]]></title>
    <url>%2F2019%2F09%2F15%2FSort%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[树的子结构]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%A0%91%E7%9A%84%E5%AD%90%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：829537本题知识点： 链表 题目描述输入一个链表，输出该链表中倒数第k个结点。 123456789101112131415161718192021222324252627282930# -*- coding:utf-8 -*-# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def HasSubtree(self, pRoot1, pRoot2): # write code here if pRoot1 is None or pRoot2 is None: return False result = False if pRoot1.val == pRoot2.val: result = self.isSubtree(pRoot1,pRoot2) if result == False: result = self.HasSubtree(pRoot1.left, pRoot2) | self.HasSubtree(pRoot1.right, pRoot2) return result def isSubtree(self,root1,root2): if root2 is None: return True if root1 is None: return False if root1.val == root2.val: return self.isSubtree(root1.left,root2.left) &amp; self.isSubtree(root1.right,root2.right) return False 运行时间：24 ms占用内存：5860K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[合并两个排序的链表]]></title>
    <url>%2F2019%2F09%2F14%2F%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：587032本题知识点： 链表 题目描述输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 1234567891011121314151617181920212223/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* Merge(ListNode* pHead1, ListNode* pHead2) &#123; if(!pHead1)return pHead2; if(!pHead2)return pHead1; if(pHead1-&gt;val&lt;=pHead2-&gt;val)&#123; pHead1-&gt;next= Merge(pHead1-&gt;next,pHead2); return pHead1; &#125;else&#123; pHead2-&gt;next= Merge(pHead1,pHead2-&gt;next); return pHead2; &#125; &#125;&#125;; 1234567891011121314151617181920# -*- coding:utf-8 -*-# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: # 返回合并后列表 def Merge(self, pHead1, pHead2): # write code here if pHead1 is None: return pHead2 if pHead2 is None: return pHead1 if pHead1.val &lt; pHead2.val: pHead1.next = self.Merge(pHead1.next,pHead2) return pHead1 else: pHead2.next = self.Merge(pHead1,pHead2.next) return pHead2 运行时间：3ms占用内存：492k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mosse]]></title>
    <url>%2F2019%2F09%2F14%2Fmosse%2F</url>
    <content type="text"><![CDATA[MOSSEMOSSE(Minimum Output Sum of Squared Error) 是2010年 的CVPR，它的全名叫做Visual Object Tracking using Adaptive Correlation Filters。 MOSSE 是第一篇将correlation filter(CF) 引入object tracking 的论文，它也是CSK和KCF/DCF等算法的基础。 CF(相关滤波)相关一般分为自相关和互相关，这里我们一般指的是互相关，假设我们有两个信号f和g \begin{array}{l}{(f \otimes g)(\tau) \stackrel{\text {def}}{=} \int_{-\infty}^{\infty} f^{*}(t) g(t+\tau) d t} \\ {(f \otimes g)(n) \stackrel{\text {def}}{=} \sum_{-\infty}^{\infty} f^{*}[m] g(m+n)}\end{array}f∗表示f的共轭，互相关的直接解释就是衡量两个信号在某个时刻τ时的相似程度。假设f和g的形状一样，那么一定是f和g对齐的时候二者的相似程度最大，此时达到最大的输出响应，如下图所示：卷积计算和相关计算的关系 Two-dimensional correlation is equivalent to two-dimensional convolution with the filter matrix rotated 180 degrees. 论文解读 将CF应用在tracking方面最基本的思想就是，设计一个滤波模板，使得该模板与跟踪目标的ROI做卷积运算，得到最大的输出响应。 g=f \otimes h g表示输出响应 f表示输入原始图片的灰度图像 h表示滤波模板为了简化计算，将时域的卷积转化为频域的点乘积。时域公式表示： g=f^{*} h频域公式表示： G=F \bullet H^{*}所以目标H的计算为： H^{*}=\frac{G}{F}在跟踪的光照等其他因素的影响下，为了提高滤波模板的鲁棒性，在文章中作者对GroundTruth进行随机仿射变换得到一系列的训练样本fi，gi是由高斯函数产生的并且其峰值位置是在fi的中心,我们同时考虑m帧作为参考，这就是MOSSE模型的思想，最终该模型的目标函数表示为： \min _{H^{*}} \sum_{i}\left|F_{i} \odot H^{*}-G_{i}\right|^{2}将目标函数最小化，对上式在频域进行求导（复数域不同于实数域），得到： H=\frac{\sum_{i=1}^{m} F_{i} \odot G_{i}^{*}}{\sum_{i=1}^{m} F_{i} \odot F_{i}^{*}}在跟踪过程中，我们只需要将以上模板与当前帧与滤波模板做相关操作，在输出响应中找到最大值的位置，该位置就是目标在当前帧中的位置。本文的参数更新的策略为： H_{t}=\frac{A_{t}}{B_{t}} \begin{array}{l}{A_{t}=\eta F_{t} \cdot G_{t}^{*}+(1-\eta) A_{t-1}} \\ {B_{t}=\eta F_{t} \cdot F_{t}^{*}+(1-\eta) B_{t-1}}\end{array}其中，η是一个超参数，为经验值。 缺点： 输入的特征为单通道灰度图像，特征表达能力有限 没有尺度更新，对于尺度变化的跟踪目标不敏感 代码解析这里面主要做的就是 ，初始帧的输入与输出来求出Ai与Bi，从而求出初始的模板Hi，下面将初始的Hi与当前帧所在的上个位置进行卷积，频域也就是进行相乘。然后找到最大值的位置也就是当前目标的中心，由于宽高不变，所以在此基础上更新宽高就可以了，实现目标跟踪。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import numpy as npimport cv2import osfrom utils import linear_mapping, pre_process, random_warp"""This module implements the basic correlation filter based tracking algorithm -- MOSSEDate: 2018-05-28"""class mosse: def __init__(self, args, img_path): # get arguments.. self.args = args self.img_path = img_path # get the img lists... self.frame_lists = self._get_img_lists(self.img_path) self.frame_lists.sort() # start to do the object tracking... def start_tracking(self): # get the image of the first frame... (read as gray scale image...) init_img = cv2.imread(self.frame_lists[0]) init_frame = cv2.cvtColor(init_img, cv2.COLOR_BGR2GRAY) init_frame = init_frame.astype(np.float32) # get the init ground truth.. [x, y, width, height] init_gt = cv2.selectROI('demo', init_img, False, False) init_gt = np.array(init_gt).astype(np.int64) # start to draw the gaussian response... response_map = self._get_gauss_response(init_frame, init_gt) # start to create the training set ... # get the goal.. print(init_gt) g = response_map[init_gt[1]:init_gt[1]+init_gt[3], init_gt[0]:init_gt[0]+init_gt[2]] print(g) fi = init_frame[init_gt[1]:init_gt[1]+init_gt[3], init_gt[0]:init_gt[0]+init_gt[2]] G = np.fft.fft2(g) # start to do the pre-training... Ai, Bi = self._pre_training(fi, G) # start the tracking... for idx in range(len(self.frame_lists)): current_frame = cv2.imread(self.frame_lists[idx]) frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY) frame_gray = frame_gray.astype(np.float32) if idx == 0: Ai = self.args.lr * Ai Bi = self.args.lr * Bi pos = init_gt.copy() clip_pos = np.array([pos[0], pos[1], pos[0]+pos[2], pos[1]+pos[3]]).astype(np.int64) else: Hi = Ai / Bi fi = frame_gray[clip_pos[1]:clip_pos[3], clip_pos[0]:clip_pos[2]] fi = pre_process(cv2.resize(fi, (init_gt[2], init_gt[3]))) Gi = Hi * np.fft.fft2(fi) gi = linear_mapping(np.fft.ifft2(Gi)) # find the max pos... max_value = np.max(gi) max_pos = np.where(gi == max_value) dy = int(np.mean(max_pos[0]) - gi.shape[0] / 2) dx = int(np.mean(max_pos[1]) - gi.shape[1] / 2) # update the position... pos[0] = pos[0] + dx pos[1] = pos[1] + dy # trying to get the clipped position [xmin, ymin, xmax, ymax] clip_pos[0] = np.clip(pos[0], 0, current_frame.shape[1]) clip_pos[1] = np.clip(pos[1], 0, current_frame.shape[0]) clip_pos[2] = np.clip(pos[0]+pos[2], 0, current_frame.shape[1]) clip_pos[3] = np.clip(pos[1]+pos[3], 0, current_frame.shape[0]) clip_pos = clip_pos.astype(np.int64) # get the current fi.. fi = frame_gray[clip_pos[1]:clip_pos[3], clip_pos[0]:clip_pos[2]] fi = pre_process(cv2.resize(fi, (init_gt[2], init_gt[3]))) # online update... Ai = self.args.lr * (G * np.conjugate(np.fft.fft2(fi))) + (1 - self.args.lr) * Ai Bi = self.args.lr * (np.fft.fft2(fi) * np.conjugate(np.fft.fft2(fi))) + (1 - self.args.lr) * Bi # visualize the tracking process... cv2.rectangle(current_frame, (pos[0], pos[1]), (pos[0]+pos[2], pos[1]+pos[3]), (255, 0, 0), 2) cv2.imshow('demo', current_frame) cv2.waitKey(100) # if record... save the frames.. if self.args.record: frame_path = 'record_frames/' + self.img_path.split('/')[1] + '/' if not os.path.exists(frame_path): os.mkdir(frame_path) cv2.imwrite(frame_path + str(idx).zfill(5) + '.png', current_frame) # pre train the filter on the first frame... def _pre_training(self, init_frame, G): height, width = G.shape fi = cv2.resize(init_frame, (width, height)) # pre-process img.. fi = pre_process(fi) Ai = G * np.conjugate(np.fft.fft2(fi)) Bi = np.fft.fft2(init_frame) * np.conjugate(np.fft.fft2(init_frame)) for _ in range(self.args.num_pretrain): if self.args.rotate: fi = pre_process(random_warp(init_frame)) else: fi = pre_process(init_frame) Ai = Ai + G * np.conjugate(np.fft.fft2(fi)) Bi = Bi + np.fft.fft2(fi) * np.conjugate(np.fft.fft2(fi)) return Ai, Bi # get the ground-truth gaussian reponse... def _get_gauss_response(self, img, gt): # get the shape of the image.. height, width = img.shape # get the mesh grid... xx, yy = np.meshgrid(np.arange(width), np.arange(height)) # get the center of the object... center_x = gt[0] + 0.5 * gt[2] center_y = gt[1] + 0.5 * gt[3] # cal the distance... dist = (np.square(xx - center_x) + np.square(yy - center_y)) / (2 * self.args.sigma) # get the response map... response = np.exp(-dist) # normalize... response = linear_mapping(response) return response # it will extract the image list def _get_img_lists(self, img_path): frame_list = [] for frame in os.listdir(img_path): if os.path.splitext(frame)[1] == '.jpg': frame_list.append(os.path.join(img_path, frame)) return frame_list # it will get the first ground truth of the video.. def _get_init_ground_truth(self, img_path): gt_path = os.path.join(img_path, 'groundtruth.txt') with open(gt_path, 'r') as f: # just read the first frame... line = f.readline() gt_pos = line.split(',') return [float(element) for element in gt_pos] 参考链接：http://simtalk.cn/2017/07/03/Object-Tracking/https://github.com/TianhongDai/mosse-object-tracking]]></content>
      <categories>
        <category>Object-Tracking</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四边形按照顺时针排序]]></title>
    <url>%2F2019%2F09%2F12%2F%E5%9B%9B%E8%BE%B9%E5%BD%A2%E6%8C%89%E7%85%A7%E9%A1%BA%E6%97%B6%E9%92%88%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[做图像检测的时候处理数据经常遇到给出矩形的四个坐标点，要求找出左上角坐标并对乱序的坐标按顺时针或者逆时针进行排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091from scipy.spatial import distance as distimport numpy as npimport mathdef cos_dist(a, b): if len(a) != len(b): return None part_up = 0.0 a_sq = 0.0 b_sq = 0.0 print(a, b) print(zip(a, b)) for a1, b1 in zip(a, b): part_up += a1*b1 a_sq += a1**2 b_sq += b1**2 part_down = math.sqrt(a_sq*b_sq) if part_down == 0.0: return None else: return part_up / part_down# this function is confined to rectangledef order_points(pts): # sort the points based on their x-coordinates xSorted = pts[np.argsort(pts[:, 0]), :] # grab the left-most and right-most points from the sorted # x-roodinate points leftMost = xSorted[:2, :] rightMost = xSorted[2:, :] # now, sort the left-most coordinates according to their # y-coordinates so we can grab the top-left and bottom-left # points, respectively leftMost = leftMost[np.argsort(leftMost[:, 1]), :] (tl, bl) = leftMost # now that we have the top-left coordinate, use it as an # anchor to calculate the Euclidean distance between the # top-left and right-most points; by the Pythagorean # theorem, the point with the largest distance will be # our bottom-right point D = dist.cdist(tl[np.newaxis], rightMost, "euclidean")[0] (br, tr) = rightMost[np.argsort(D)[::-1], :] # return the coordinates in top-left, top-right, # bottom-right, and bottom-left order return np.array([tl, tr, br, bl], dtype="float32")def order_points_quadrangle(pts): # sort the points based on their x-coordinates xSorted = pts[np.argsort(pts[:, 0]), :] # grab the left-most and right-most points from the sorted # x-roodinate points leftMost = xSorted[:2, :] rightMost = xSorted[2:, :] # now, sort the left-most coordinates according to their # y-coordinates so we can grab the top-left and bottom-left # points, respectively leftMost = leftMost[np.argsort(leftMost[:, 1]), :] (tl, bl) = leftMost # now that we have the top-left and bottom-left coordinate, use it as an # base vector to calculate the angles between the other two vectors vector_0 = np.array(bl-tl) vector_1 = np.array(rightMost[0]-tl) vector_2 = np.array(rightMost[1]-tl) angle = [np.arccos(cos_dist(vector_0, vector_1)), np.arccos(cos_dist(vector_0, vector_2))] (br, tr) = rightMost[np.argsort(angle), :] # return the coordinates in top-left, top-right, # bottom-right, and bottom-left order return np.array([tl, tr, br, bl], dtype="float32")testdata =[1074,439,1078,424,991,427,991,411]points = numpy.array(array).reshape(4,2)poit = order_points_quadrangle(points)poitarray([[ 991., 411.], [1078., 424.], [1074., 439.], [ 991., 427.]], dtype=float32) 参考链接：http://www.bnee.net/article/821708.html]]></content>
      <categories>
        <category>tools</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反转链表]]></title>
    <url>%2F2019%2F09%2F12%2F%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：606485本题知识点： 链表 题目描述输入一个链表，反转链表后，输出新链表的表头。 123456789101112131415161718192021222324/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* ReverseList(ListNode* pHead) &#123; ListNode *prev = NULL; ListNode *curr = pHead; ListNode *next = NULL; while(curr!=NULL) &#123; next = curr-&gt;next; curr-&gt;next = prev; prev = curr; curr = next; &#125; return prev; &#125;&#125;; 运行时间：4ms占用内存：488]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表中倒数第k个结点]]></title>
    <url>%2F2019%2F09%2F10%2F%E9%93%BE%E8%A1%A8%E4%B8%AD%E5%80%92%E6%95%B0%E7%AC%ACk%E4%B8%AA%E7%BB%93%E7%82%B9%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：829537本题知识点： 链表 题目描述输入一个链表，输出该链表中倒数第k个结点。 1234567891011121314151617181920212223242526272829303132/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindKthToTail(ListNode* pListHead, unsigned int k) &#123; if (k == 0) return NULL;//如果K为0，返回NULL queue&lt;ListNode*&gt; que; ListNode *node = pListHead; while (node != NULL) &#123; if (que.size() == k) &#123; que.pop(); &#125; que.push(node); node = node-&gt;next; &#125; if (que.size() == k) return que.front(); else return NULL;//如果k大于链表的最大长度，返回NULL &#125;&#125;; 运行时间：3ms占用内存：472K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持向量机]]></title>
    <url>%2F2019%2F09%2F08%2F%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[SVM的本质：寻找最大的间隔支持向量：距离超平面最近的那些点SMO算法的原理：每次循环中选择两个alpha进行优化处理。一旦找到一对合适的alpha，那么就增大其中一个同时减小另一个。合适：条件一，两个alpha要在间隔边界之外；条件二，这两个alpha还没有进行过区间化处理或不在边界上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214from numpy import *import csvdef loadDataSet(filename): # 读取数据 with open(filename) as f: dataMat = [] labelMat = [] f_csv = csv.reader(f) ## 用csv读取直接是个list headers = next(f_csv) for row in f_csv: dataMat.append([float(row[0]), float(row[1])]) labelMat.append(float(row[2])) f.close() return dataMat, labelMatdef selectJrand(i, m): # 在0-m中随机选择一个不是i的整数 j = i while (j == i): j = int(random.uniform(0, m)) return jdef clipAlpha(aj, H, L): # 保证a在L和H范围内（L &lt;= a &lt;= H） if aj &gt; H: aj = H if L &gt; aj: aj = L return ajdef kernelTrans(X, A, kTup): # 核函数，输入参数,X:支持向量的特征树；A：某一行特征数据；kTup：('lin',k1)核函数的类型和参数 m, n = shape(X) K = mat(zeros((m, 1))) print("A shape : ",A.shape) print("X shape : ",X.shape) if kTup[0] == 'lin': # 线性函数 K = X * A.T elif kTup[0] == 'rbf': # 径向基函数(radial bias function) for j in range(m): deltaRow = X[j, :] - A K[j] = deltaRow * deltaRow.T K = exp(K / (-1 * kTup[1] ** 2)) # 返回生成的结果 else: raise NameError('Houston We Have a Problem -- That Kernel is not recognized') return K# 定义类，方便存储数据class optStruct: def __init__(self, dataMatIn, classLabels, C, toler, kTup): # 存储各类参数 self.X = dataMatIn # 数据特征 self.labelMat = classLabels # 数据类别 self.C = C # 软间隔参数C，参数越大，非线性拟合能力越强 self.tol = toler # 停止阀值 self.m = shape(dataMatIn)[0] # 数据 b行数 self.alphas = mat(zeros((self.m, 1))) self.b = 0 # 初始设为0 self.eCache = mat(zeros((self.m, 2))) # 缓存 self.K = mat(zeros((self.m, self.m))) # 核函数的计算结果 for i in range(self.m): self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)def calcEk(oS, k): # 计算Ek（参考《统计学习方法》p127公式7.105） fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:, k] + oS.b) Ek = fXk - float(oS.labelMat[k]) return Ek# 随机选取aj，并返回其E值def selectJ(i, oS, Ei): maxK = -1 maxDeltaE = 0 Ej = 0 oS.eCache[i] = [1, Ei] validEcacheList = nonzero(oS.eCache[:, 0].A)[0] # 返回矩阵中的非零位置的行数 if (len(validEcacheList)) &gt; 1: for k in validEcacheList: if k == i: continue Ek = calcEk(oS, k) deltaE = abs(Ei - Ek) if (deltaE &gt; maxDeltaE): # 返回步长最大的aj maxK = k maxDeltaE = deltaE Ej = Ek return maxK, Ej else: j = selectJrand(i, oS.m) Ej = calcEk(oS, j) return j, Ejdef updateEk(oS, k): # 更新os数据 Ek = calcEk(oS, k) oS.eCache[k] = [1, Ek]# 首先检验ai是否满足KKT条件，如果不满足，随机选择aj进行优化，更新ai,aj,b值def innerL(i, oS): # 输入参数i和所有参数数据 Ei = calcEk(oS, i) # 计算E值 if ((oS.labelMat[i] * Ei &lt; -oS.tol) and (oS.alphas[i] &lt; oS.C)) or ( (oS.labelMat[i] * Ei &gt; oS.tol) and (oS.alphas[i] &gt; 0)): # 检验这行数据是否符合KKT条件 参考《统计学习方法》p128公式7.111-113 j, Ej = selectJ(i, oS, Ei) # 随机选取aj，并返回其E值 alphaIold = oS.alphas[i].copy() alphaJold = oS.alphas[j].copy() if (oS.labelMat[i] != oS.labelMat[j]): # 以下代码的公式参考《统计学习方法》p126 L = max(0, oS.alphas[j] - oS.alphas[i]) H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i]) else: L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C) H = min(oS.C, oS.alphas[j] + oS.alphas[i]) if L == H: print("L==H") return 0 eta = 2.0 * oS.K[i, j] - oS.K[i, i] - oS.K[j, j] # 参考《统计学习方法》p127公式7.107 if eta &gt;= 0: print("eta&gt;=0") return 0 oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta # 参考《统计学习方法》p127公式7.106 oS.alphas[j] = clipAlpha(oS.alphas[j], H, L) # 参考《统计学习方法》p127公式7.108 updateEk(oS, j) if (abs(oS.alphas[j] - alphaJold) &lt; oS.tol): # alpha变化大小阀值（自己设定） print("j not moving enough") return 0 oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j]) # 参考《统计学习方法》p127公式7.109 updateEk(oS, i) # 更新数据 # 以下求解b的过程，参考《统计学习方法》p129公式7.114-7.116 b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, i] - oS.labelMat[j] * ( oS.alphas[j] - alphaJold) * oS.K[i, j] b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i, j] - oS.labelMat[j] * ( oS.alphas[j] - alphaJold) * oS.K[j, j] if (0 &lt; oS.alphas[i] &lt; oS.C): oS.b = b1 elif (0 &lt; oS.alphas[j] &lt; oS.C): oS.b = b2 else: oS.b = (b1 + b2) / 2.0 return 1 else: return 0# SMO函数，用于快速求解出alphadef smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0)): # 输入参数：数据特征，数据类别，参数C，阀值toler，最大迭代次数，核函数（默认线性核） oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup) # dataArr, labelArr, 200, 0.0001, 10000, ('rbf', 1.3)) # 通过SMO算法得到b和alpha iter = 0 entireSet = True alphaPairsChanged = 0 while (iter &lt; maxIter) and ((alphaPairsChanged &gt; 0) or (entireSet)): alphaPairsChanged = 0 if entireSet: for i in range(oS.m): # 遍历所有数据 alphaPairsChanged += innerL(i, oS) print("fullSet, iter: %d i:%d, pairs changed %d" % ( iter, i, alphaPairsChanged)) # 显示第多少次迭代，那行特征数据使alpha发生了改变，这次改变了多少次alpha iter += 1 else: nonBoundIs = nonzero((oS.alphas.A &gt; 0) * (oS.alphas.A &lt; C))[0] for i in nonBoundIs: # 遍历非边界的数据 alphaPairsChanged += innerL(i, oS) print("non-bound, iter: %d i:%d, pairs changed %d" % (iter, i, alphaPairsChanged)) iter += 1 if entireSet: entireSet = False elif (alphaPairsChanged == 0): entireSet = True print("iteration number: %d" % iter) return oS.b, oS.alphasdef train(data_train, data_test): dataArr, labelArr = loadDataSet(data_train) # 读取训练数据 b, alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', 1.3)) # 通过SMO算法得到b和alpha datMat = mat(dataArr) labelMat = mat(labelArr).transpose() svInd = nonzero(alphas)[0] # 选取不为0数据的行数（也就是支持向量） sVs = datMat[svInd] # 支持向量的特征数据 labelSV = labelMat[svInd] # 支持向量的类别（1或-1） print("there are %d Support Vectors" % shape(sVs)[0]) # 打印出共有多少的支持向量 m, n = shape(datMat) # 训练数据的行列数 errorCount = 0 for i in range(m): kernelEval = kernelTrans(sVs, datMat[i, :], ('rbf', 1.3)) # 将支持向量转化为核函数 predict = kernelEval.T * multiply(labelSV, alphas[ svInd]) + b # 这一行的预测结果（代码来源于《统计学习方法》p133里面最后用于预测的公式）注意最后确定的分离平面只有那些支持向量决定。 if sign(predict) != sign(labelArr[i]): # sign函数 -1 if x &lt; 0, 0 if x==0, 1 if x &gt; 0 errorCount += 1 print("the training error rate is: %f" % (float(errorCount) / m)) # 打印出错误率 dataArr_test, labelArr_test = loadDataSet(data_test) # 读取测试数据 errorCount_test = 0 datMat_test = mat(dataArr_test) labelMat = mat(labelArr_test).transpose() m, n = shape(datMat_test) for i in range(m): # 在测试数据上检验错误率 kernelEval = kernelTrans(sVs, datMat_test[i, :], ('rbf', 1.3)) predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b if sign(predict) != sign(labelArr_test[i]): errorCount_test += 1 print("the test error rate is: %f" % (float(errorCount_test) / m))# 主程序def main(): filename_traindata = './train_data.csv' filename_testdata = './test_data.csv' train(filename_traindata, filename_testdata)if __name__ == '__main__': main() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203feature1,feature2,label-0.214824,0.662756,-1.000000-0.061569,-0.091875,1.0000000.406933,0.648055,-1.0000000.223650,0.130142,1.0000000.231317,0.766906,-1.000000-0.748800,-0.531637,-1.000000-0.557789,0.375797,-1.0000000.207123,-0.019463,1.0000000.286462,0.719470,-1.0000000.195300,-0.179039,1.000000-0.152696,-0.153030,1.0000000.384471,0.653336,-1.000000-0.117280,-0.153217,1.000000-0.238076,0.000583,1.000000-0.413576,0.145681,1.0000000.490767,-0.680029,-1.0000000.199894,-0.199381,1.000000-0.356048,0.537960,-1.000000-0.392868,-0.125261,1.0000000.353588,-0.070617,1.0000000.020984,0.925720,-1.000000-0.475167,-0.346247,-1.0000000.074952,0.042783,1.0000000.394164,-0.058217,1.0000000.663418,0.436525,-1.0000000.402158,0.577744,-1.000000-0.449349,-0.038074,1.0000000.619080,-0.088188,-1.0000000.268066,-0.071621,1.000000-0.015165,0.359326,1.0000000.539368,-0.374972,-1.000000-0.319153,0.629673,-1.0000000.694424,0.641180,-1.0000000.079522,0.193198,1.0000000.253289,-0.285861,1.000000-0.035558,-0.010086,1.000000-0.403483,0.474466,-1.000000-0.034312,0.995685,-1.000000-0.590657,0.438051,-1.000000-0.098871,-0.023953,1.000000-0.250001,0.141621,1.000000-0.012998,0.525985,-1.0000000.153738,0.491531,-1.0000000.388215,-0.656567,-1.0000000.049008,0.013499,1.0000000.068286,0.392741,1.0000000.747800,-0.066630,-1.0000000.004621,-0.042932,1.000000-0.701600,0.190983,-1.0000000.055413,-0.024380,1.0000000.035398,-0.333682,1.0000000.211795,0.024689,1.000000-0.045677,0.172907,1.0000000.595222,0.209570,-1.0000000.229465,0.250409,1.000000-0.089293,0.068198,1.0000000.384300,-0.176570,1.0000000.834912,-0.110321,-1.000000-0.307768,0.503038,-1.000000-0.777063,-0.348066,-1.0000000.017390,0.152441,1.000000-0.293382,-0.139778,1.000000-0.203272,0.286855,1.0000000.957812,-0.152444,-1.0000000.004609,-0.070617,1.000000-0.755431,0.096711,-1.000000-0.526487,0.547282,-1.000000-0.246873,0.833713,-1.0000000.185639,-0.066162,1.0000000.851934,0.456603,-1.000000-0.827912,0.117122,-1.0000000.233512,-0.106274,1.0000000.583671,-0.709033,-1.000000-0.487023,0.625140,-1.000000-0.448939,0.176725,1.0000000.155907,-0.166371,1.0000000.334204,0.381237,-1.0000000.081536,-0.106212,1.0000000.227222,0.527437,-1.0000000.759290,0.330720,-1.0000000.204177,-0.023516,1.0000000.577939,0.403784,-1.000000-0.568534,0.442948,-1.000000-0.011520,0.021165,1.0000000.875720,0.422476,-1.0000000.297885,-0.632874,-1.000000-0.015821,0.031226,1.0000000.541359,-0.205969,-1.000000-0.689946,-0.508674,-1.000000-0.343049,0.841653,-1.0000000.523902,-0.436156,-1.0000000.249281,-0.711840,-1.0000000.193449,0.574598,-1.000000-0.257542,-0.753885,-1.000000-0.021605,0.158080,1.0000000.601559,-0.727041,-1.000000-0.791603,0.095651,-1.000000-0.908298,-0.053376,-1.0000000.122020,0.850966,-1.000000-0.725568,-0.292022,-1.000000 test datafeature1,feature2,label0.676771,-0.486687,-1.0000000.008473,0.186070,1.000000-0.727789,0.594062,-1.0000000.112367,0.287852,1.0000000.383633,-0.038068,1.000000-0.927138,-0.032633,-1.000000-0.842803,-0.423115,-1.000000-0.003677,-0.367338,1.0000000.443211,-0.698469,-1.000000-0.473835,0.005233,1.0000000.616741,0.590841,-1.0000000.557463,-0.373461,-1.000000-0.498535,-0.223231,-1.000000-0.246744,0.276413,1.000000-0.761980,-0.244188,-1.0000000.641594,-0.479861,-1.000000-0.659140,0.529830,-1.000000-0.054873,-0.238900,1.000000-0.089644,-0.244683,1.000000-0.431576,-0.481538,-1.000000-0.099535,0.728679,-1.000000-0.188428,0.156443,1.0000000.267051,0.318101,1.0000000.222114,-0.528887,-1.0000000.030369,0.113317,1.0000000.392321,0.026089,1.0000000.298871,-0.915427,-1.000000-0.034581,-0.133887,1.0000000.405956,0.206980,1.0000000.144902,-0.605762,-1.0000000.274362,-0.401338,1.0000000.397998,-0.780144,-1.0000000.037863,0.155137,1.000000-0.010363,-0.004170,1.0000000.506519,0.486619,-1.0000000.000082,-0.020625,1.0000000.057761,-0.155140,1.0000000.027748,-0.553763,-1.000000-0.413363,-0.746830,-1.0000000.081500,-0.014264,1.0000000.047137,-0.491271,1.000000-0.267459,0.024770,1.000000-0.148288,-0.532471,-1.000000-0.225559,-0.201622,1.0000000.772360,-0.518986,-1.000000-0.440670,0.688739,-1.0000000.329064,-0.095349,1.0000000.970170,-0.010671,-1.000000-0.689447,-0.318722,-1.000000-0.465493,-0.227468,-1.000000-0.049370,0.405711,1.000000-0.166117,0.274807,1.0000000.054483,0.012643,1.0000000.021389,0.076125,1.000000-0.104404,-0.914042,-1.0000000.294487,0.440886,-1.0000000.107915,-0.493703,-1.0000000.076311,0.438860,1.0000000.370593,-0.728737,-1.0000000.409890,0.306851,-1.0000000.285445,0.474399,-1.000000-0.870134,-0.161685,-1.000000-0.654144,-0.675129,-1.0000000.285278,-0.767310,-1.0000000.049548,-0.000907,1.0000000.030014,-0.093265,1.000000-0.128859,0.278865,1.0000000.307463,0.085667,1.0000000.023440,0.298638,1.0000000.053920,0.235344,1.0000000.059675,0.533339,-1.0000000.817125,0.016536,-1.000000-0.108771,0.477254,1.000000-0.118106,0.017284,1.0000000.288339,0.195457,1.0000000.567309,-0.200203,-1.000000-0.202446,0.409387,1.000000-0.330769,-0.240797,1.000000-0.422377,0.480683,-1.000000-0.295269,0.326017,1.0000000.261132,0.046478,1.000000-0.492244,-0.319998,-1.000000-0.384419,0.099170,1.0000000.101882,-0.781145,-1.0000000.234592,-0.383446,1.000000-0.020478,-0.901833,-1.0000000.328449,0.186633,1.000000-0.150059,-0.409158,1.000000-0.155876,-0.843413,-1.000000-0.098134,-0.136786,1.0000000.110575,-0.197205,1.0000000.219021,0.054347,1.0000000.030152,0.251682,1.0000000.033447,-0.122824,1.000000-0.686225,-0.020779,-1.000000-0.911211,-0.262011,-1.0000000.572557,0.377526,-1.000000-0.073647,-0.519163,-1.000000-0.281830,-0.797236,-1.000000-0.555263,0.126232,-1.000000 参考链接：https://blog.csdn.net/csqazwsxedc/article/details/71513197https://blog.csdn.net/zouxy09/article/details/17291543]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从csv中读取数据]]></title>
    <url>%2F2019%2F09%2F08%2F%E4%BB%8Ecsv%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031import csvimport numpy as npdef loadDataSet(filename): # 读取数据 with open(filename) as f: dataMat = [] labelMat = [] f_csv = csv.reader(f) ## 用csv读取直接是个list headers = next(f_csv) for row in f_csv: dataMat.append([float(row[0]), float(row[1])]) labelMat.append(float(row[2])) f.close() return dataMat, labelMatdef loadData(filename): # 读取数据 dataMat=[] labelMat=[] fr=open(filename) next(fr) # 忽略第一行 for line in fr.readlines(): lineArr=line.strip().split(',') dataMat.append([lineArr[0],lineArr[1]]) labelMat.append(lineArr[2]) return dataMat,labelMat # 返回数据特征和数据类别if __name__ == '__main__': dataMat,labelMat = loadData('test_data.csv') print(dataMat,labelMat)]]></content>
      <categories>
        <category>python</category>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制中1的个数]]></title>
    <url>%2F2019%2F09%2F08%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%AD1%E7%9A%84%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：489798本题知识点： 进制转化 补码 反码 原码 题目描述输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 123456789101112class Solution &#123;public: int NumberOf1(int n) &#123; int count=0; while(n!=0) &#123; count++; n = (n-1)&amp;n; &#125; return count; &#125;&#125;; 运行时间：3ms占用内存：356k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCA降维]]></title>
    <url>%2F2019%2F09%2F07%2FPCA%E9%99%8D%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[PCA（principal Component Analysis），主成分分析法。顾名思义，就是提取出数据中主要的成分，是一种数据压缩方法，常用于去除噪声、数据预处理，也是机器学习中常见的降维方法。 步骤 对所有样本进行中心化处理即将每个元素减去它的平均值，这样可以增加基向量的正交性。 计算协方差矩阵及特征值、特征向量 对特征值进行排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# coding:utf-8from matplotlib import pylab as pltimport numpy as npdef read_file(filename): f = open(filename, 'r') d = f.readlines() f.close() return dclass PCA(object): """ 使用PCA对高维数据进行降维处理 """ def __init__(self): data = read_file('data.txt') self.n = len(data) # 数据的个数 self.dim = 4 # 原始数据的维度 self.x = np.zeros((self.n, self.dim), dtype='float64') for i in range(self.n): data_ = data[i].split(',') self.x[i][0] = data_[0] self.x[i][1] = data_[1] self.x[i][2] = data_[2] self.x[i][3] = data_[3] self.k = 2 # 降到二维 self.mean_x = np.zeros((self.n, self.dim), dtype='float64') # 原始数据减去均值以后的x self.mean = np.zeros((self.dim, 1), dtype='float64') # x的均值 self.cov = np.zeros((self.dim, self.dim), dtype='float64') # 协方差矩阵 self.pre_x = np.zeros((self.n, self.dim), dtype='float64') # 预处理之后的数据 self.eig_val = np.zeros((1, self.dim), dtype='float64') # 特征值 self.eig_vec = np.zeros((self.dim, self.dim), dtype='float64') # 特征向量 self.final_x = np.zeros((self.n, self.k), dtype='float64') # 投影后的数据 self.pretreatment() self.pca() def pretreatment(self): """ 预处理 """ # 求均值 for i in range(self.dim): self.mean[i] = np.mean(self.x[:, i]) for i in range(self.n): self.mean_x[i] = self.x[i] - self.mean.T # 求协方差 # self.cov = np.cov(self.mean_x, rowvar=0) # mean_x已经是x减去均值了，所以直接相乘就是方差 self.cov = self.mean_x.T.dot(self.mean_x) / self.n for i in range(self.dim): self.pre_x[:, i] = self.mean_x[:, i] / np.sqrt(self.cov[i][i]) # x的每个维度都处理一次 def pca(self): """ pca的实现 """ # 需要注意的是，在这里需要对预处理之后的数据重新计算协方差 # 计算均值 for i in range(self.dim): self.mean[i] = np.mean(self.pre_x[:, i]) # 计算协方差 for i in range(self.n): self.mean_x[i] = self.pre_x[i] - self.mean.T self.cov = (self.mean_x.T.dot(self.mean_x)) / self.n # 求特征值 self.eig_val, self.eig_vec = np.linalg.eig(np.mat(self.cov)) # eig_vec的列向量是特征向量，所以用eig_v存储特征向量，以便后面排序 eig_v = np.zeros((self.dim, self.dim), dtype='float64') for i in range(self.dim): eig_v[i] = self.eig_vec[:, i].T # 排序 eig_list = zip(self.eig_val, eig_v) sorted(eig_list,key=lambda g: g[0], reverse=True) # 处理排序的结果 for i in range(len(list(eig_list))): self.eig_val[i] = eig_list[i][0] self.eig_vec[i] = eig_list[i][1] # 最大的k个特征向量，降维 f_vec = self.eig_vec[0:self.k, :] self.final_x = self.pre_x * f_vec.T # 显示降维后的数据点 plt.plot(self.final_x[0:50, 0], self.final_x[0:50, 1], 'bo') plt.plot(self.final_x[50:100, 0], self.final_x[50:100, 1], 'go') plt.plot(self.final_x[100:150, 0], self.final_x[100:150, 1], 'ro') plt.show()if __name__ == '__main__': a = PCA() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491505.1,3.5,1.4,0.2,Iris-setosa4.9,3.0,1.4,0.2,Iris-setosa4.7,3.2,1.3,0.2,Iris-setosa4.6,3.1,1.5,0.2,Iris-setosa5.0,3.6,1.4,0.2,Iris-setosa5.4,3.9,1.7,0.4,Iris-setosa4.6,3.4,1.4,0.3,Iris-setosa5.0,3.4,1.5,0.2,Iris-setosa4.4,2.9,1.4,0.2,Iris-setosa4.9,3.1,1.5,0.1,Iris-setosa5.4,3.7,1.5,0.2,Iris-setosa4.8,3.4,1.6,0.2,Iris-setosa4.8,3.0,1.4,0.1,Iris-setosa4.3,3.0,1.1,0.1,Iris-setosa5.8,4.0,1.2,0.2,Iris-setosa5.7,4.4,1.5,0.4,Iris-setosa5.4,3.9,1.3,0.4,Iris-setosa5.1,3.5,1.4,0.3,Iris-setosa5.7,3.8,1.7,0.3,Iris-setosa5.1,3.8,1.5,0.3,Iris-setosa5.4,3.4,1.7,0.2,Iris-setosa5.1,3.7,1.5,0.4,Iris-setosa4.6,3.6,1.0,0.2,Iris-setosa5.1,3.3,1.7,0.5,Iris-setosa4.8,3.4,1.9,0.2,Iris-setosa5.0,3.0,1.6,0.2,Iris-setosa5.0,3.4,1.6,0.4,Iris-setosa5.2,3.5,1.5,0.2,Iris-setosa5.2,3.4,1.4,0.2,Iris-setosa4.7,3.2,1.6,0.2,Iris-setosa4.8,3.1,1.6,0.2,Iris-setosa5.4,3.4,1.5,0.4,Iris-setosa5.2,4.1,1.5,0.1,Iris-setosa5.5,4.2,1.4,0.2,Iris-setosa4.9,3.1,1.5,0.1,Iris-setosa5.0,3.2,1.2,0.2,Iris-setosa5.5,3.5,1.3,0.2,Iris-setosa4.9,3.1,1.5,0.1,Iris-setosa4.4,3.0,1.3,0.2,Iris-setosa5.1,3.4,1.5,0.2,Iris-setosa5.0,3.5,1.3,0.3,Iris-setosa4.5,2.3,1.3,0.3,Iris-setosa4.4,3.2,1.3,0.2,Iris-setosa5.0,3.5,1.6,0.6,Iris-setosa5.1,3.8,1.9,0.4,Iris-setosa4.8,3.0,1.4,0.3,Iris-setosa5.1,3.8,1.6,0.2,Iris-setosa4.6,3.2,1.4,0.2,Iris-setosa5.3,3.7,1.5,0.2,Iris-setosa5.0,3.3,1.4,0.2,Iris-setosa7.0,3.2,4.7,1.4,Iris-versicolor6.4,3.2,4.5,1.5,Iris-versicolor6.9,3.1,4.9,1.5,Iris-versicolor5.5,2.3,4.0,1.3,Iris-versicolor6.5,2.8,4.6,1.5,Iris-versicolor5.7,2.8,4.5,1.3,Iris-versicolor6.3,3.3,4.7,1.6,Iris-versicolor4.9,2.4,3.3,1.0,Iris-versicolor6.6,2.9,4.6,1.3,Iris-versicolor5.2,2.7,3.9,1.4,Iris-versicolor5.0,2.0,3.5,1.0,Iris-versicolor5.9,3.0,4.2,1.5,Iris-versicolor6.0,2.2,4.0,1.0,Iris-versicolor6.1,2.9,4.7,1.4,Iris-versicolor5.6,2.9,3.6,1.3,Iris-versicolor6.7,3.1,4.4,1.4,Iris-versicolor5.6,3.0,4.5,1.5,Iris-versicolor5.8,2.7,4.1,1.0,Iris-versicolor6.2,2.2,4.5,1.5,Iris-versicolor5.6,2.5,3.9,1.1,Iris-versicolor5.9,3.2,4.8,1.8,Iris-versicolor6.1,2.8,4.0,1.3,Iris-versicolor6.3,2.5,4.9,1.5,Iris-versicolor6.1,2.8,4.7,1.2,Iris-versicolor6.4,2.9,4.3,1.3,Iris-versicolor6.6,3.0,4.4,1.4,Iris-versicolor6.8,2.8,4.8,1.4,Iris-versicolor6.7,3.0,5.0,1.7,Iris-versicolor6.0,2.9,4.5,1.5,Iris-versicolor5.7,2.6,3.5,1.0,Iris-versicolor5.5,2.4,3.8,1.1,Iris-versicolor5.5,2.4,3.7,1.0,Iris-versicolor5.8,2.7,3.9,1.2,Iris-versicolor6.0,2.7,5.1,1.6,Iris-versicolor5.4,3.0,4.5,1.5,Iris-versicolor6.0,3.4,4.5,1.6,Iris-versicolor6.7,3.1,4.7,1.5,Iris-versicolor6.3,2.3,4.4,1.3,Iris-versicolor5.6,3.0,4.1,1.3,Iris-versicolor5.5,2.5,4.0,1.3,Iris-versicolor5.5,2.6,4.4,1.2,Iris-versicolor6.1,3.0,4.6,1.4,Iris-versicolor5.8,2.6,4.0,1.2,Iris-versicolor5.0,2.3,3.3,1.0,Iris-versicolor5.6,2.7,4.2,1.3,Iris-versicolor5.7,3.0,4.2,1.2,Iris-versicolor5.7,2.9,4.2,1.3,Iris-versicolor6.2,2.9,4.3,1.3,Iris-versicolor5.1,2.5,3.0,1.1,Iris-versicolor5.7,2.8,4.1,1.3,Iris-versicolor6.3,3.3,6.0,2.5,Iris-virginica5.8,2.7,5.1,1.9,Iris-virginica7.1,3.0,5.9,2.1,Iris-virginica6.3,2.9,5.6,1.8,Iris-virginica6.5,3.0,5.8,2.2,Iris-virginica7.6,3.0,6.6,2.1,Iris-virginica4.9,2.5,4.5,1.7,Iris-virginica7.3,2.9,6.3,1.8,Iris-virginica6.7,2.5,5.8,1.8,Iris-virginica7.2,3.6,6.1,2.5,Iris-virginica6.5,3.2,5.1,2.0,Iris-virginica6.4,2.7,5.3,1.9,Iris-virginica6.8,3.0,5.5,2.1,Iris-virginica5.7,2.5,5.0,2.0,Iris-virginica5.8,2.8,5.1,2.4,Iris-virginica6.4,3.2,5.3,2.3,Iris-virginica6.5,3.0,5.5,1.8,Iris-virginica7.7,3.8,6.7,2.2,Iris-virginica7.7,2.6,6.9,2.3,Iris-virginica6.0,2.2,5.0,1.5,Iris-virginica6.9,3.2,5.7,2.3,Iris-virginica5.6,2.8,4.9,2.0,Iris-virginica7.7,2.8,6.7,2.0,Iris-virginica6.3,2.7,4.9,1.8,Iris-virginica6.7,3.3,5.7,2.1,Iris-virginica7.2,3.2,6.0,1.8,Iris-virginica6.2,2.8,4.8,1.8,Iris-virginica6.1,3.0,4.9,1.8,Iris-virginica6.4,2.8,5.6,2.1,Iris-virginica7.2,3.0,5.8,1.6,Iris-virginica7.4,2.8,6.1,1.9,Iris-virginica7.9,3.8,6.4,2.0,Iris-virginica6.4,2.8,5.6,2.2,Iris-virginica6.3,2.8,5.1,1.5,Iris-virginica6.1,2.6,5.6,1.4,Iris-virginica7.7,3.0,6.1,2.3,Iris-virginica6.3,3.4,5.6,2.4,Iris-virginica6.4,3.1,5.5,1.8,Iris-virginica6.0,3.0,4.8,1.8,Iris-virginica6.9,3.1,5.4,2.1,Iris-virginica6.7,3.1,5.6,2.4,Iris-virginica6.9,3.1,5.1,2.3,Iris-virginica5.8,2.7,5.1,1.9,Iris-virginica6.8,3.2,5.9,2.3,Iris-virginica6.7,3.3,5.7,2.5,Iris-virginica6.7,3.0,5.2,2.3,Iris-virginica6.3,2.5,5.0,1.9,Iris-virginica6.5,3.0,5.2,2.0,Iris-virginica6.2,3.4,5.4,2.3,Iris-virginica5.9,3.0,5.1,1.8,Iris-virginica 参考链接：https://github.com/eva-n27/PCA]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kmeans算法]]></title>
    <url>%2F2019%2F09%2F07%2Fkmeans%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[K-Means的思想十分简单，首先随机指定类中心，根据样本与类中心的远近划分类簇，接着重新计算类中心，迭代直至收敛。但是其中迭代的过程并不是主观地想象得出，事实上，若将样本的类别看做为“隐变量”（latent variable），类中心看作样本的分布参数，这一过程正是通过EM算法的两步走策略而计算出，其根本的目的是为了最小化平方误差函数E。 kmeans算法的最大弱点：只能处理球形的簇（理论）kmeans 计算步骤 1.随机选取K个聚类中心，这里的k值可以自己设定 2.先设置一个聚类标志，用来保存当前的 样本与第几个聚类中心最近 3.计算每个样例与每个聚类中心的距离，保存最小距离的k以及距离 4.更新聚类中心，为当前类别所有样本的均值大小 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192from numpy import *import timeimport matplotlib.pyplot as plt# calculate Euclidean distancedef euclDistance(vector1, vector2): return sqrt(sum(power(vector2 - vector1, 2))) # 求这两个矩阵的距离， vector1, vector2 均为矩阵# init centroids with random samples# 在样本集中随机选取k个样本点作为初始质心def initCentroids(dataSet, k): numSamples, dim = dataSet.shape # 矩阵的行数、列数 centroids = zeros((k, dim)) # 感觉要不要你都可以 for i in range(k): index = int(random.uniform(0, numSamples)) # 随机产生一个浮点数，然后将其转化为int型 centroids[i, :] = dataSet[index, :] return centroids# k-means cluster# dataSet为一个矩阵# k为将dataSet矩阵中的样本分成k个类def kmeans(dataSet, k): numSamples = dataSet.shape[0] # 读取矩阵dataSet的第一维度的长度,即获得有多少个样本数据 # first column stores which cluster this sample belongs to, # second column stores the error between this sample and its centroid clusterAssment = mat(zeros((numSamples, 2))) # 得到一个N*2的零矩阵 clusterChanged = True ## step 1: init centroids centroids = initCentroids(dataSet, k) # 在样本集中随机选取k个样本点作为初始质心 while clusterChanged: clusterChanged = False ## for each sample for i in range(numSamples): # range minDist = 100000.0 minIndex = 0 ## for each centroid ## step 2: find the centroid who is closest # 计算每个样本点与质点之间的距离，将其归内到距离最小的那一簇 for j in range(k): distance = euclDistance(centroids[j, :], dataSet[i, :]) if distance &lt; minDist: minDist = distance minIndex = j ## step 3: update its cluster # k个簇里面与第i个样本距离最小的的标号和距离保存在clusterAssment中 # 若所有的样本不在变化，则退出while循环 if clusterAssment[i, 0] != minIndex: clusterChanged = True clusterAssment[i, :] = minIndex, minDist ** 2 # 两个**表示的是minDist的平方 ## step 4: update centroids for j in range(k): # clusterAssment[:,0].A==j是找出矩阵clusterAssment中第一列元素中等于j的行的下标，返回的是一个以array的列表，第一个array为等于j的下标 pointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]] # 将dataSet矩阵中相对应的样本提取出来 centroids[j, :] = mean(pointsInCluster, axis=0) # 计算标注为j的所有样本的平均值 print('Congratulations, cluster complete!') return centroids, clusterAssment# show your cluster only available with 2-D data# centroids为k个类别，其中保存着每个类别的质心# clusterAssment为样本的标记，第一列为此样本的类别号，第二列为到此类别质心的距离def showCluster(dataSet, k, centroids, clusterAssment): numSamples, dim = dataSet.shape if dim != 2: print("Sorry! I can not draw because the dimension of your data is not 2!") return 1 mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '&lt;r', 'pr'] if k &gt; len(mark): print("Sorry! Your k is too large! please contact wojiushimogui") return 1 # draw all samples for i in range(numSamples): markIndex = int(clusterAssment[i, 0]) # 为样本指定颜色 plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex]) mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '&lt;b', 'pb'] # draw the centroids for i in range(k): plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize=12) plt.show() 123456789101112131415161718192021222324252627from numpy import *import timeimport matplotlib.pyplot as pltimport kmeans## step 1: load dataprint("step 1: load data...")dataSet = [] # 列表，用来表示，列表中的每个元素也是一个二维的列表；这个二维列表就是一个样本，样本中包含有我们的属性值和类别号。# 与我们所熟悉的矩阵类似，最终我们将获得N*2的矩阵，每行元素构成了我们的训练样本的属性值和类别号fileIn = open("./testSet.txt") # 是正斜杠for line in fileIn.readlines(): temp = [] lineArr = line.strip().split('\t') # line.strip()把末尾的'\n'去掉 temp.append(float(lineArr[0])) temp.append(float(lineArr[1])) dataSet.append(temp)# dataSet.append([float(lineArr[0]), float(lineArr[1])])fileIn.close()## step 2: clustering...print("step 2: clustering...")dataSet = mat(dataSet) # mat()函数是Numpy中的库函数，将数组转化为矩阵k = 4centroids, clusterAssment = kmeans.kmeans(dataSet, k) # 调用KMeans文件中定义的kmeans方法。## step 3: show the resultprint("step 3: show the result...")kmeans.showCluster(dataSet, k, centroids, clusterAssment) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879801.658985 4.285136 -3.453687 3.424321 4.838138 1.151539 -5.379713 -3.362104 0.972564 2.924086 -3.567919 1.531611 0.450614 -3.302219 -3.487105 -1.724432 2.668759 1.594842 -3.156485 3.191137 3.165506 -3.999838 -2.786837 -3.099354 4.208187 2.984927 -2.123337 2.943366 0.704199 -0.479481 -0.392370 -3.963704 2.831667 1.574018 -0.790153 3.343144 2.943496 -3.357075 -3.195883 -2.283926 2.336445 2.875106 -1.786345 2.554248 2.190101 -1.906020 -3.403367 -2.778288 1.778124 3.880832 -1.688346 2.230267 2.592976 -2.054368 -4.007257 -3.207066 2.257734 3.387564 -2.679011 0.785119 0.939512 -4.023563 -3.674424 -2.261084 2.046259 2.735279 -3.189470 1.780269 4.372646 -0.822248 -2.579316 -3.497576 1.889034 5.190400 -0.798747 2.185588 2.836520 -2.658556 -3.837877 -3.253815 2.096701 3.886007 -2.709034 2.923887 3.367037 -3.184789 -2.121479 -4.232586 2.329546 3.179764 -3.284816 3.273099 3.091414 -3.815232 -3.762093 -2.432191 3.542056 2.778832 -1.736822 4.241041 2.127073 -2.983680 -4.323818 -3.938116 3.792121 5.135768 -4.786473 3.358547 2.624081 -3.260715 -4.009299 -2.978115 2.493525 1.963710 -2.513661 2.642162 1.864375 -3.176309 -3.171184 -3.572452 2.894220 2.489128 -2.562539 2.884438 3.491078 -3.947487 -2.565729 -2.012114 3.332948 3.983102 -1.616805 3.573188 2.280615 -2.559444 -2.651229 -3.103198 2.321395 3.154987 -1.685703 2.939697 3.031012 -3.620252 -4.599622 -2.185829 4.196223 1.126677 -2.133863 3.093686 4.668892 -2.562705 -2.793241 -2.149706 2.884105 3.043438 -2.967647 2.848696 4.479332 -1.764772 -4.905566 -2.911070 参考链接：https://github.com/wojiushimogui/kmeans]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xml生成]]></title>
    <url>%2F2019%2F09%2F07%2Fxml%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[先创建 root Element, 然后创建 SubElement, 最后将 root 传入 ElementTree(element), 创建 tree, 调用 tree.write() 方法写入文件,创建 XML 类型的数据文件1234567891011121314151617import xml.etree.ElementTree as ETdef subElement(root, tag, text): ele = ET.SubElement(root, tag) ele.text = text ele.tail = '\n'root = ET.Element("note")to = root.makeelement("to", &#123;&#125;)to.text = "peter"to.tail = '\n'root.append(to)subElement(root, "from", "marry")subElement(root, "heading", "Reminder")subElement(root, "body", "Don't forget the meeting!")tree = ET.ElementTree(root)tree.write("note.xml", encoding="utf-8", xml_declaration=True) 1234567&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;note&gt;&lt;to&gt;peter&lt;/to&gt;&lt;from&gt;marry&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Don't forget the meeting!&lt;/body&gt;&lt;/note&gt;]]></content>
      <categories>
        <category>programs</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xml解析]]></title>
    <url>%2F2019%2F09%2F07%2Fxml%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223&lt;annotation&gt; &lt;folder&gt;ILSVRC2015_VID_train_0002/ILSVRC2015_train_00555002&lt;/folder&gt; &lt;filename&gt;000000&lt;/filename&gt; &lt;source&gt; &lt;database&gt;ILSVRC_2015&lt;/database&gt; &lt;/source&gt; &lt;size&gt; &lt;width&gt;1280&lt;/width&gt; &lt;height&gt;720&lt;/height&gt; &lt;/size&gt; &lt;object&gt; &lt;trackid&gt;0&lt;/trackid&gt; &lt;name&gt;n02691156&lt;/name&gt; &lt;bndbox&gt; &lt;xmax&gt;659&lt;/xmax&gt; &lt;xmin&gt;592&lt;/xmin&gt; &lt;ymax&gt;375&lt;/ymax&gt; &lt;ymin&gt;334&lt;/ymin&gt; &lt;/bndbox&gt; &lt;occluded&gt;0&lt;/occluded&gt; &lt;generated&gt;0&lt;/generated&gt; &lt;/object&gt;&lt;/annotation&gt; ElementTree生来就是为了处理XML, 它在Python标准库中有两种实现：一种是纯Python实现的, 如xml.etree.ElementTree, 另一种是速度快一点的xml.etree.cElementTree. 注意：尽量使用C语言实现的那种, 因为它速度更快, 而且消耗的内存更少. a. 遍历根节点的下一层 b. 下标访问各个标签、属性、文本 c. 查找root下的指定标签 d. 遍历XML文件 e. 修改XML文件12345import os, systry: import xml.etree.cElementTree as ETexcept: import xml.etree.ElementTree as ET 解析xml文件12345678xmlFilePath = os.path.abspath('000000.xml')try: tree = ET.parse(xmlFilePath) # 或者 tree = ET.ElementTree(xmlFilePath) root = tree.getroot() # 获取根节点except Exception as e: print('parse xml failed!') sys.exit() 逐层遍历123print(root.tag, root.attrib, root.text)for child in root: print(child.tag, child.attrib, child.text) 递归遍历全部:1234567def traverseXml(element): if len(element) &gt; 0: # 叶节点的len为0 for child in element: print(child.tag, child.attrib) traverseXml(child)traverseXml(root) 根据签名查找需要的标签12345item_lists = root.findall('item') # 只能找到儿子, 不能找到孙子, 返回的是儿子们组成的列表item = root.find('item') # 返回的是单个的儿子print(root)print(item_lists)print(item) 获取叶子节点的值当访问到叶子节点时, 就可以利用 text 来得到相应的标签了1234567891011obj_bbox_set =[]objects = root.findall('object')for obj in objects: obj_name = obj.find('name').text bbox = obj.find('bndbox') x1 = int(bbox.find('xmin').text) y1 = int(bbox.find('ymin').text) x2 = int(bbox.find('xmax').text) y2 = int(bbox.find('ymax').text) obj_bbox_set.append([x1, x2, y1, y2, obj_name])print(obj_bbox_set)]]></content>
      <categories>
        <category>programs</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩形覆盖]]></title>
    <url>%2F2019%2F09%2F07%2F%E7%9F%A9%E5%BD%A2%E8%A6%86%E7%9B%96%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：363840本题知识点： 递归 题目描述我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 12345678class Solution &#123;public: int rectCover(int number) &#123; if(number &lt;= 0) return 0; if(number == 1 || number == 2) return number; return rectCover(number - 1) + rectCover(number - 2); &#125;&#125;; 运行时间：538ms占用内存：484k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mx-maskrcnn环境搭建]]></title>
    <url>%2F2019%2F09%2F06%2Fmx-maskrcnn%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[从https://hub.docker.com/ 选取所需的镜像 下载caffe2 镜像docker pull caffe2/caffe2 :snapshot-py2-cuda8.0-cudnn7-ubuntu16.04Cannot open your terminal ‘/dev/pts/0’错误原因解决可以使用script命令来记录这个终端会话,执行script /dev/nullscreen -S caiusdocker 分配http://www.cnblogs.com/codeaaa/p/9041533.htmlhttps://blog.csdn.net/u013948858/article/details/78429954（有效）docker run -it -v /media/:/media/ —name=mxcaius —runtime=nvidia 89f57a4ade86 /bin/bashdocker ubuntu源卡主，解决措施：mv source改完之后改回去 mv sources.list.d.odd sources.list.d需要BLAS库，可以安装ATLAS、OpenBLAS、MKL，我安装的是atlassudo apt-get install libatlas-base-dev安装opencv库pip install opencv-pythonsudo apt-get install libopencv-dev安装Python包cd python;python setup.py installapt-get install python-numpyodules/imgproc/src/resize.cpp:3596: error: (-215:Assertion failed) func != 0 in function ‘resize’ numpy 1.14setuptools和numpy(sudo apt-get install python-numpy) git clone —recursive https://github.com/apache/incubator-mxnet.git incubator-mxnet —branch 0.11.0cp rcnn/CXX_OP/* incubator-mxnet/src/operator/cd incubator-mxnetmake -j USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1cd ..makebash scripts/train_alternate.shmakecaius@sugon:~$ echo -n “cvlab1205” |md5sumd0599e86d6134fee87bcf017ddca1990 然后我们使用docker ps查看到该容器信息，接下来就使用docker attach进入该容器可形变卷积 IndexError: list index out of range self.class_id = [0, 1] imdb = eval(dataset)(image_set, root_path, dataset_path) [‘train’]imagesetIcdar2015/media/data1/caius/dataset[‘train’]imagesetIcdar2015/media/data1/caius/dataset icdar2015_train gt roidb loaded from model/res50-fpn/icdar2015/alternate/cache/icdar2015_train_gt_roidb.pklOpenCV Error: Assertion failed (func != 0) in resize, file /io/opencv/modules/imgproc/src/imgwarp.cpp, line 3370Traceback (most recent call last): File “train_alternate_mask_fpn.py”, line 118, in main() File “train_alternate_mask_fpn.py”, line 115, in main args.rcnn_epoch, args.rcnn_lr, args.rcnn_lr_step) File “train_alternate_mask_fpn.py”, line 61, in alternate_train vis=False, shuffle=False, thresh=0) File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/tools/test_rpn.py”, line 63, in test_rpn imdb_boxes = generate_proposals(predictor, test_data, imdb, vis=vis, thresh=thresh) File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/core/tester.py”, line 61, in generate_proposals for im_info, data_batch in test_data: File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/core/loader.py”, line 60, in next self.get_batch() File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/core/loader.py”, line 83, in get_batch data, label, im_info = get_rpn_testbatch(roidb) File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/io/rpn.py”, line 32, in get_rpn_testbatch imgs, roidb,masks = get_image(roidb) File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/io/image.py”, line 99, in get_image mask, _ = resize(mask, target_size, max_size) File “/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss/rcnn/io/image.py”, line 138, in resize im = cv2.resize(im, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR)cv2.error: /io/opencv/modules/imgproc/src/imgwarp.cpp:3370: error: (-215) func != 0 in function resize root@d59236d7a683:/media/data1/caius/mx-maskrcnn-original-std-broadcast-2-maskloss/mx-maskrcnn-original-std-broadcast-2-maskloss#]]></content>
      <categories>
        <category>python</category>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker使用笔记]]></title>
    <url>%2F2019%2F09%2F06%2Fdocker%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[0. 查看需要的Docker列表https://hub.docker.com/r/nvidia/cuda/列出已经存在的镜像列表 1. 创建容器(没有镜像, 会自动下载)docker run -it -v /media/data2/dh:/media/data2/dh —name=cloud —runtime=nvidia nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04 /bin/bash(已有镜像)docker run -it -v /media/data2/dh:/media/data2/dh —name=cloud —runtime=nvidia afc5ab1e9a0d /bin/bash 2. 启动容器dockerstart cloud（容器名） 3. 进入容器docker exec -it cloud /bin/bash 4. 离开容器exit 5. 删除容器A. 停止容器docker stop CONTAINER_ID B. 删除容器docker rm CONTAINER_ID 启动 systemctl start docker 守护进程重启 sudo systemctl daemon-reload 重启docker服务 systemctl restart docker 重启docker服务 sudo service docker restart 关闭docker service docker stop 关闭docker systemctl stop docker]]></content>
      <categories>
        <category>其他</category>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[变态跳台阶]]></title>
    <url>%2F2019%2F09%2F06%2F%E5%8F%98%E6%80%81%E8%B7%B3%E5%8F%B0%E9%98%B6%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：396047本题知识点： 递归 题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 解析f(n) = f(n-1)+f(n-2)+…+f(1)f(n-1) = f(n-2)+f(n-3)+…f(1) f(n) = 2*f(n-1) 123456789class Solution &#123;public: int jumpFloorII(int number) &#123; if(number == 1) return 1; else return 2*jumpFloorII(number-1); &#125;&#125;; 运行时间：4ms占用内存：480k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Terminal 手册]]></title>
    <url>%2F2019%2F09%2F05%2Fcmd%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[查看磁盘空间df -hl 查看磁盘剩余空间df -h 查看每个根路径的分区大小 查看文件/文件夹大小查看指定文件/文件夹大小：du -hs &lt;文件名或文件夹名&gt;查看当前文件夹下所有文件大小（包括子文件夹）：du -sh 查看文件数量统计当前目录下文件的个数（不包括目录）ls -l | grep “^-“ | wc -l ls 命令ls -a 显示全部的文件及文件夹，包括隐藏的文件或文件夹ls -l 显示较全的文件信息，包括权限、用户、用户组等。ls —color 显示文件及文件夹，并标有不同的颜色。 tab键tab command 用于当你的命令记不全时，输入一部再按一下进行补全，如果有多个前面部分相同命令，则按两次tab键 cmpcmp /bin/ls /bin/dir 用于比较两个文件是否是完全相同的。 cpcp /bin/ls /bin/a 用于复制文件的命令。这时就复制了一个命令文件，就可以运行a命令，与ls用法相同 cp命令与操作文件一样是用来复制的，带r表示将其子目录一起复制。 mv格式：mv /home/user1/桌面/ruijie/xrgsu /usr/share/local/bin/xrgsu chmod用于改为用户对于文件的操作权限。chmod 0+r 添加读的权限。sudo chmod 0-r filename取消读的权限。 cat cat 命令就是用于查看ubuntu中文本文件的内容的命令。 cat /proc/cpuinfo 用于查看计算机的cpu信息。 cat /proc/meminfo 用于查看计算机的内在信息。 cat /etc/issue 查看ubuntu的版本信息。 查看cuda 版本 cat /usr/local/cuda/version.txt 查看cudnn 版本 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2touch格式：touch test1 test2 test3touch命令用于创建文件，可以同一时间创建多个文件。pwdpwd命令是用来指出当前所在的路径。是print working directory的缩写]]></content>
      <categories>
        <category>其他</category>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跳台阶]]></title>
    <url>%2F2019%2F09%2F05%2F%E8%B7%B3%E5%8F%B0%E9%98%B6%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：489122本题知识点： 递归 题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 1234567891011class Solution &#123;public: int jumpFloor(int number) &#123; if(number == 1) return 1; else if(number==2) return 2; else return jumpFloor(number-1)+jumpFloor(number-2); &#125;&#125;; 运行时间：519 ms占用内存：456K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斐波那契数列]]></title>
    <url>%2F2019%2F09%2F04%2F%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：640784本题知识点： 递归 题目描述大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。n&lt;=39 12345678class Solution &#123;public: int Fibonacci(int n) &#123; if(n &lt;= 0) return 0; if(n==1 || n==2) return 1; return Fibonacci(n-1)+Fibonacci(n-2); &#125;&#125;; 运行时间：694 ms占用内存：484K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[采坑记录]]></title>
    <url>%2F2019%2F09%2F04%2F%E9%87%87%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[os.getcwd()该函数不需要传递参数，它返回当前的目录。需要说明的是，当前目录并不是指脚本所在的目录，而是所运行脚本的目录。就是说如果你在home的终端运行 os.listdir(path)其参数path 为要获得内容目录的路径]]></content>
      <categories>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遍历文件夹图片]]></title>
    <url>%2F2019%2F09%2F03%2F%E9%81%8D%E5%8E%86%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[题目要求要求从下图所示的文件夹遍历子文件夹，并将所在的图片路径保存到txt文件中 代码如下1234567891011121314151617import os, globimport randomroot = '/media/data1/lesson/pokemon/pokeman'f_w = open(os.path.join('../', 'train2.txt'), 'w', encoding='utf8')images = []for name in sorted(os.listdir(os.path.join((root)))): # 获取子文件夹 if not os.path.isdir(os.path.join(root,name)): continue images += glob.glob(os.path.join(root, name, '*.png')) images += glob.glob(os.path.join(root, name, '*.jpg')) images += glob.glob(os.path.join(root, name, '*.jpeg'))random.shuffle(images)for line in images: f_w.write(line + '\n') # f_w.write(line)f_w.close()print('Write Done!') 12345678910111213141516171819202122232425262728293031323334# 咖喱的代码import osimport globimport os.path as osp dataset_dir = os.getcwd() bulbasaur_dir = osp.join(dataset_dir, 'pokeman/bulbasaur') charmander_dir = osp.join(dataset_dir, 'pokeman/charmander') mewtwo_dir = osp.join(dataset_dir, 'pokeman/mewtwo') pikachu_dir = osp.join(dataset_dir, 'pokeman/pikachu') squirtle_dir = osp.join(dataset_dir, 'pokeman/squirtle')def process(dir_path, save_path): img_paths = glob.glob(osp.join(dir_path, '*.jpg')) f= open(save_path, 'w') for img_path in img_paths: f.write(img_path) f.write('\n') f.close()dataset_dir = os.getcwd()bulbasaur_dir = osp.join(dataset_dir, 'pokeman/bulbasaur')charmander_dir = osp.join(dataset_dir, 'pokeman/charmander')mewtwo_dir = osp.join(dataset_dir, 'pokeman/mewtwo')pikachu_dir = osp.join(dataset_dir, 'pokeman/pikachu')squirtle_dir = osp.join(dataset_dir, 'pokeman/squirtle')save_dir = osp.join(dataset_dir, 'imgpath.txt')process(test_dir, save_dir)]]></content>
      <categories>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用两个栈实现队列]]></title>
    <url>%2F2019%2F09%2F02%2F%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：499320本题知识点： 队列 栈 题目描述用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。 123456789101112131415161718192021222324252627class Solution&#123;public: void push(int node) &#123; while(!stack2.empty())//入队时要保证 Stack2为空 &#123; stack1.push(stack2.top()); stack2.pop(); &#125; stack1.push(node); &#125; int pop() &#123; while(!stack1.empty())//入队时要保证 Stack1为空 &#123; stack2.push(stack1.top()); stack1.pop(); &#125; int temp = stack2.top(); stack2.pop(); return temp; &#125;private: stack&lt;int&gt; stack1; stack&lt;int&gt; stack2;&#125;; 运行时间：3ms占用内存：460K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从尾到头打印链表]]></title>
    <url>%2F2019%2F08%2F29%2F%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：1022710本题知识点： 链表 题目描述输入一个链表，按链表从尾到头的顺序返回一个ArrayList。 123456789101112131415161718192021222324252627/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; value; ListNode *p=NULL; p=head; stack&lt;int&gt; stk; while(p!=NULL)&#123; stk.push(p-&gt;val); p=p-&gt;next; &#125; while(!stk.empty())&#123; value.push_back(stk.top()); stk.pop(); &#125; return value; &#125; &#125;; 运行时间：3ms占用内存：480K]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[透视变换]]></title>
    <url>%2F2019%2F08%2F29%2F%E9%80%8F%E8%A7%86%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[替换空格]]></title>
    <url>%2F2019%2F08%2F29%2F%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：1142927本题知识点： 字符串 题目描述请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123;public: void replaceSpace(char *str,int length) &#123; if(str==NULL) return ; int CountOfBlanks=0; int Originallength=0; for(int i=0;str[i]!='\0';i++) &#123; Originallength++; if(str[i]==' ') ++CountOfBlanks; &#125; int len =Originallength+2*CountOfBlanks; if(len+1&gt;length) return ; /* int pOrignallength=orignallength; int pNewlength=newlength; while(pOrignallength&gt;=0 &amp;&amp; pNewlength&gt;pOrignallength) &#123; if(str[pOrignallength]==' ') &#123; str[pNewlength--]='0'; str[pNewlength--]='2'; str[pNewlength--]='%'; &#125; else &#123; str[pNewlength--]=str[pOrignallength]; &#125; pOrignallength--; &#125; */ char*pStr1=str+Originallength;//复制结束符‘\0’ char*pStr2=str+len; while(pStr1&lt;pStr2) &#123; if(*pStr1==' ') &#123; *pStr2--='0'; *pStr2--='2'; *pStr2--='%'; &#125; else &#123; *pStr2--=*pStr1; &#125; --pStr1; &#125; &#125;&#125;;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从上往下打印二叉树]]></title>
    <url>%2F2019%2F08%2F28%2F%E4%BB%8E%E4%B8%8A%E5%BE%80%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[时间限制：1秒 空间限制：32768K 热度指数：420679本题知识点： 队列 树 题目描述从上往下打印出二叉树的每个节点，同层节点从左至右打印。 123456789101112131415161718192021222324252627282930/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;int&gt; PrintFromTopToBottom(TreeNode* root) &#123; //队列是先进先出 queue&lt;TreeNode*&gt; que; vector&lt;int&gt; vec; que.push(root);//先将整个二叉树放入队列 while(!que.empty()) //当队列非空进行循环 &#123; TreeNode* p; p = que.front();//先读取队列的首元素 que.pop();//弹出队列的首元素 if(p == NULL) continue;//所有元素存入vec后，由于队列中存放着空指针，依然进入循环，但此时p的值为NULL，不执行下面的操作，跳出循环结束 que.push(p-&gt;left); que.push(p-&gt;right); vec.push_back(p-&gt;val); &#125; return vec; &#125;&#125;; 运行时间：3ms占用内存：464k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch trick]]></title>
    <url>%2F2019%2F08%2F28%2FPytorch-trick%2F</url>
    <content type="text"><![CDATA[目录： 指定GPU编号 查看模型每层输出详情 梯度裁剪 扩展单张图片维度 独热编码 防止验证模型时爆显存 学习率衰减 冻结某些层的参数 对不同层使用不同学习率 1. 指定GPU编号 设置当前使用的GPU设备仅为0号设备，设备名称为 /gpu:0：os.environ[“CUDA_VISIBLE_DEVICES”] = “0” 设置当前使用的GPU设备为0,1号两个设备，名称依次为 /gpu:0、/gpu:1： os.environ[“CUDA_VISIBLE_DEVICES”] = “0,1” ，根据顺序表示优先使用0号设备,然后使用1号设备。指定GPU的命令需要放在和神经网络相关的一系列操作的前面。 2.查看模型每层输出详情Keras有一个简洁的API来查看模型的每一层输出尺寸，这在调试网络时非常有用。现在在PyTorch中也可以实现这个功能。 使用很简单，如下用法：12from torchsummary import summarysummary(your_model, input_size=(channels, H, W)) input_size 是根据你自己的网络模型的输入尺寸进行设置。 3.梯度裁剪（Gradient Clipping）12345678import torch.nn as nnoutputs = model(data)loss= loss_fn(outputs, target)optimizer.zero_grad()loss.backward()nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)optimizer.step() nn.utils.clip_grad_norm_ 的参数： parameters – 一个基于变量的迭代器，会进行梯度归一化 max_norm – 梯度的最大范数 max_norm – 梯度的最大范数知乎用户 不椭的椭圆 提出：梯度裁剪在某些任务上会额外消耗大量的计算时间，可移步评论区查看详情。 4、扩展单张图片维度因为在训练时的数据维度一般都是 (batch_size, c, h, w)，而在测试时只输入一张图片，所以需要扩展维度，扩展维度有多个方法：12345678910111213import cv2import torchimage = cv2.imread(img_path)image = torch.tensor(image)print(image.size())img = image.view(1, *image.size())print(img.size())# output:# torch.Size([h, w, c])# torch.Size([1, h, w, c]) 或者1234567891011import cv2import numpy as npimage = cv2.imread(img_path)print(image.shape)img = image[np.newaxis, :, :, :]print(img.shape)# output:# (h, w, c)# (1, h, w, c) 或者1234567891011121314151617import cv2import torchimage = cv2.imread(img_path)image = torch.tensor(image)print(image.size())img = image.unsqueeze(dim=0) print(img.size())img = img.squeeze(dim=0)print(img.size())# output:# torch.Size([(h, w, c)])# torch.Size([1, h, w, c])# torch.Size([h, w, c]) tensor.unsqueeze(dim)：扩展维度，dim指定扩展哪个维度。 tensor.squeeze(dim)：去除dim指定的且size为1的维度，维度大于1时，squeeze()不起作用，不指定dim时，去除所有size为1的维度。 5.独热编码在PyTorch中使用交叉熵损失函数的时候会自动把label转化成onehot，所以不用手动转化，而使用MSE需要手动转化成onehot编码。1234567891011121314151617181920212223import torchclass_num = 8batch_size = 4def one_hot(label): """ 将一维列表转换为独热编码 """ label = label.resize_(batch_size, 1) m_zeros = torch.zeros(batch_size, class_num) # 从 value 中取值，然后根据 dim 和 index 给相应位置赋值 onehot = m_zeros.scatter_(1, label, 1) # (dim,index,value) return onehot.numpy() # Tensor -&gt; Numpylabel = torch.LongTensor(batch_size).random_() % class_num # 对随机数取余print(one_hot(label))# output:[[0. 0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0. 0.]] 6. 防止验证模型时爆显存 验证模型时不需要求导，即不需要梯度计算，关闭autograd，可以提高速度，节约内存。如果不关闭可能会爆显存。123with torch.no_grad(): # 使用model进行预测的代码 pass 感谢知乎用户zhaz 的提醒，我把 torch.cuda.empty_cache() 的使用原因更新一下。 这是原回答： Pytorch 训练时无用的临时变量可能会越来越多，导致 out of memory ，可以使用下面语句来清理这些不需要的变量。 官网 上的解释为： Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible innvidia-smi.torch.cuda.empty_cache() 意思就是PyTorch的缓存分配器会事先分配一些固定的显存，即使实际上tensors并没有使用完这些显存，这些显存也不能被其他应用使用。这个分配过程由第一次CUDA内存访问触发的。 而 torch.cuda.empty_cache() 的作用就是释放缓存分配器当前持有的且未占用的缓存显存，以便这些显存可以被其他GPU应用程序中使用，并且通过 nvidia-smi命令可见。注意使用此命令不会释放tensors占用的显存。 对于不用的数据变量，Pytorch 可以自动进行回收从而释放相应的显存。 7. 学习率衰减1234567891011import torch.optim as optimfrom torch.optim import lr_scheduler# 训练前的初始化optimizer = optim.Adam(net.parameters(), lr=0.001)scheduler = lr_scheduler.StepLR(optimizer, 10, 0.1) # # 每过10个epoch，学习率乘以0.1# 训练过程中for n in n_epoch: scheduler.step() ... 8. 冻结某些层的参数在加载预训练模型的时候，我们有时想冻结前面几层，使其参数在训练过程中不发生变化。 我们需要先知道每一层的名字，通过如下代码打印：123net = Network() # 获取自定义网络结构for name, value in net.named_parameters(): print('name: &#123;0&#125;, grad: &#123;1&#125;'.format(name, value.requires_grad)) 假设前几层信息如下：12345678name: cnn.VGG_16.convolution1_1.weight, grad: Truename: cnn.VGG_16.convolution1_1.bias, grad: Truename: cnn.VGG_16.convolution1_2.weight, grad: Truename: cnn.VGG_16.convolution1_2.bias, grad: Truename: cnn.VGG_16.convolution2_1.weight, grad: Truename: cnn.VGG_16.convolution2_1.bias, grad: Truename: cnn.VGG_16.convolution2_2.weight, grad: Truename: cnn.VGG_16.convolution2_2.bias, grad: True 后面的True表示该层的参数可训练，然后我们定义一个要冻结的层的列表：123456no_grad = [ 'cnn.VGG_16.convolution1_1.weight', 'cnn.VGG_16.convolution1_1.bias', 'cnn.VGG_16.convolution1_2.weight', 'cnn.VGG_16.convolution1_2.bias'] 冻结方法如下：123456net = Net.CTPN() # 获取网络结构for name, value in net.named_parameters(): if name in no_grad: value.requires_grad = False else: value.requires_grad = True 冻结后我们再打印每层的信息：12345678name: cnn.VGG_16.convolution1_1.weight, grad: Falsename: cnn.VGG_16.convolution1_1.bias, grad: Falsename: cnn.VGG_16.convolution1_2.weight, grad: Falsename: cnn.VGG_16.convolution1_2.bias, grad: Falsename: cnn.VGG_16.convolution2_1.weight, grad: Truename: cnn.VGG_16.convolution2_1.bias, grad: Truename: cnn.VGG_16.convolution2_2.weight, grad: Truename: cnn.VGG_16.convolution2_2.bias, grad: True 可以看到前两层的weight和bias的requires_grad都为False，表示它们不可训练。最后在定义优化器时，只对requires_grad为True的层的参数进行更新。1optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01) 9. 对不同层使用不同学习率我们对模型的不同层使用不同的学习率。 还是使用这个模型作为例子：12345678910111213net = Network() # 获取自定义网络结构for name, value in net.named_parameters(): print('name: &#123;&#125;'.format(name))# 输出：# name: cnn.VGG_16.convolution1_1.weight# name: cnn.VGG_16.convolution1_1.bias# name: cnn.VGG_16.convolution1_2.weight# name: cnn.VGG_16.convolution1_2.bias# name: cnn.VGG_16.convolution2_1.weight# name: cnn.VGG_16.convolution2_1.bias# name: cnn.VGG_16.convolution2_2.weight# name: cnn.VGG_16.convolution2_2.bias 对 convolution1 和 convolution2 设置不同的学习率，首先将它们分开，即放到不同的列表里：1234567891011121314151617conv1_params = []conv2_params = []for name, parms in net.named_parameters(): if "convolution1" in name: conv1_params += [parms] else: conv2_params += [parms]# 然后在优化器中进行如下操作：optimizer = optim.Adam( [ &#123;"params": conv1_params, 'lr': 0.01&#125;, &#123;"params": conv2_params, 'lr': 0.001&#125;, ], weight_decay=1e-3,) 我们将模型划分为两部分，存放到一个列表里，每部分就对应上面的一个字典，在字典里设置不同的学习率。当这两部分有相同的其他参数时，就将该参数放到列表外面作为全局参数，如上面的weight_decay。 也可以在列表外设置一个全局学习率，当各部分字典里设置了局部学习率时，就使用该学习率，否则就使用列表外的全局学习率。 显示训练时间123456for epoch in range(start_epoch, config.epochs): start = time.time() train_loss, lr = train_epoch(model, optimizer, scheduler, train_loader, device, criterion, epoch, all_step, writer, logger) logger.info('[&#123;&#125;/&#123;&#125;], train_loss: &#123;:.4f&#125;, time: &#123;:.4f&#125;, lr: &#123;&#125;'.format( epoch, config.epochs, train_loss, time.time() - start, lr)) 参考：https://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&amp;mid=2247485953&amp;idx=2&amp;sn=3ae788b7d643541254ba311f7a7faced&amp;chksm=fd16fb1eca61720870bc58c1a465a346cf2c6a7e8bea39e4b3d582474b595021f3a5b635086d&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1566885137387&amp;sharer_shareid=285785c5623899db73795495779fe8be#rd]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch手册]]></title>
    <url>%2F2019%2F08%2F28%2FPytorch%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[PyTorch 主要提供以下两大特色： 支持强力GPU加速的Tensor计算能力 基于tape的具有自动微分求导能力的深度神经网络框架 PyTorch 主要包含以下组成要素: 组成要素 描述说明 torch 一个类似于numpy的tensor哭, 提供强力的GPU支持 torch.autograd 一个基于tape的具有自动微分求导能力的库, 可以支持几乎所有的tesnor operatioin torch.nn 一个神经网络库, 与autograd深度整合, 可以提供最大限度的灵活性 torch.multiprocessing Python的多线程处理, 可以提供torch Tensors之间的内存共享, 对于加载数据和Hogwild training来说十分有用 torch.utils 一些功能类和函数, 如DataLoader, Trainer等等 torch.legacy(.nn/.optim) 为了兼容性而存在的一些代码和实现 Pytorch通常可以作为以下用途使用: 为了使用GPUs性能的numpy替代品 可以提供强大灵活力和速度优势的深度学习平台.torchbackends.cudnn1torch.backends.cudnn.benchmark = True 上述设置可以让内置的cudnn的auto-tuner自动寻找最合适当前配置的搞笑算法, 来达到优化运行效率的目标, 在使用时, 应该遵循以下两个准则: 如果网络的输入数据维度或类型上变化不大, 则该设置可以增加运行效率 如果网络的输入数据在每次的iteration中都变化的话, 会导致cudnn每次都寻找一遍最优配置, 这样反而 会降低 运行效率.torch.cat()1torch.cat(seq, dim=0, out=None) # 返回连接后的tensor 将给定的 tensor 序列 seq 按照维度连接起来. 默认维度为0, 说明会将其在第 0 个维度上进行拼接.(最后的结果是第 0 维度增大, 例如三个2行3列的 tensor 按照第0维度拼接, 最后得到的 tensor 维度为6行3列) clamp()/clamp_()1torch.clamp(input, min, max, out=None) -&gt; Tensor 将input里面元素全部划分到[min,max]区间内, 小于min的置为min, 大于max的置为max. 如果不指定min或者max,则认为无下界或上界其他调用形式:1torch.Tensor(min, max) # 调用tensor为input, 返回值为out device()1device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") gather()1torch.gather(input, dim, index, out=None) -&gt; Tensor 沿着dim指定的轴按着index指定的值重新组合成一个新的tensor.123out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 即假设input是一个 n 维的tensor, 其 size 为 (x0,x1,…,xi−1,xi,xi+1,…,xn−1), 若dim=i, 则 index 必须也是一个 n 维的tensor, 其 size 为 (x0,x1,…,xi−1,y,xi+1,…,xn−1), 其中 y≥1, 而返回的 tensor out 的 size 和 index 的 size 相同.一句来说 gather 的作用就是, 在指定的维度上筛选给给定下标index指示的值, 其他值舍弃.一个例子说明:scores是一个计算出来的分数，类型为[torch.FloatTensor of size 5x1000]而y_var是正确分数的索引，类型为[torch.LongTensor of size 5]容易知道，这里有1000个类别，有5个输入图像，每个图像得出的分数中只有一个是正确的，正确的索引就在y_var中，这里要做的是将正确分数根据索引标号提取出来。12scores = model(X_var) # 分数scores = scores.gather(1, y_var.view(-1, 1)).squeeze() #进行提取 提取后的scores格式也为[torch.FloatTensor of size 5]这里讲一下变化过程： 首先要知道之前的scores的size为[5,1000]，而y_var的size为[5]，scores为2维，y_var为1维不匹配，所以先用view将其展开为[5,1]的size，这样维数n就与scroes匹配了。 接下来进行gather，gather函数中第一个参数为1，意思是在第二维进行汇聚，也就是说通过y_var中的五个值来在scroes中第二维的5个1000中进行一一挑选，挑选出来后的size也为[5,1]，然后再通过squeeze将那个一维去掉，最后结果为[5]. Tensor形式1torch.Tensor.gather(dim, index) -&gt; Tensor torch.ge()torch.gt()1torch.gt(input, other, out=None) # -&gt; Tensor 根据 input 和 other 的值返回一个二值 tensor, 如果满足大于条件则为1, 不满足则为0.other 可以是能够转换成 input size 的tensor, 也可以是一个 float 标量. torch.index_select()1torch.index_select(input, dim, index, out=None) # -&gt; Tensor 返回在 dim 维度上的 index 指明的下标组成的 tensor.返回的 tensor 的维度的数量和 input 是相同的, 但是第 dim 维度的 size 会和 index size大小相同. 其他维度的 size 保持不变. torch.le()1torch.le(input, other, out=None) # -&gt;Tensor 按元素计算 input≤other. max()123torch.max(input) # 返回一个Tensor, 代表所有元素中的最大值torch.max(input,dim,keepdim=False,out=None) # 返回一个元组:(Tensor, LongTensor) 第二种形式会返回一个元组, 元组内元素类型为: (Tensor, LongTensor), 其中, 前者代表对应 dim 上 reduce 后的最大值, 后者代表最大值在维度 dim 中对应的下标.如果keepdim=True, 则输出的 tensor 的 size 会和输入的相同, 只不过对应 dim 维度上的size为1. 否则, 对应 dim 维度会被 squeeze/reduce, 使得输出的维度比输入的维度少1.12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]])&gt;&gt;&gt; torch.max(a, 1)(tensor([ 0.8475, 1.1949, 1.5717, 1.0036]), tensor([ 3, 0, 0, 1])) mm()注意, 没有torch.mm_版本1torch.mm(mat1, mat2, out=None) # 返回值为Tensor, 也可以使用out记录返回值 两矩阵相乘, 矩阵的size需要满足乘法规则其他调用形式:1torch.Tensor(mat2) # 调用者为mat1 norm()返回输入tensor的p-norm标量1torch.norm(input, p=2) # 返回一个标量tensor numel()1torch.numel(input) #返回一个int值 返回 inpput tensor 中的元素的总个数12a = torch.randn(1,2,3,4,5)print(torch.numel(a)) # 120 ones()randn()标准正太分布随机基础, 传入参数为维度信息 torch.sort()1torch.sort(input, dim=None, descending=False, out=None) # 返回 (Tensor, LongTensor) sum()1234torch.sum(input, dtype=None) # 返回求和后的Tensor(只有一个元素)torch.sum(input, dim, keepdim=False, dtype=None) # 返回在dim上reduce的sum和, 如果dim包含多个维度, 则都进行reduce求和.# reduce这个词很形象, 因为返回的Tensor的维度刚好没有了dim指示的那些维度 其他形式:1torch.Tensor.sum() torch.t()1torch.t(input) # 返回转置后的Tensor 其他形式:1torch.Tensor.t() unsqueeze()在指定维度上插入一个 singleton 维度(一般用于将单一数据处理用 batch 的形式)1torch.unsqueeze(input, dim, out=None) # -&gt; Tensor 返回的tensor与input tensor 共享数据 dim 的取值范围在 [-input.dim()-1, input.dim()+1] 之间, 如果为负值, 则相当于 dim = dim + input.dim() + 1. zeros()torch.cudatorch.cuda.empty_cache()释放所有未使用的 GPU 内存, 使用这些内存可以被其他 GPU 应用使用, 并且可以被 nvidia-smi 查到.empty_cache() 并不会强制提升供 PyTorch 使用的显卡内存的大小, 查看Memory management torch.Tensortorch.Tensor 是默认类型 torch.FloatTensor 的别名, 使用 torch.Tenosr 的构造函数创建 tensor 变量时, 传入的是维度信息(注意与 torch.tensor() 的区别):12t = torch.Tensor(2,3,4) # 里面的数值未初始化, 是随机的print(t.size()) # torch.Size([2,3,4]) torch.LongTesnor 使用方法相似, 只不过数据类型是长整型. troch.tensor()创建tensor1torch.tensor(data, dtype=None, device=None, requires_grad=False) 可以利用torch.tensor从python的list数据或者其他序列数据中创建tensor对象12torch.tensor([[1,-1],[1,-1]])torch.tensor(np.array([[1,2,3],[4,5,6]])) 注意, torch.tensor()函数总是会对数据进行复制操作, 因此, 如果你仅仅是想将数据的requires_grad标志改变, 那么就应该使用required_grad_()或者detach()函数来避免复制. 同时, 对numpy数组使用torch.as_tensor()将其转换成tensor而无需复制 torch.Tensor.cpu()12torch.Tensor.cpu()z = x.cpu() 将tensor移动到cpu上, 注意返回值z是cpu上的数据, tensor x 本身的device属性不变 torch.Tensor.cuda()12torch.Tensor.cuda()z = x.cuda() torch.Tensor.dim()1torch.Tensor.dim() -&gt; int 返回 tensor 的维度的个数. torch.Tensor.max()1torch.Tensor.max(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor) 详情见 torch.max() torch.Tensor.numel()1torch.Tensor.numel() 详见 torch.numel() torch.Tensor.to()1torch.Tensor.to(*args, *kwargs) 返回一个转移后的tensor, 而自身维持不变1234t = torch.randn(2,3)t.to(torch.float64)t.to(device)t.to("cuda:0") 将tensor移动到gpu上, 注意返回值 z 是gpu 上的数据, tensor x 本身的 device 属性不变 torch.Tensor.numpy()tensor与numpy数组的转换123torch.Tensor.numpy() # 返回tensor对应的numpy数组torch.from_numpy(ndarray) # 将numpy数组ndarray转换成对应的tensor并返回. torch.Tensor 实际上是 torch.FloatFensor 的别名 torch.Tensor.permute()重新排列tensor的维度1torch.Tensor.permute(*dims) # 返回一个重新排列维度后的 tensor torch.Tensor.unsqueeze()详细可见torch.unsqueeze torch.Tensor.expand()1torch.Tensor.expand(*sizes) # 返回 tensor 将 tensor 中的 singleton 维度扩展到一个更大的 size.参数 -1 意味着不改变原始的维度新增的维度的元素被被添加到前头, size不能设置为-1.expand 并没有申请新的内存, 而仅仅是在当前已经存在的 tensor 上面创建了新的视图(view), 使得 singleton 维度被扩展成了一个更大的尺寸.Any dimension of size 1 can be expanded to an arbitrary value without new memory.1234x = torch.tensor([1],[2],[3])print(x.size()) # torch.Size([3,1])print(x.expand(3,4)) # torch.Size([3,4]) # 将维度为1的扩展到任意尺寸print(x.expand(-1,4)) # torch.Size([3,4]) # -1 代表不改变维度 注意, 只能对 singleton 的维度进行扩展, 如果强行对其他维度扩展, 则会报错. torch.Tensor.expand_as()1torch.Tensor.expand_as(other) # 返回 tensor 将当前 tensor 扩展到和 other 一样的size.self.expand_as(other) 与 self.expand(other.size()) 等价. torch.Tensor.index_fill_()1torch.Tensor.index_fill_(dim, index, val) # 返回tensor 在给定的维度 dim 上, 用 val 将该维度上的 index 坐标的值填充.1234567x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)index = torch.tensor([0, 2])x.index_fill_(1, index, -1)print(x)#tensor([[-1., 2., -1.],# [-1., 5., -1.],# [-1., 8., -1.]]) torch.Tensor.contiguous()返回一个连续的tensor, 数据内容不变1torch.Tensor.contiguous() # 如果tensor本身就是连续的, 那么就会返回tensor本身 这里的 contiguous 指的是内存上的连续, 由于在 PyTorch 中, view 只能用在 contiguous 的 tensor 上面, 而如果在 view 之前使用了 transpose, permute 等操作后, 就需要使用 contiguous 来返回一个 contiguous tensor.在 PyTorch 0.4 版本以后, 增加了 torch.reshape(), 这与 numpy.reshape() 的功能类似, 它大致相当于 tensor.contiguous().view() ? torch.Tensor.item()当Tensor中只包含一个元素时, 可以利用该函数返回这个元素的标量 torch.Tensor.tolist()可以将Tensor转换成列表 torch.Tensor.zero_()1torch.Tensor.zero_() 将当前的 tensor 变量全部置为0(原地) torch.autogradset_grad_enabled()1class torch.autograd.set_grad_enabled(mode) 用来控制梯度计算的开关(依据bool类型参数mode决定), 可以当做上下文管理器使用, 也可以当做函数使用1234567891011# 当做上下文管理器with torch.set_grad_enabled(is_train): # 注意, 这里省略了autograd loss.backward() optimizer.step()# 当做函数使用w1 = torch.Tensor([1], requires=True)torch.set_grad_enabled(True)print(w1.requires_grad) # Truetorch.set_grad_enabled(False)print(w1.requires_grad) # False no_grad()1class torch.autograd.no_grad 用于禁用梯度计算的上下文管理器.在测试阶段, 当你确信你不会调用Tensor.backward()时,禁用梯度计算十分有用. 这会降低计算使用内存消耗.123456x = torch.tensor([1.0], requires_grad=True)with torch.no_grad(): # 省略了autograd print(x.requires_grad) # True, 虽然为True, 但在该上下文中, 会无视掉requires_grad参数, 一律做False处理 y = x*2 print(y.requires_grad) # False, 在当前上下文产生的tensor的requires_grad属性为Falseprint(x.requires_grad) # True torch.autograd.Function1class torch.autograd.Function 为可微分的 ops 记录 operation history, 同时定义计算公式. 每一个作用在 tensor 上的 operatin 都会创建一个新的 function 对象, 它会执行计算过程并记录相关信息. 这些信息可以从一个由 functions 组成的有向图中获得. 当 backward() 方法被调用时, 就会利用这些信息在 function 上进行反向传播, 并将梯度传给下一个 Funtion.通常情况下, 当用于需要自定义可自动求导的 ops 时, 可以实现一个 Function 的子类. 123456789101112# Exampleclass Exp(Function): @staticmethod def forward(ctx, i): result = i.exp() ctx.save_for_backward(result) @staticmethod def backward(ctx, grad_output): result, = ctx.saved_tensors return grad_output*result static forward(ctx, args, kwargs):*定义前向计算的逻辑. static backward(ctx, *grad_outputs):定义反向传导的逻辑, 如果确定不会使用到反向传播, 则可以不实现该函数. torch.nnModule1class torch.nn.Module 所有神经网络Module的基类, 自定义的模型也应该是它的子类.Modules可以包含其他Module(如Linear, Conv2d等等). parameters()12for param in model.parameters(): print(param.data, param.size()) state_dict:1torch.nn.Module.state_dict(destination=None,prefix="",keep_vars=False) 以字典形式返回整个module的状态 train1torch.nn.Module.train(mode=True) 将module的模式设置为train, 这只对部分module有效, 如Dropout, BatchNorm等, 详细请查看官网.返回值: torch.nn.Module training1torch.nn.Module.training # 属性, 返回一个bool值, 指示当前的模式是否为train eval1torch.nn.Module.eval() # 注意, 和train不同, eval为无参函数 将module的mode设置为evaluation, 同样, 只对部分module起效. Linear1torch.nn.Linear(in_features, out_features, bias=True) 全连接层的实现. 输入的shape为 (N,…,infeatures), 输出的shape为 (N,…,outfeatures), 可以看出, 除了最后一维不同外, 其他维度都相同. (通常在使用Linear之前, 会将输入变成二维的矩阵, 其中第一维为batch size, 第二维为特征向量).in_features 和 out_features 可以当做属性用.来获取. Conv2d1class torch.nn.Conv2的(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) in_channels(int): out_channels(int): kernel_size(intortuple): stride(intortuple, optional):MaxPool2dSoftmax()1class torch.nn.Softmax(dim=None) dim指明了需要进行 softmax 的维度, 在这个维度上的值, 加起来和为1. ReLU1torch.nn.ReLU(inplace=False) 输入输出的shape是相同的, 执行relu函数 torch.nn.Sequential1class torch.nn.Sequential(*args) torch.nn.MSELoss1class torch.nn.MSELoss(size_average=None, reduce=None, reduction="elementwise_mean") size_average(bool, optional): 弃用(见reduction参数). 默认情况下, loss会计算在每个样本上的平均误差. 如果将size_average置为False, 则计算平方误差总和. 当reduce参数为False时, 忽视该参数 reduce(bool, optional): 弃用(见reduction参数). reduce参数顾名思义, 就是是否让MSELoss函数返回值的维度减少, 默认为True, 即会将任意维度的输入计算loss后, 返回一个标量(平均or总和取决于size_average), 如果为False, 则说明返回值维度不应该发生变化, 故而返回值就是对每个元素单独进行平方损失计算. 12345678910y = torch.tensor([1,2,3,4], dtype=torch.float)pred_y = torch.tensor([1,1,1,1], dtype=torch.float)loss_fn1 = torch.nn.MSELoss()loss1 = loss_fn1(y, pred_y)loss_fn2 = torch.nn.MSELoss(size_average=False)loss2 = loss_fn2(y, pred_y)loss_fn3 = torch.nn.MSELoss(reduce=False)loss3 = loss_fn3(y, pred_y)print(loss1,loss2,loss3)# tensor(3.5000) tensor(14.) tensor([0., 1., 4., 9.]) reduction(string, optional): 用字符串来替代上面两个参数的作用: “elementwise_mean”(默认) | “sum” | “none” (不进行reduce). torch.nn.functionalconv1d()conv2d()relu()1torch.nn.functional.relu(input, inplace=True) # 返回 一个 Tenosr relu_()1torch.nn.functional.relu_(input) # relu() 的原地版本 torch.optimlr_schedulerStepLR1class torch.optim.lr_schedulr.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1) 每经过step_size次epoch之后, lr就会衰减gamma倍(new_lr=lr×gamma), 初始的lr来自于optimizer中的lr参数.12345# Observe that all parameters are being optimizedoptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)# Decay LR by a factor of 0.1 every 7 epochsexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) ExponentialLR1class torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma,last_epoch=-1) CosineAnnealingLR12## Adamclass torch.optim.Adam(params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False) conv2dtorch.utils.dataDataLoader1class torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,batch_sampler=None,num_workers=0,collate_fn=&lt;function default_collate&gt;,pin_memory=False,drop_last=False,timeout=0,worker_init_fn=None) 数据加载器, 将数据集和采样器结合起来, 并且提供单/多线程的迭代器. dataset(utils.data.Dataset): batch_size(int,optional): batch中的样本个数 shuffle(bool,optional) num_worker(int,optional): 加载数据的线程个数, 0意味着只有一个主线程.方法： iter(self): 可以当做迭代器使用, 如inputs,class_ids=next(iter(dataloaders)), 其中, input的shape为 (N,C,H,W), class_ids的shape为 (N). len(self): 返回数据集的类别数目 torchvisiontorchvision.utilsmake_grid1torchvision.utils.make_grid(tensor,nrow=8,padding=2,normalize=False,range=None,scale_each=False,pad_value=0) 制作一个关于image的grid, 返回值依然是一个tensor, 只不过尺度变成了3D, 相当于把多个图片拼接在一起了, 直接通过plt.imshow(grid)即可输出网格化以后的图片. tensor(Tensor/list): 4D的 mini-batch Tensor, Shape为 (N×C×H×W), 或者是同维度的list.torchvision.transformstorchvision.transforms.Compose1234567class torchvision.transforms.Compose(transforms)# 使用trans.Compose([ transforms.CenterCrop(10), transforms.ToTensor(),]) 将多个transforms操作组合起来, 注意参数是列表形式 Transforms on PIL Image123# cv2 image to PIL Image# skimage to PIL Image 注意, 以下操作作用在PIL Image上的 CenterCrop1class torchvision.transform.CenterCrop(size) size参数表示输出的图谱的大小, 如果只传入了一个数字, 则该数字既表示高度, 又表示宽度. Resize1class torchvision.transforms.Resize(size, interpolation=2) size: 期望的输出size. interpolation: 插值方法, 默认为双线性插值ToTensor1class torchvision.transforms.ToTensor 将一个PIL Image或者numpy.ndarray (H×W×C,[0, 255])转换成torch.FloatTensor (C×H×W, [0.0, 1.0]). RandomHorizontalFlip1transforms.RandomHorizontalFlip(p=0.5) 在给定概率下对PIL Image随机执行水平翻转操作 RandomResizedCrop1torch.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333), interpolation=2) 对PIL Image随机执行剪裁操作(按照scale和ratio的区间剪裁), 然后将剪裁后的图片放缩都期望的尺寸(默认插值为双线性插值) size: 期望得到的尺寸 scale: 剪裁的面积比例(相对于原始图) ratio: 剪裁的宽高比 interpolation: 默认为:PIL.Image.BILINEARTransforms on torch.*Tensor注意, 以下操作是作用在tensor上的Normalize1class torchvision.transforms.Normalize(mean, std) 将图片tensor按照均值mean和标准差std进行归一化, 对于n个channels, 有 mean=(M1, …, Mn), std=(S1,…,Sn).注意, 这个归一化操作是原地进行的 torchvision.datasetsImageFolder1class torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=&lt;function default_loader&gt;) 一个一般化的数据加载器, 主要针对如下数据排列格式:1234567root/dog/x.pngroot/dog/y.pngroot/dog/z.png...root/cat/123.pngroot/cat/nsdf3.pngroot/cat/asd932_.png root: 根目录路径 transform(callable,optional): 对图片要做的变换操作 target_transform(callable,optional): 对target要做的变换操作 loader: 用于加载给定路径图片的函数属性： classes(list): 返回类别的名字列表 class_names class_to_idx(dict): 以字典的形式返回(class_name, class_index) imgs(list): 返回元组列表: (image path, class_index)方法： getitem(index): 根据index返回(sample,target)元组. 可以使用 len(imagefolder) 返回类别数量 sort()1sort(dim=None, descending=False) # 默认为升序, 返回(Tensor, LongTensor) 详见 torch.sort() torch.distributedtorch.distributed.reduce()inspect 模块1234inspect.signature() # 查看函数签名, python3.6以上inspect.getargspec() # 查看函数签名, python3.6以上inspect.getsource() # 获取模型的codeinspect.getabsfile() # 获取模块的路径 un normalize1234567mean = torch.tensor([1, 2, 3], dtype=torch.float32)std = torch.tensor([2, 2, 2], dtype=torch.float32)normalize = T.Normalize(mean.tolist(), std.tolist())unnormalize = T.Normalize((-mean / std).tolist(), (1.0 / std).tolist())​~~~s]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy实现神经网络]]></title>
    <url>%2F2019%2F08%2F28%2Fnumpy%E5%AE%9E%E7%8E%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637import numpy as np# N 为batch size, D_in 为输入维度# H 为隐藏层的维度, D_out 为输出的维度N, D_in, H, D_out = 64, 1000, 100, 10# 创建随机的输入和输出数据x = np.random.randn(N, D_in) # N × D_in 的矩阵y = np.random.randn(N, D_out) # N × D_out 的矩阵# 对两个隐藏层w1,w2进行初始化w1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)# 设置学习率learning_rate = 1e-6for t in range(500): # 前向传播: 计算预测结果 y_pred h = x.dot(w1) # x维度为64 × 1000, w1维度为 1000 × 100, 计算完以后, h维度为 64 × 100 h_relu = np.maximum(h,0) y_pred = h_relu.dot(w2) # h_relu维度为 64×100, w2维度为100×10, y的维度为64×10 # 计算损失 loss = np.square(y_pred - y).sum() print(t, loss) # 反向传播根据loss更新w1和w2的值 grad_y_pred = 2.0*(y_pred - y) # 对y_pred求导 grad_w2 = h_relu.T.dot(grad_y_pred) # 对w2求导, 微分矩阵应该与w2的size相同 grad_h_relu = grad_y_pred.dot(w2.T) # 对h_relu求导 grad_h = grad_h_relu.copy() grad_h[h &lt; 0] = 0 # 经过relu, 将小于0的梯度归0 grad_w1 = x.T.dot(grad_h) # Update weights w1 = w1 - learning_rate * grad_w1 w2 = w2 - learning_rate * grad_w2]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[glob模块]]></title>
    <url>%2F2019%2F08%2F28%2Fglob%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[glob模块是Python最简单的模块之一, 内容非常少, 用它可以查找符合特定规则的文件路径名, 查找文件时只会用到三个匹配符: * : 匹配0个或多个字符 ? : 匹配单个字符 [] : 匹配指定范围内的字符, 如[0-9]匹配数字 glob.glob()参数:_(str): 文件路径的正则表达式 返回值:_(list): 符合正则表达式的文件路径列表 备注:返回所有匹配的文件路径列表, 它只有一个参数pathname, 定义了文件路径匹配的规则, 这里可以是绝对路径或者相对路径:123456import globpathes_list = glob.glob("~/Pictures/*.jpg")# 获取Pictures下的所有图片relative_pathes_list = glob.glob("../*.py")# 获取上级目录中的所有.py文件 在 linux, osx 系统中, 通配符的匹配是大小写区分的, 也就是需要特别指定大小写:1extensions = ['jpg', 'JPG', 'jpeg', 'JPEG'] 但是在 windows 当中, 通配符的匹配是不区分大小写的, 因此只需要指定大小写中的一个即可, 两个都指定的话, 会出现重复的情况1extensions = ['jpg', 'jpeg'] glob.iglob获取一个可遍历的对象, 使用它可以逐个获取匹配的文件路径名. 与glob.glob()的区别是: glob.glob()会同时获取到所有的匹配路径, 而glob.iglob()一次只获取一个匹配路径.1234f = glob.iglob("../*.py")print f # &lt;generator object iglob at 0x00B9FF80&gt;for py in f: print(py)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logging模块]]></title>
    <url>%2F2019%2F08%2F28%2Flogging%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[简单使用1234567import logginglogging.debug("debug msg")logging.info("info msg")logging.warn("warn msg")logging.error("error msg")logging.critical("critical msg") 默认情况下, logging模块将日志打印到屏幕上, 只有日志级别高于WARNING的日志信息才回输出]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shutil模块]]></title>
    <url>%2F2019%2F08%2F28%2Fshutil%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[1234567shutil.copyfile("old","new") # 复制文件，都只能是文件shutil.copytree("old","new") # 复制文件夹，都只能是目录，且new必须不存在shutil.copy("old","new") # 复制文件/文件夹，复制 old 为 new（new是文件，若不存在，即新建），复制 old 为至 new 文件夹（文件夹已存在）shutil.move("old","new") # 移动文件/文件夹至 new 文件夹中]]></content>
      <categories>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PIL模块]]></title>
    <url>%2F2019%2F08%2F28%2FPIL%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[导入1from PIL import Image 读取1img = Image.open(filepath) 显示1img.show() 与 numpy 数组的互相转换PIL Image 转 numpy 数组1img_to_array = np.array(img) numpy 数组转 PIL Image (注意要确保数组内的值符合 PIL 的要求)1array_to_img = Image.fromarray(img_to_array) PIL 与 cv2 格式互相转换PIL.Image读入的图片数据类型不是 numpy 数组, 它的size属性为 (w, h), 利用np.array转换成 numpy 数组后, 它的通道顺序为 (r, g, b)1234567891011from PIL import Imageimport numpy as np# PIL to cv2pil_img = Image.open(img_path)print(pil_img.size) # (w, h)np_img = np.array(pil_img)cv2_img = np_img[:, :, ::-1] # 交换通道# cv2 to PILpil_img = Image.fromarray(cv2_img[:, :, ::-1])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[skimage模块]]></title>
    <url>%2F2019%2F08%2F28%2Fskimage%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[比opencv的速度要慢很多, 但是使用起来更加简单, 真的对速度要求很高的话, 一般都会C++和opecv使用. 所以一般情况下, 首先看skimage能否实现, 不行的话再转用opencv123import skimagefrom skimage import io # IO is a submodule. Submodules need to be imported from the parent module explicitly.img = io.imread("1.jpg")]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv模块]]></title>
    <url>%2F2019%2F08%2F28%2Fopencv%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[opencv 基础知识cv2.imread 读入的图片, 其shape为(h, w, c), 颜色通道顺序为 (b, g, r) 常用颜色读取图片1img = cv2.imread(img_path) 保存图片1cv2.imwrite(save_path, img) 文本(startX, startY) 为左上角坐标1cv2.putText(img, "text test", (startX, startY), cv2.FONT_HERSHEY_SIMPLEX, font_size, (B,G,R), thickness) 画框(x,y) 为左上角坐标(x+h,y+w) 为右下角坐标1cv2.rectangle(img,(x,y), (x+h,y+w), (0,255,0), thickness) waitKey()12345keypress = cv2.waitKey(200) # 200为当前图片的显示持续时间if keypress == ord('c') # keypress为按键的整数形式, 所以需要用ord将字符类型转换if cv2.waitKey(200) == 27: # Decimal 27 = Esc opencv与numpyopencv的基础类型为numpy.ndarray, 因此可以直接使用 ndarray 的一些属性的方法1234import cv2img = cv2.imread('./test.jpg')print(type(img)) # &lt;class 'numpy.ndarray'&gt;print(img.shape) # (500, 1069, 3) (高, 宽, 通道) 利用 cv2.merge 方法将 numpy.ndarray 数据转换成opencv的图片数据:12345678910# 图片的分辨率为300*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 300), dtype=np.uint8)g = np.random.randint(0, 255, (200, 300), dtype=np.uint8)r = np.random.randint(0, 255, (200, 300), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test') 通道的拆分与合并拆分: cv2.split合并: cv2.merge123456789101112# 图片的分辨率为800*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 800), dtype=np.uint8)g = np.random.randint(0, 255, (200, 800), dtype=np.uint8)r = np.random.randint(0, 255, (200, 800), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test')# 拆分通道, 每个通道都变成了单通道数组[blue, green, red] = cv2.split(img) 将 BGR 转换成 RGB 通道顺序12345# 方法一:rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)# 方法二:rgb_img = img[:, :, [2, 1, 0]] # img[h,w,v]rgb_img = img[:, :, ::-1] PIL 与 cv2 格式互相转换PIL.Image读入的图片数据类型不是 numpy 数组, 它的size属性为 (w, h), 利用np.array转换成 numpy 数组后, 它的通道顺序为 (r, g, b)1234567891011from PIL import Imageimport numpy as np# PIL to cv2pil_img = Image.open(img_path)print(pil_img.size) # (w, h)np_img = np.array(pil_img)cv2_img = np_img[:, :, ::-1] # 交换通道# cv2 to PILpil_img = Image.fromarray(cv2_img[:, :, ::-1]) 用matplotlib显示图像1234b,g,r=cv2.split(img)img2=cv2.merge([r,g,b])plt.imshow(img2)plt.show() 截取子图12# 已知子图左上角坐标 (x1, y1), 右下角坐标(x2, y2)crop_img = img[y1:y2, x1:x2, :] opencv 核心算法cv212345678910111213141516import cv2image_path = './test.jpg'src_image = cv2.imread(image_path) # 读取图片size = src_image.shape # 获取图片的尺寸, 返回一个元组: (height, width, depth)copy_image = src_image.copy() # 复制图片cv2.imwrite('./dst_test.jpg', copy_image) # 保存图片cv2.imshow('image', src_image) # 显示图片# 利用下标访问指定像素for x in range(src_image.shape[0]): # 以行为主, 行数=图片height for y in range(src_image.shape[1]): # 列数 = 图片width src_image[x,y] = (255,0,255) # (blue, green, red) 值越高表示对应颜色越显著, 全0为黑, 全255为白]]></content>
      <categories>
        <category>opencv</category>
        <category>python</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python手册]]></title>
    <url>%2F2019%2F08%2F28%2Fpython%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[最近在学习查找资料的过程之中，看到了大佬的博客，觉得写得很好，也是我现在所欠缺的，所以下面先对大佬的博客进行复现。以供自己日后复习，查找，完善成自己的东西。 字符串固定字数，不足的空格补齐12345str.ljust(10) # 左对齐 字符串长10位rjust，ljust和center三个方法来给字符串补全空格rjust，向右对其，在左边补空格ljust，向左对其，在右边补空格center，让字符串居中，在左右补空格 排序sorted: 返回一个新的 listlist.sort(): 改变 list 自身的值reverse 参数: 默认为 False, 升序, True 时变为降序 列表循环删除列表元素常见错误: 直接删除, 或者正序删除 正确做法: 1.使用 pop, 倒序删除12for i in range(len(list)): list.pop() 2.使用切片, 遍历拷贝列表, 操作原始列表, 用 remove 删除, remove 会操作首个遇到的匹配元素, 相等元素删除, 删除哪个都一样 12345for x in enumerate(a[::]): a.remove(x)for x in enumerate(a[::-1]): a.remove(x) 遍历列表:123456789101112131415161718192021222324252627zz_list = ['a', 'b', 'c', 'd']for index in list: print(index) # 0 # 1 # 2 # 3for index in range(len(list)): print(index) # 0 # 1 # 2 # 3for index, val in enumerate(list): print(index, val) # 0 a # 1 b # 2 c # 3 d# 设置遍历的开始序号, val的输出不变for i, val in enumerate(list, 2): print(index, val) # 2 a # 3 b # 4 c # 5 d append() 方法追加单个元素 extend() 方法extend()函数用于在列表末尾一次性追加另一个序列中的多个值(用新列表扩展原来的列表).该方法没有返回值, 会直接在已经存在的列表中添加新的列表内容, extend和+=的作用差不多12345a= [[1,2,3],[4,5,6]]b= [['a','b','c'],['d','e','f']]a.extend(b)print(a)# [[1, 2, 3], [4, 5, 6], ['a', 'b', 'c'], ['d', 'e', 'f']] 序列切片(双冒号)Python序列切片地址可以写为 [开始(包含) : 结束(不包含) : 步长]. 当开始省略的时候, 默认从第0项开始, 当结尾省略的时候, 默认到数组最后, 当步长省略的时候, 默认为1. 步长可以为负数, 代表从右向左取数.123456a = range(10) # a = [0, 1, 2, 3, 4, 5, 6, 7, 8 ,9]a[0:9:1] # [0, 1, 2, 3, 4, 5, 6, 7, 8] 包含开始下标, 不包含结束下标a[1::2] # [1, 3, 5, 7, 9]a[::3] # [0, 3, 6, 9]a[::-1] # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]a[::-2] # [9, 7, 5, 3, 1] update() 方法1dict.update(dict2) 将 dict2 中的键值更新到 dict 中, 对于存在的则覆盖原值, 对于不存在的则添加新的键值. 实例1234567#!/usr/bin/pythondict = &#123;'Name': 'Zara', 'Age': 7&#125;dict2 = &#123;'Sex': 'female' &#125;dict.update(dict2)print "Value : %s" % dict 以上实例输出结果为：1Value : &#123;'Age': 7, 'Name': 'Zara', 'Sex': 'female'&#125; 字典遍历字典:1zz_dict = &#123;'x': 1, 'y':2, 'z':3&#125; 遍历keys:123456789# 输出均为: x y zfor key in zz_dict: print(key)for key in zz_dict.iterkeys(): print(key)for key in zz_dict.keys(): print(key) 遍历values:123456# 输出均为 1 2 3for value in zz_dict.itervalues(): print(value)for value in zz_dict.values(): print(value) 遍历keys和values123456# 输出为: x corresponds to 1 (其余两个也一样)for key, value in zz_dict.iteritems(): # python3 没有iteritems print(key, "corresponds to", value)for key, value in zz_dict.items(): print(key, "corresponds to", value) 字符串判断字符串是否为字母或者数字str.isalnum() 字母或数字str.isalpha() 字母str.isdigit() 数字str.isspace() 空白符, \t, \n, \r isdigit() 和 isnumeric() 的区别123456789101112131415161718192021222324num = "1" #unicodenum.isdigit() # Truenum.isdecimal() # Truenum.isnumeric() # Truenum = "1" # 全角num.isdigit() # Truenum.isdecimal() # Truenum.isnumeric() # Truenum = b"1" # bytenum.isdigit() # Truenum.isdecimal() # AttributeError 'bytes' object has no attribute 'isdecimal'num.isnumeric() # AttributeError 'bytes' object has no attribute 'isnumeric'num = "IV" # 罗马数字num.isdigit() # Truenum.isdecimal() # Falsenum.isnumeric() # Truenum = "四" # 汉字num.isdigit() # Falsenum.isdecimal() # Falsenum.isnumeric() # True isdigit()True: Unicode数字，byte数字（单字节），全角数字（双字节），罗马数字False: 汉字数字Error: 无 isdecimal()True: Unicode数字，，全角数字（双字节）False: 罗马数字，汉字数字Error: byte数字（单字节） isnumeric()True: Unicode数字，全角数字（双字节），罗马数字，汉字数字False: 无Error: byte数字（单字节） str.rstrip()参数:chars: 指定删除的字符(默认为空格或换行符) 返回值:返回删除指定字符后的新字符串 备注:删除字符串末尾的指定字符(默认为空格或换行符)1str.rstrip([chars]) str.strip()参数chars — 移除字符串头尾指定的字符序列。返回值返回移除字符串头尾指定的字符生成的新字符串。备注:1str.strip([chars]) str.split()参数 str — 分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。 num — 分割次数。默认为 -1, 即分隔所有。返回值 返回分割后的字符串列表。1str.split(str="", num=string.count(str)). 文件reduce() 函数reduce() 函数会对参数序列中元素进行累积。函数将一个数据集合（链表，元组等）中的所有数据进行下列操作：用传给 reduce 中的函数 function（有两个参数）先对集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据用 function 函数运算，最后得到一个结果。reduce() 函数语法：1reduce(function, iterable[, initializer]) 参数 function — 函数，有两个参数 iterable — 可迭代对象 initializer — 可选，初始参数返回值 返回函数计算结果实例1234567&gt;&gt;&gt;def add(x, y) : # 两数相加... return x + y... &gt;&gt;&gt; reduce(add, [1,2,3,4,5]) # 计算列表和：1+2+3+4+515&gt;&gt;&gt; reduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数15 zip() 函数zip() 函数用于将可迭代的对象作为参数, 将对象中对应的元素打包成一个个 元组 ,然后返回有这些元组组成的 对象. ( 相比于python2中返回列表的方式, 这样做的好处是节约了不少的内存 )可以用list()转换或者dict()转换将对象转换成相应的数据类型如果各个迭代器的元素个数不一致, 则返回列表长度与最短的对象相同, 多出来的部分会被舍弃, 利用*号操作符, 可以将元组解压成列表.123456789101112131415161718192021a = [1,2,3]b = [4,5,6]c = ['a','b','c','d','e','f']zip_ab = zip(a,b)print(zip_ab) # &lt;zip object at 0x104605348&gt;print(dict(zip_ab)) # &#123;1: 4, 2: 5, 3: 6&#125;# !!!注意, 一旦将zip_ab转换成dict以后, zip_ab内部就为空了!! 例如, 再次调用上面的语句:print(dict(zip_ab)) # &#123;&#125;# 但是zip_ab对象本身不会消失, 地址仍然不变print(zip_ab) # &lt;zip object at 0x104605348&gt;zip_abc = zip(a,b,c) # 注意, 三个元素的zip是不能转换成dict类型的print(zip_abc) # &lt;zip object at 0x1046054c8&gt;print(list(zip_abc)) # [(1, 4, 'a'), (2, 5, 'b'), (3, 6, 'c')]zip_abc = zip(a,b,c)z_a, z_b, z_c = zip(*zip_abc) # 利用zip(*)可以将zip对象重新解压, 返回类型是元组print(z_a) # (1,2,3)print(z_b) # (4,5,6)print(z_c) # ('a','b','c') getattr() 函数getattr()函数用于返回一个对象的属性值, 语法如下1getattr(object, name[, default]) 参数： object: 对象 name: 字符串, 对象属性 default: 默认返回值, 如果不提供该参数, 在没有对应属性时, 将触发Attributerror实例12345678910111213&gt;&gt;&gt;class A(object):... bar = 1... &gt;&gt;&gt; a = A()&gt;&gt;&gt; getattr(a, 'bar') # 获取属性 bar 值1&gt;&gt;&gt; getattr(a, 'bar2') # 属性 bar2 不存在，触发异常Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'A' object has no attribute 'bar2'&gt;&gt;&gt; getattr(a, 'bar2', 3) # 属性 bar2 不存在，但设置了默认值3&gt;&gt;&gt; dir() 函数可以查看某个类的所有方法和属性1members = [attr for attr in dir(classA)] _var: 在一个模块中以单下划线开头的变量和函数会被默认当做内部函数, 在使用from a_module import * 导入时, 这部分变量和函数不会被导入. 不过如果使用import a_module导入模块时, 仍然可以用a_module._var的形式访问该变量或函数 var_: 有时候, 一个变量的最适合的名称已经被另一个关键字所占用. 在这种情况下, 可以在名称的末尾附加一个下划线来解决冲突. __var: 双下划线前缀会导致Python解释器重写属性名称, 以避免子类中的命名冲突. 举例来说, 如果在class Test中有一个成员__x, 那么当利用内置函数dir(Test)来查看类的属性时, 会发现__x被解释器重命名为_Test__x. 双下划线的名称修饰同样也适用于方法名称. __var__: 双下划线开头和结尾的是一些 Python 的特殊对象, 如类成员的 __init__, __del__, __name__, __call__ 等. Python 官方推荐永远不要讲这样的命名方式应用于自己的变量或函数. 有一种说法是说双下划线建议为类的私有成员, 但是 PEP8 当前的官方版本中并没有明说. _: 有时候我们会用一个独立的下划线作为一个名字, 这通常是用来指示某个变量时临时的或者无关紧要的.类的特殊方法call()在 Python 中, 函数实际上也是一个对象:123f = absprint(f.__name__) # 'abs'print(f(-123)) # 123 从上面可以看出, 函数是一个对象, 当它赋给另一个变量时, 该变量也是一个函数对象, 可以起到与原函数相同的效果. 在 Python 中, 一个类实例也可以变成一个可调用对象, 只需要实现一个特殊方法 __call__() 即可. 下面我们举例把 Person 类变成一个可调用对象:123456789class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender def __call__(self, friend): print(&quot;name:&quot;, self.name) print(&quot;friend:&quot;, friend) 接下来我们就可以将 Person 类的实例对象当做一个函数来使用, 如下所示:1234p = Person('Bob', 'male')p('Tim')# name: Bob# friend: Tim getitem()凡是在类中定义了 __getitem__() 方法, 那么它的实例对象就是可以通过 [] 操作符来访问指定的成员或进行特定的行为, 大多数情况下会将该方法实现成通过索引来方法元素的形式.1234567class DataBase(object): def __init__(self): super(DataBase, self).__init__() self.vals = [1,2,3,4,5] def __getitem__(self, key): return self.vals[key] setitem()使得可以通过 A[3] = 4, B[“a”] = 5 等方式来对类中的元素进行赋值 file()查看模块的路径 len()使得类对象可以使用 Python 的内建方法 len(), 返回你自定义的数值.123456789101112131415class DictDemo: def __init__(self,key,value): self.dict = &#123;&#125; self.dict[key] = value def __getitem__(self,key): return self.dict[key] def __setitem__(self,key,value): self.dict[key] = value def __len__(self): return len(self.dict)dictDemo = DictDemo('key0','value0')print(dictDemo['key0']) #value0dictDemo['key1'] = 'value1'print(dictDemo['key1']) #value1print(len(dictDemo)) #2 repr()1234567891011121314151617181920212223242526272829303132333435363738class Test(object): def __init__(self, value='hello, world!'): self.data = value&gt;&gt;&gt; t = Test()&gt;&gt;&gt; t&lt;__main__.Test at 0x7fa91c307190&gt;&gt;&gt;&gt; print t&lt;__main__.Test object at 0x7fa91c307190&gt;# 看到了么？上面打印类对象并不是很友好，显示的是对象的内存地址# 下面我们重构下该类的__repr__以及__str__，看看它们俩有啥区别# 重构__repr__class TestRepr(Test): def __repr__(self): return 'TestRepr(%s)' % self.data&gt;&gt;&gt; tr = TestRepr()&gt;&gt;&gt; trTestRepr(hello, world!)&gt;&gt;&gt; print trTestRepr(hello, world!)# 重构__repr__方法后，不管直接输出对象还是通过print打印的信息都按我们__repr__方法中定义的格式进行显示了# 重构__str__calss TestStr(Test): def __str__(self): return '[Value: %s]' % self.data&gt;&gt;&gt; ts = TestStr()&gt;&gt;&gt; ts&lt;__main__.TestStr at 0x7fa91c314e50&gt;&gt;&gt;&gt; print ts[Value: hello, world!]# 你会发现，直接输出对象ts时并没有按我们__str__方法中定义的格式进行输出，而用print输出的信息却改变了 str()参见 repr() 代码示例 星号 **: 乘法**: 乘幂 用于函数参数单星号: 将所有参数以 元组(tuple) 的形式导入123456def foo(param1, *param2): print(param1) print(param2)foo(1,2,3,4,5)# 1# (2,3,4,5) 双星号: 将所有参数以 字典 的形式导入123456def bar(param1, **param2): print(param1) print(param2)bar(1, a=2, b=3)# 1# &#123;'a': 2, 'b': 3&#125; 当然这两个用法可以同时出现在一个函数中:12345678910def fun(a, b=10, *args, **kwargs): print(a) print(b) print(args) print(kwargs)fun(1,2,3,4,e=5,f=6)# 1# 2# (3,4)# &#123;'e': 5, 'f': 6&#125; globals() 函数该函数会以字典类型返回当前位置的全部全局变量 stripe()readlines()lambda 函数3.6新功能 f string包的导入机制模块和包的定义模块(module): 用来从逻辑上组织 Python 代码(变量, 函数, 类), 通常是一个.py文件.包(package): 定义了一个由模块和子包组成的 Python 应用程序执行环境, 本质上就是一个有层次的文件目录结果(必须带有一个__init__.py文件) import 的搜索路径 在当前目录下搜索 在环境变量PYTHONPATH中指定的路径列表中搜索 在 Python 安装路径的lib库中搜索Python 所有加载的模型信息都存放在sys.modules结构中, 当import一个模块时, 会按如下步骤来进行: 如果import A, 检查sys.modules中是否已经有A, 如果有则不加载, 如果没有则为A创建module对象, 并加载A; 如果是from A import B, 先为A创建module对象, 再解析A(此时会加载并执行A中的所有代码), 从中寻找B并填充到A的__dict__中.在导入模块的时候, 模块所在文件夹会自动生成一个__pycache__/module_name.cpython-35.pyc的文件.1234import module_name的本质是将module_name.py中的全部代码加载到内存中, 并将其赋值给与模块同名的变量, 这个变量的类型是class&lt;module&gt;.from module_name import name的本质是将指定的变量或者方法导入到当前的文件中import package_name的本质是执行该包下的__init__.py文件, 在执行文件后, 会在package_name目录下生成一个__pycache__/__init__cpython-35.pyc文件.from package_name import *的本质是导入__init__.py文件中的__all__列表(eg. __all__ = [&apos;L2Norm&apos;, &apos;MultiBoxLoss&apos;]). 相对导入和绝对导入绝对导入:12import A.Bfrom A import B 相对导入:12from . import B # . 代表当前路径from ..A import B # .. 代表上层路径, ... 代表上上层路径. 在没有明确指定包结构的情况下, Python 是根据__name__来决定一个模块在包中的结构的, 如果是__main__, 则它本身就是顶层模块, 没有包结构, 如果是A.B.C结构, 则A是顶层模块. Python 的导入方式的不同具有不同的规则: 1.如果是绝对导入, 一个模块只能导入自身的子模块或者和它的顶层模块同级别的模块及其子模块.2.如果是相对导入, 一个模块必须有包结构且只能导入它的顶层模块内部的模块. 如果一个模块被直接运行, 则它自己为顶层模块, 不存在层次结构, 所以也找不到上层(..)的相对路径Python2.x 默认为相对路径导入, 而 Python3.x 默认为绝对路径导入, 这样可以避免导入的子包覆盖掉标准库模块. 通常, 在 Python2.x 中, 我们利用下面的语句来使其导入规则遵循 Python3.x1from __future__ import absolute_import absolute_import的意思并不是将所有的导入都视为绝对导入, 而是指禁用隐式相对导入(implicit relative import), 关于隐式的显示的具体区别, 可以看下面的例子, 假设有如下的包结构:1234567891011121314thing└── __init__.py├── books│ ├── __init__.py│ ├── adventure.py│ ├── history.py│ ├── horror.py│ └── lovestory.py├── furniture│ ├── __init__.py│ ├── armchair.py│ ├── bench.py│ ├── screen.py│ └── stool.py 那么如果想在stool.py中导入bench模块, 则有如下几种方式:123import bench # 隐式相对导入from . import bench # 显式相对导入from furniture import bench # 绝对导入 隐式相对导入没有告诉解释器相对于谁进行导入, 默认相对于当前模块; 而显式相对导入则明确告诉了解释器相对于谁来导入. 以上导入方式的第三种是官方推荐的, 第一种是官方强烈不推荐的, Python3 中第一种导入方式只能用于导入sys.path中的模块.**注意, 还有相对导入的模块不能被直接运行, 会提示如下错误:1234Traceback (most recent call last): File &quot;test.py&quot;, line 8, in &lt;module&gt; from .ssd import SSDModuleNotFoundError: No module named &apos;__main__.ssd&apos;; &apos;__main__&apos; is not a package 另外存在一种情况就是: 假如有两个模块a.py和b.py放在同一个目录下, 则可以直接在a.py中使用import b来导入模块b. 这是为什么呢? 我们上面说了在 Python3.x 中不能使用这种隐式相对导入, 但是这里却可以成功导入, 这是因为此时我们是直接运行a.py, 所以a.py和b.py的目录没有被当做一个包来处理, 因此不涉及相对导入和绝对导入的概念. 因此相对导入和绝对导入仅仅是针对于包而言的. 综合距离存在目录结构如下所示:123456789101112dirRoot└── __init__.py├── file1.py├── file2.py├── dirA│ ├── __init__.py│ ├── a1.py│ └── a2.py├── dirB│ ├── __init__.py│ ├── b1.py│ └── b2.py 直接运行a1.py, 并希望导入a2模块:1234# a1.pyimport a2 # 正确, 此时并未将 dirA 当做包来处理, a1.py 和 a2.py 相当于两个独立的模块from a2 import func_a2 # 正确from .a2 import func_a2 # 错误, 当进行相对导入时, 不能直接运行 直接运行file1.py, 并希望导入a1模块, 同时a1模块中需要导入a2模块:12345678910# file1.pyfrom dirA import a1a1.func_a1() # a1.py 中的函数a1.func_a2() # a1.py 中导入了 a2.py 的函数, 可以直接使用# a1.pyimport a2 # 错误, 此时由于 dirA 中有 __init__.py 文件, 因此会将 dirA 当做包来处理,# 由于 Python3.x 不允许使用隐式的相对导入, 因此该语句非法from a2 import func_a2 # 错误, 原因同上from .a2 import func_a2 # 正确, 当进行相对导入时, 需要使用显式的相对导入 直接运行file1.py, 并希望导入a1模块, 同时a1模块中需要导入dirB/b1模块(跨文件夹导入):12345678910# file1.pyfrom dirA import a1a1.func_a1() # a1.py 中的函数a1.func_a2() # a2.py 中的函数a1.func_b1() # b1.py 中的函数# a1.pyfrom .a2 import func_a2 # 推荐使用绝对导入 from dirA.a1 import func_a2from dirB import b1 # 由于运行的是 file1.py 文件, 因此顶层目录是 dirRootfrom dirB.b1 import func_b1 # 所以可以直接使用 dirB 包 直接运行a1.py, 并希望跨目录的导入dirB/b1模块. 由于这种跨目录的导入超越了顶层路径的限制, 因此必须使用sys.path.append()方法来额外添加搜索路径, 否则无法正常导123456# a1.pyimport syssys.path.append("../") # 将 dirA 的上一次目录添加到搜索路径中from dirB import b1 # 正确, 注意必须先添加 path, 然后再导入from dirB.b1 import func_b1 # 正确from .a2 import func_a2 # 这里是错误的, 当直接执行 a1.py 时, a1.py 中不能包含显式相对导入 获取 python 版本:1print(sys.version_info) 获取包的安装位置1print(cv2) 解析 xml 文件导入:12345import sysif sys.version_info[0] == 2: import xml.etree.cElementTree as ETelse: import xml.etree.ElementTree as ET 解析:12345678910111213xmlfile = ET.parse(xmlfile_path)root = xmlfile.getroot() # 获取根节点root.tag # 标签root.attrib # 属性字典for child in root: # 迭代访问子节点 print(child.tag, child.attrib)# 可以通过索引访问嵌套节点的内容root[0][1].textElement.findall() #Element.find() # python 中 == 和 is 的区别== 只用于判断值是否相等is 用于判断两个对象是否为同一个实例小整数对象池: Python 为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。而Python 对小整数的定义是 [-5, 257)，只有数字在-5到256之间它们的id才会相等，超过了这个范围就不行了，同样的道理，字符串对象也有一个类似的缓冲池，超过区间范围内自然不会相等了 队列 queue在 Python3 中, 原来的Queue模块被重命名为queue, 该模块包含以下三类数据结构: queue.Queue(maxsize=0): FIFO queue, 先进先出队列, 代表普通队列 queue.LifoQueue(maxsize=0): LIFO queue, 后进先出队列, 类似栈的作用 queue.PriorityQueue(maxsize=0): 优先级队列, 类似堆的作用. 默认为小顶堆, 常用形式为元组:(priority_number, data)上面的 maxsize 表明了队列中最大可以容纳的元素数量, 如果超过, 则无法插入. 当 maxsize &lt;= 0 时, 代表元素数量无限制.公有方法(以上三个通用): qsize(): 返回 approximate size, qsize() &gt; 0 不保证get()一定 work, 同理, qsize() &lt; maxsize 不保证put()一定 work. empty(): 如果队列为空, 返回 True. 和qsize()一样, 不提供保证性. full(): 如果队列满, 返回 True. 不提供保证性 put(item[, block[, timeout]]) put_nowait(item): 等价于put(item, False) get([block[, timeout]]) get_nowait(): 等价于get(False) task_done(): join():堆 heapqheapq 模块只有最小堆的功能, 要实现最大堆, 需要在入堆和出堆的时候取反, 并且 heapq 模块只能作用于数值型类型.最大堆: _heapify_max(), _heappop_max() 给定一组数据, 创建堆, 两种方式(二者等价):1234567import heapqdata = [1,3,6,2,8,5]heap = []for d in data: heapq.heappush(heap, n) # 方法一 逐个构建heapq.heapify(data) # 方法二 原地构建, 效率更高 小顶堆:123456heap = [1,3,6,2,8,5]heapq.heapify(heap)heapq.heappop(heap) # 返回并删除堆顶heapq.heapreplace(heap, 10) # 删除堆顶并添加新值heapq.heappushpop(heap, 10) # 先将新值加入堆中, 然后立刻弹出堆顶print(heap[0]) # 查看堆顶 大顶堆:123456789101112# 方法一: 取负值heap = [-1,-3,-6,-2,-8,-5]# 方法二: 内置方法heap = [1,3,6,2,8,5]heapq._heapify_max(heap) # max_heapprint(heap[0]) # 查看堆顶, 8heapq._heappop_max(heap) # po from maxheapprint(heap[0]) # 6heapq._heapreplace_max(heap, 10)print(heap[0]) # 10# heapq._heappushpop_max(heap, 10) # 注意, 没有 _heappushpop_max 函数 Python 刷题常用队列:123456789101112import Queuebase_queue = Queue.Queue() # 基本队列, 先进先出base_queue.put(x)base_queue.get()lifo_queue = Queue.LifoQueue() # 先进后出, 类似栈lifo_queue.put(x)lifo_queue.get()prio_queue = Queue.PriorityQueue() # 优先队列, 与C++中priority_queue类似, 可实现堆的功能prio_queue.put(x)prio_queue.get() numpy 中vstack, hstack, concatenate 和 stack 之间的区别和联系concatenate1numpy.concatenate((a1, a2, ...), axis=0, out=None) concatenate 的作用就是将多个数组序列按照axis指定的维度连接起来, 这些数组序列 a1, a2, … 必须保证 除了 axis 指定维度之外的其他维度具有相同的 shape. 注意: 这里的维度指的是a1, a2的维度, 而不是(a1, a2)的维度 从维度角度来更好理解 concatenate 的作用concatenate 执行后的 shape 特定是: axis 指定的维度是多个数组序列对应维度的数值和, 而其他维度保持不变. 也就是说不会增加新的维度, 这是 concatenate 与 stack 之间的一个重要的区别. 如下所示:12345678910111213141516171819202122import numpy as npa1 = np.array([[1, 1], [2, 2], [3, 3]]) # shape = 3x2a2 = np.array([[1, 1], [2, 2]]) # shape = 2 x 2print(a1.shape, a2.shape)concat1 = np.concatenate((a1, a2), axis=0)print(concat1.shape) # shape 为 [5, 2], 在 0 维度上为 3+2, 其他维度保持不变print(concat1) # a1, a2 维度 0 不同, 一个为 3, 一个为 2, 其他维度相同, 均为 2#[[1 1]# [2 2]# [3 3]# [1 1]# [2 2]]#print(np.concatenate((a1, a2), axis=1)) # 由于维度 0 二者不同, 无法保持不变, 因此报错a1 = np.array([[1, 2, 3]]) # shape = 1x3a2 = np.array([[1, 2]]) # shape = 1x2print(a1.shape, a2.shape)concat2 = np.concatenate((a1, a2), axis=1)print(concat2.shape) # shape 为 [1, 5]在 1 维度上为 3 + 2, 0 维度上保持 1 不变print(concat2)# [[1 2 3 1 2]]# print(np.concatenate((a1, a2), axis=0)) # 维度 1 不同, 报错 有时候, concatenate的第一个参数只会传送一个一个数组序列, 这时候, 等价于将这个数组序列的第一维的元素看做是多个数组序列作为concatenate的参数进行传递. 如下所示:123456789a = [[1, 2, 3], [1, 2, 3]]print(np.concatenate(a, axis=0)) # 该行与下一行等价print(np.concatenate((a[0], a[1]), axis=0))a = [[1, 2, 3], [1, 2]]print(np.concatenate(a, axis=0)) # 可以看出, 虽然 a 的第一维度为 2, 第二维度为 3 和 2# 但是, 我们要将其拆分, 拆分后, a[0], a[1] 的第一维度3和2, 其他维度相同, 因此可以在第一维度上进行连接print(np.concatenate((a[0], a[1]), axis=0)) stack12numpy.stack(arrays, axis=0, out=None)numpy.stack((a1, a2, ...), axis=0, out=None) stack 的作用就是将多个数组序列按照axis指定的维度 堆叠 起来, 这些数组序列 a1, a2, … 必须保证 所有维度都相同, 注意这里与 concatenate 的区别. 要更好的理解stack, 可以借助 维度 的概念进行理解, 对于 shape 相同的 k 个数组序列来说, stack 的作用相当于新插入一个维度, 维度的大小为 k, 插入的位置为axis指定的位置. 如下所示:123456789101112131415a1 = [[1, 1], [2, 2], [3, 3]] # shape = 3x2a2 = [[4, 4], [5, 5], [6, 6]] # shape = 3x2a3 = [[7, 7], [8, 8], [9, 9]] # shape = 3x2a4 = [[0, 0], [0, 0], [0, 0]] # shape = 3x2stack1 = np.stack((a1, a2, a3, a4), axis=0) # 新插入维度大小为 4, 位置为第 0 维print(stack1.shape) # shape 为 (4, 3, 2)print('###\n', stack1) # 先将 shape 画好, 然后进行填充, 在第 0 维上进行堆叠, 因此 stack1[*][*] = a1[0], a1[1], ..., a4[2]stack2 = np.stack((a1, a2, a3, a4), axis=1) # 新插入维度大小为 4, 位置为第 1 维print(stack2.shape) # shape 为 (3, 4, 2)print('###\n', stack2) # 在第 1 维上进行堆叠, 因此 stack2[*][*] = a1[0], a2[0], a3[0], a1[1], ...stack3 = np.stack((a1, a2, a3, a4), axis=2) # 新插入维度大小为 4, 位置为第 2 维print(stack3.shape) # shape 为 (3, 2, 4)print('###\n', stack3) # 在第 2 维上进行堆叠, 因此 stack2[*][*] = [1 4 7 0], [1 4 7 0], [2 5 8 0], ... hstack 和 vstackhstack 和 vstack 虽然名字中都带有 stack, 但是实际上, 它们和np.stack的关系并不大, 一个明显的区别就是np.stack要求进行堆叠的多个数组序列需要保证 shape 完全相同, 并且堆叠后会新增加一个由axis指定的维度. 实际上, hstack 和 vstack 可以看做是特殊的 concatenate, 它们在某些情况下可以用 concatenate 来代替 既然 hstack 和 vstack 是特殊的 concatenate, 也就是说, 它们所接受的多个数组序列在axis指定的维度上可以不同, 而在其他维度上必须相同. vstack: 在垂直方向上将多个数组序列进行堆叠, 相当于在axis=0维度上执行concatenatehstack: 在水平方向上将多个数组序列进行堆叠, 相当于在axis=1维度上执行concatenate1234567891011121314151617181920a = [[1, 1], [2, 2], [3, 3]] # shape = 3x2b = [[4, 4], [5, 5], [6, 6]] # shape = 3x2c = [[7, 7], [8, 8], [9, 9]] # shape = 3x2d = [[0, 0], [0, 0], [0, 0]] # shape = 3x2v = np.vstack((a, b, c, d))print(v.shape) # (12, 2)print(v)x = np.concatenate((a, b, c, d), axis = 0) # 等价于 vstackprint(x.shape) # 12, 2print(x)h = np.hstack((a, b, c, d))print(h.shape) # (3, 8)print(h)x = np.concatenate((a, b, c, d), axis = 1) # 等价于 hstackprint(x.shape) # 3, 8print(x) 需要特别注意, 当多个数组序列是一维数组时, 应该先将一维数组转换成二维数组, 然后才能与相应的 concatenate 进行等价. 这是因为, 在数组序列是一维数组时, concatenate 是无法使用axis=1的, 因此此时的 hstack 相当于是在axis=0上进行 concatenate, 而 vstack 则需要先将数组的 shape 从 (N,) 转换成 (1, N) 后才相当于是在axis=1上进行 concatenate 12345678910111213141516a = np.array([1, 2, 3, 4, 5]) # 当面对的是一维数组时,b = np.array([6, 7, 8, 9, 10])h = np.hstack((a, b))print(h.shape)print(h)con = np.concatenate((a, b), axis=0) # 当 a, b 是一维数组时, hstack 相当于在 axis=0 上进行连接print(con.shape)print(con)v = np.vstack((a, b))print(v.shape)print(v)con = np.concatenate(([a], [b]), axis=0) # 当 a, b 是一维数组时, vstack 相当于将 a, b 先转换成二维 (1, N), 然后在 axis=0 上进行连接print(con.shape)print(con) set 去重对于二维列表, 由于 list 的元素也是 list, 在内存中存储的是首元素地址, 无法直接使用 set, 因此需要先将内部的元素全部全换成 tuple 后, 才能使用 list 去重. 如下所示12345678a = list()a.append([1,2,3])a.append([1,2,3])a.append([1,2,3])a.append([4, 5, 6])# b = set(a) # 报错b = set(map(tuple, a))print(b) # &#123;(4, 5, 6), (1, 2, 3)&#125; os.sep用法ython是跨平台的。在Windows上，文件的路径分隔符是’\’，在Linux上是’/‘。 为了让代码在不同的平台上都能运行，那么路径应该写’\’还是’/‘呢？ 使用os.sep的话，就不用考虑这个了，os.sep根据你所处的平台，自动采用相应的分隔符号。 举例 Linux下一个路径，/usr/share/python,那么上面的os.sep就是‘/’windows下一个路径，C：\Users\Public\Desktop,那么上面的os.sep就是‘\’.1data_dir = os.sep.join(['hello', 'world']) Python3 元组Python元组包含了以下内置函数 len(tuple) 计算元组元素个数。 1234&gt;&gt;&gt; tuple1 = ('Google', 'Runoob', 'Taobao')&gt;&gt;&gt; len(tuple1)3&gt;&gt;&gt; max(tuple) 返回元组中元素最大值。 1234&gt;&gt;&gt; tuple2 = ('5', '4', '8')&gt;&gt;&gt; max(tuple2)'8'&gt;&gt;&gt; min(tuple) 返回元组中元素最小值。 1234&gt;&gt;&gt; tuple2 = ('5', '4', '8')&gt;&gt;&gt; min(tuple2)'4'&gt;&gt;&gt; tuple(seq) 将列表转换为元组。 1234&gt;&gt;&gt; list1= ['Google', 'Taobao', 'Runoob', 'Baidu']&gt;&gt;&gt; tuple1=tuple(list1)&gt;&gt;&gt; tuple1('Google', 'Taobao', 'Runoob', 'Baidu') 序列化Python对象你需要将一个Python对象序列化为一个字节流，以便将它保存到一个文件、存储到数据库或者通过网络传输它。对于序列化最普遍的做法就是使用 pickle 模块。为了将一个对象保存到一个文件中，可以这样做 pickle 对于大型的数据结构比如使用 array 或 numpy 模块创建的二进制数组效率并不是一个高效的编码方式。 如果你需要移动大量的数组数据，你最好是先在一个文件中将其保存为数组数据块或使用更高级的标准编码方式如HDF5 (需要第三方库的支持)。12345678910111213141516171819In [1]: import pickle In [2]: obj = 123,"abcdef", ["ac", 123], &#123;"key": "value", "key1": "value1"&#125; In [3]: print(obj) (123, 'abcdef', ['ac', 123], &#123;'key': 'value', 'key1': 'value1'&#125;)In [4]: # 序列化到文件 In [5]: with open(r'./a.pickle','wb') as f: ...: pickle.dump(obj,f) ...: In [6]: with open(r'./a.pickle','rb') as f: ...: aa= pickle.load(f) ...: print(aa) ...: ...: (123, 'abcdef', ['ac', 123], &#123;'key': 'value', 'key1': 'value1'&#125;) 参考链接：https://hellozhaozheng.github.iohttps://www.runoob.com/python/python-tutorial.html]]></content>
      <categories>
        <category>programs</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广度/宽度优先搜索(BFS)]]></title>
    <url>%2F2019%2F08%2F28%2FBFS%2F</url>
    <content type="text"><![CDATA[前言广度优先搜索 是最简单的图搜索算法之一， 也是许多重要的图算法的原型。Prime的最小生成树算法和Dijkstra的单源最短路径算法都使用了类似广度优先搜索的思想。给定图G=(V,E) 和一个可以识别的源节点 s，广度优先搜索对图G中的边进行系统性的探索来发现可以从源节点，到达所有的节点。该算法能够计算从源结点s到每个可到达的节点的距离(最小的边数)，同时生成一棵“广度优先搜索树”。该树以源结点s为根节点，包括所有可以从s到达的结点。对于每个从源结点s可以到达的结点v，在广度优先搜索树里从结点s到结点v的简单路径所对应的的就是图G中从结点s到结点v的“最短路径”，即包含最少边数的路径，该算法既可以用于有向图也可以用于无向图。广度优先算法之所以如此得名是因为该算法始终是将已经发现的结点和未发现结点之间的边界，沿其广度方向向外扩展。也就是说，算法需要在发现所有距离源结点s为k的所有结点之后，才会发现距离源结点s为k+1的 其他结点。 图的概念 图(graph) 是一种$\textcolor{Blue}{网状数据} $结构， 图是由非空的顶点集合和一个描述顶点之间的关系的集合组成。 图由顶点和边组成，顶点表示对象，边表示对象之间的连接关系。 边也可以带权值，称为带权值图。无向图术语 两个顶点之间如果有边连接，视为两个顶点相邻 相邻顶点间的序列称为路径 起点和终点重合的路径称为圈 顶点连接的边数叫做这个顶点的度 没有圈的连通图，就是树 没有圈的非连通图，就是森林 一棵树的边数等于顶点数-1 边数等于顶点数-1 的连通图，就是树 12345678910111213141516171819BFS(G,s) \\for each vertex u \in G.V -&#123;s&#125;\\ u.color = WHITE\\ u.d = \infty\\ u.\pi = NIL\\s.color = GRAY\\s.d = 0\\s.\pi = NIL\\Q = \emptyset\\ENQUEUE(Q,s)\\while Q\neq = \emptyset\\ u = DEQUEUE(Q)\\ for each v \in G.Adj[u]\\ if v.color == WHITE\\ v.color = GRAY\\ v.d = u.d+1\\ v.\pi = u\\ ENQUEUE(Q,v)\\ u.color = BLACK\\ 广度优先搜索的流程图 实例POJ3984《迷宫问题》定义一个二维数组：int maze[5][5] = { 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,};它表示一个迷宫，其中的1表示墙壁，0表示可以走的路，只能横着走或竖着走，不能斜着走，要求编程序找出从左上角到右下角的最短路线。 解题思路队列是先进后出，后进先出。 对应于题目的输入数组：0, 1, 0, 0, 0,0, 1, 0, 1, 0,0, 0, 0, 0, 0,0, 1, 1, 1, 0,0, 0, 0, 1, 0,把节点定义为(x,y)，(x,y)表示数组maze的项maze[x][y]。于是起点就是(0,0)，终点是(4,4)。按照刚刚的思路，手工梳理一遍：初始条件：起点Vs为(0,0)终点Vd为(4,4)灰色节点集合Q={}初始化所有节点为白色节点下面开始广度优先搜索：1.起始节点Vs变成灰色，加入队列Q，Q={(0,0)}2.取出队列Q的头一个节点Vn，Vn={0,0}，Q={}3.把Vn={0,0}染成黑色，取出Vn所有相邻的白色节点{(1,0)}4.不包含终点(4,4)，染成灰色，加入队列Q，Q={(1,0)}5.取出队列Q的头一个节点Vn，Vn={1,0}，Q={}6.把Vn={1,0}染成黑色，取出Vn所有相邻的白色节点{(2,0)}7.不包含终点(4,4)，染成灰色，加入队列Q，Q={(2,0)}8.取出队列Q的头一个节点Vn，Vn={2,0}，Q={}9.把Vn={2,0}染成黑色，取出Vn所有相邻的白色节点{(2,1), (3,0)}10.不包含终点(4,4)，染成灰色，加入队列Q，Q={(2,1), (3,0)}11.取出队列Q的头一个节点Vn，Vn={2,1}，Q={(3,0)}12.把Vn={2,1}染成黑色，取出Vn所有相邻的白色节点{(2,2)}13.不包含终点(4,4)，染成灰色，加入队列Q，Q={(3,0), (2,2)}14.持续下去，知道Vn的所有相邻的白色节点中包含了(4,4)……15.此时获得了答案 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// BFS.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include &lt;iostream&gt;using namespace std;int map[5][5];//相邻四个节点int borderUponX[4] = &#123; 0, 0, 1, -1 &#125;;int borderUponY[4] = &#123; 1, -1, 0, 0 &#125;;int front = 0, rear = 1;struct node &#123; int pre; int x; int y;&#125; path[100];void print(int i) &#123;//当前节点 if (path[i].pre != -1) &#123;//找到前面那个节点 print(path[i].pre); cout &lt;&lt; "(" &lt;&lt; path[i].x &lt;&lt; "," &lt;&lt; path[i].y &lt;&lt; ")" &lt;&lt; endl; &#125; else &#123;//最前面的那个节点 cout &lt;&lt; "(" &lt;&lt; path[i].x &lt;&lt; "," &lt;&lt; path[i].y &lt;&lt; ")" &lt;&lt; endl; &#125;&#125;void bfsSearch(int x, int y) &#123; //开始节点（出发），前面没有节点了 path[front].x = x; path[front].y = y; path[front].pre = -1; //当front == rear的时候说明已经走完了所以“相邻”节点 //且都不通 while (front &lt; rear) &#123; for (int i = 0; i != 4; i++) &#123; //相邻节点坐标 int pathX = path[front].x + borderUponX[i]; int pathY = path[front].y + borderUponY[i]; //不符合的节点（遇到边界或已经走过了） if (pathY &lt; 0 || pathX &lt; 0 || pathX &gt; 4 || pathY &gt; 4 || map[pathX][pathY]) continue; else &#123;//将front的相邻的可以过去的并且是还没有走过的节点加到路径里面 map[pathX][pathY] = 1; path[rear].x = pathX; path[rear].y = pathY; path[rear].pre = front; rear++; &#125; if (pathX == 4 &amp;&amp; pathY == 4) &#123; //找到了一条路径，又是第一次找到 //那么就是最短路径了 print(rear - 1); break; &#125; &#125; front++; &#125;&#125;int main(int argc, char const *argv[])&#123; for (int i = 0; i &lt; 5; i++) for (int j = 0; j &lt; 5; j++) cin &gt;&gt; map[i][j]; bfsSearch(0, 0); system("pause"); return 0;&#125;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维数组中的查找]]></title>
    <url>%2F2019%2F08%2F27%2F%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 时间限制：1秒 空间限制：32768K 热度指数：1323359 题目解析已知从左到右、从上导线都呈递增关系，令行row为0，令列col为第一行最后一位，然后将target与第一行最后一个数进行比较，若大于这个数则，行数++，若小于这个数，则列数向前递减。题目的要求是 当目标数target既不大于也不小于array[row][col]，认为target==array[row][col]，返回true。其他的情况则返回false。注： 在 c++中获取vector数组的行数和列数的代码与java不一样 123456c++:int col = array[0].size()-1;int row = array.size();java:int col = array[0].length - 1;int array_len = array.length; c++代码 如下：12345678910111213141516171819202122232425262728class Solution &#123;public: //行数： //example.length // 列数： //example[0].length //第0行的列数 bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; if(array.size()==0) &#123; return false; &#125; int row = 0; int col = array[0].size()-1; int array_len = array.size(); while(row &lt;array_len &amp;&amp; col&gt;=0 ) &#123; if(target&gt; array[row][col]) row++; else if(target&lt; array[row][col]) col--; else return true; &#125; return false; &#125;&#125;; 运行时间：11ms占用内存：1500k]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[仿射变换]]></title>
    <url>%2F2019%2F08%2F26%2F%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[欧式变换包括平移和旋转变换 什么是仿射变换？ 简单的来说“仿射变换” 就是：“线性变换”+平移尺度变换包括相似变换，当x与y变换的尺度相等的时候，叫做相似变换什么是线性变换？ 1 线性变换 线性变换从几何直观有三个 要点： 变换前是直线的，变换后依旧是直线 直线比例保持不变 变换前是原点，变换后依然是原点 2 仿射变换仿射变换从几何直观只有两个要点： 变换前是直线的，变换后依然是直线 直线比例保持不变* 与线性变换相比少了原点保持不变这一条]]></content>
      <categories>
        <category>maths</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSD源码解析]]></title>
    <url>%2F2019%2F08%2F24%2Fssd%2F</url>
    <content type="text"><![CDATA[论文地址: SSD: Single Shot MultiBox Detector 非官方代码: pytorch 介绍SSD，全称Single Shot MultiBox Detector，是一种One-Stage的方法，它由Wei Liu在ECCV 2016上提出，SSD具有如下主要特点： 从YOLO中继承了将detection转化为regression的思路，同时一次即可完成网络训练 基于Faster RCNN中的anchor，提出了相似的prior box 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，相当于半个FPN思路 SSD的 网络结构 由上图可以看出，SSD的基础网络结构由基础网络VGG16组成，在VGG16基础网络之后接了一个3x3的卷积和一个1x1的卷积做特征融合，然后增加了一个Extra Feature Layers 层，这个层由八个卷积层构成。SSD在前面的基础网络去conv_4_3之后的relu层输出，以及倒数第二层的conv_7_1的relu再加上Extra Feature Layers层的第1,3,5,7层 共有6个 featuremap层，在此基础上对box进行预测。但感觉要提升效果的话可以对基础网络进行更改，增加特征融合等等。 空洞卷积(Dilation Conv) ssd网络里还使用了空洞卷积(Dilation Conv),采用VGG16做基础模型，首先VGG16是在ILSVRC CLS-LOC数据集预训练。然后借鉴了DeepLab-LargeFOV，分别将VGG16的全连接层fc6和fc7转换成 3×3卷积层 conv6和 1×1 卷积层conv7，同时将池化层 pool5 由原来的 stride=2 的 2×2 变成 stride=1 的(猜想是不想reduce特征图大小)，为了配合这种变化，采用了一种 Atrous Algorithm，其实就是conv6采用扩展卷积或带孔卷积（Dilation Conv），其在不增加参数与模型复杂度的条件下指数级扩大卷积的视野，其使用扩张率(dilation rate)参数，来表示扩张的大小，如下图所示，(a)是普通的 3×3 卷积，其视野就是 3×3 ，(b)是扩张率为 1，此时视野变成 7×7 ，(c)扩张率为3时，视野扩大为 15×15 ，但是视野的特征更稀疏了。Conv6采用 3×3 大小但dilation rate=6的扩展卷积。 Prior Box SSD中有着类似anchor机制的Prior Box机制，用于来生成先验框，后面将这些先验框与真实的gt进行匹配，然后与预测的进行回归。从而得到物体真实的 位置。SSD的prior Box 按照如下规则生成： 以feature map上每个点的中点为中心（offset=0.5），生成一些列同心的prior box（然后中心点的坐标会乘以step，相当于从feature map位置映射回原图位置） 正方形prior box最小边长为’’’pash $min_size$’’’，最大边长为：\sqrt{min_size*max_size}E=mc^2 根据相应的aspect ratio，会生成不同个数的长方形 ，长宽为：$ \sqrt{aspect_ratio}min_size$ 和 $1/ \sqrt{aspect_ratio}min_size$ $f(x)=ax+b$ 最终网络生成固定数量的Prior Box 每个feature map 对应prior box的min_size 和max_size 由以下的公式决定，公式中的m是使用feature map的数量(m=6) S_k = S_min + \frac{S_max-S_min}{m-1}(k-1) , k \in[1,m]第一层feature map对应的min_size=S1，max_size=S2；第二层min_size=S2，max_size=S3；其他类推。在原文中，Smin=0.2，Smax=0.9 min_size max_size def.boxes num conv4_3 30 60 4 fc7 60 111 6 conv6_2 111 162 6 fc7 162 213 6 conv4_3 213 264 4 fc7 264 315 4 训练策略正负样本给定输入图像以及每个物体的Ground Truth,首先找到每个Ground True box对应的default box中IOU最大的最为正样本。然后,在剩下的default box中寻找与Ground Truth 的IOU大于0.5的default box作为正样本。一个Ground Truth可能对应多个正样本default box.其他的default box作为负样本。,为了保证样本尽量平衡,SSD采用了hard nagative mining,即对负样本进行抽样,抽样时按照置信度误差(预测背景的置信度越小,误差越大)进行奖序排列,选取误差较大的top-k作为训练的负样本,保证正负样本比例接近1:3。 目标函数目标函数为训练过程中的优化标准,目标函数也称损失函数,主要包括位置误差(localization loss,loc) 与置信度误差(confidence loss,conf,分类损失)的加权和,定义为： 代码解析基础模型定义1234567891011121314151617181920212223242526# vgg([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',# 512, 512, 512], 3)# This function is derived from torchvision VGG make_layers()# https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.pydef vgg(cfg, i, batch_norm=False): layers = [] in_channels = i for v in cfg: if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)] elif v == 'C': layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)] else: conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1) if batch_norm: layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] else: layers += [conv2d, nn.ReLU(inplace=True)] in_channels = v pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6) conv7 = nn.Conv2d(1024, 1024, kernel_size=1) layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)] return layers 1234567891011121314151617181920212223242526272829303132base = &#123; '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M', 512, 512, 512], '512': [],&#125;extras = &#123; '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256], '512': [],&#125;mbox = &#123; '300': [4, 6, 6, 6, 4, 4], # number of boxes per feature map location '512': [],&#125;def add_extras(cfg, i, batch_norm=False): # Extra layers added to VGG for feature scaling layers =[] in_channel = i flag = False for k,v in enumerate(cfg): if in_channel !="S": if v == "S": layers += [nn.Conv2d(in_channel,cfg[k+1], kernel_size=(1,3)[flag], stride=2,padding=1)] # flag 来控制卷积核是1 还是3 else: layers += [nn.Conv2d(in_channel, v, kernel_size=(1,3)[flag])] flag = not flag in_channel = v return layers 模型Head部分的生成123456789101112131415161718# cfg [4, 6, 6, 6, 4, 4], # number of boxes per feature map locationdef multibox(vgg, extra_layers, cfg, num_classes): loc_layers = [] conf_layers = [] vgg_source = [21, -2] for k, v in enumerate(vgg_source): loc_layers += [nn.Conv2d(vgg[v].out_channels, cfg[k] * 4, kernel_size=3, padding=1)] conf_layers += [nn.Conv2d(vgg[v].out_channels, cfg[k] * num_classes, kernel_size=3, padding=1)] # 对extra_layers中的（Conv2d-2_1、Conv2d-4_1、Conv2d-6_1、Conv2d-8_1）层通过卷积提取特征 for k, v in enumerate(extra_layers[1::2], 2): loc_layers += [nn.Conv2d(v.out_channels, cfg[k] * 4, kernel_size=3, padding=1)] conf_layers += [nn.Conv2d(v.out_channels, cfg[k] * num_classes, kernel_size=3, padding=1)] return vgg, extra_layers, (loc_layers, conf_layers) 模型先验框的生成123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class PriorBox(object): """Compute priorbox coordinates in center-offset form for each source feature map. """ def __init__(self, cfg): super(PriorBox, self).__init__() self.image_size = cfg['min_dim'] # number of priors for feature map location (either 4 or 6) self.num_priors = len(cfg['aspect_ratios']) self.variance = cfg['variance'] or [0.1] self.feature_maps = cfg['feature_maps'] self.min_sizes = cfg['min_sizes'] self.max_sizes = cfg['max_sizes'] self.steps = cfg['steps'] self.aspect_ratios = cfg['aspect_ratios'] self.clip = cfg['clip'] self.version = cfg['name'] for v in self.variance: if v &lt;= 0: raise ValueError('Variances must be greater than 0') def forward(self): mean = [] # 'steps': [8, 16, 32, 64, 100, 300], # 'feature_maps': [38, 19, 10, 5, 3, 1], # 'min_sizes': [21, 45, 99, 153, 207, 261], # 'max_sizes': [45, 99, 153, 207, 261, 315], for k, f in enumerate(self.feature_maps): for i, j in product(range(f), repeat=2): f_k = self.image_size / self.steps[k] # unit center x,y cx = (j + 0.5) / f_k cy = (i + 0.5) / f_k # aspect_ratio: 1 # rel size: min_size s_k = self.min_sizes[k]/self.image_size mean += [cx, cy, s_k, s_k] # aspect_ratio: 1 # rel size: sqrt(s_k * s_(k+1)) s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size)) mean += [cx, cy, s_k_prime, s_k_prime] # rest of aspect ratios for ar in self.aspect_ratios[k]: mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)] mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)] # back to torch land output = torch.Tensor(mean).view(-1, 4) if self.clip: output.clamp_(max=1, min=0) return output MultiBox 损失函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155class MultiBoxLoss(nn.Module): """SSD Weighted Loss Function Compute Targets: 1) Produce Confidence Target Indices by matching ground truth boxes with (default) 'priorboxes' that have jaccard index &gt; threshold parameter (default threshold: 0.5). 2) Produce localization target by 'encoding' variance into offsets of ground truth boxes and their matched 'priorboxes'. 3) Hard negative mining to filter the excessive number of negative examples that comes with using a large number of default bounding boxes. (default negative:positive ratio 3:1) Objective Loss: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N Where, Lconf is the CrossEntropy Loss and Lloc is the SmoothL1 Loss weighted by α which is set to 1 by cross val. Args: c: class confidences, l: predicted boxes, g: ground truth boxes N: number of matched default boxes See: https://arxiv.org/pdf/1512.02325.pdf for more details. # 计算目标: # 输出那些与真实框的iou大于一定阈值的框的下标. # 根据与真实框的偏移量输出localization目标 # 用难样例挖掘算法去除大量负样本(默认正负样本比例为1:3) # 目标损失: # L(x,c,l,g) = (Lconf(x,c) + αLloc(x,l,g)) / N # 参数: # c: 类别置信度(class confidences) # l: 预测的框(predicted boxes) # g: 真实框(ground truth boxes) # N: 匹配到的框的数量(number of matched default boxes) """# MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5, False, args.cuda) def __init__(self, num_classes, overlap_thresh, prior_for_matching, bkg_label, neg_mining, neg_pos, neg_overlap, encode_target, use_gpu=True): super(MultiBoxLoss, self).__init__() self.use_gpu = use_gpu self.num_classes = num_classes # 列表数 21 self.threshold = overlap_thresh # 交并比阈值, 0.5 self.background_label = bkg_label # 背景标签, 0 self.encode_target = encode_target # True 没卵用 self.use_prior_for_matching = prior_for_matching # True, 没卵用 self.do_neg_mining = neg_mining # 负样本和正样本的比例, 3:1 self.negpos_ratio = neg_pos # 0.5 判定负样本的阈值. self.neg_overlap = neg_overlap # False 没卵用 self.variance = cfg['variance'] def forward(self, predictions, targets): """Multibox Loss Args: predictions (tuple): A tuple containing loc preds, conf preds, and prior boxes from SSD net. conf shape: torch.size(batch_size,num_priors,num_classes) loc shape: torch.size(batch_size,num_priors,4) priors shape: torch.size(num_priors,4) targets (tensor): Ground truth boxes and labels for a batch, shape: [batch_size,num_objs,5] (last idx is the label). """ loc_data, conf_data, priors = predictions # loc_data: [batch_size, 8732, 4] # conf_data: [batch_size, 8732, 21] # priors: [8732, 4] default box 对于任意的图片, 都是相同的, 因此无需带有 batch 维度 num = loc_data.size(0) # num = batch_size priors = priors[:loc_data.size(1), :] # loc_data.size(1) = 8732, 因此 priors 维持不变 num_priors = (priors.size(0)) # num_priors = 8732 num_classes = self.num_classes # num_classes = 21 (默认为voc数据集) # match priors (default boxes) and ground truth boxes # 将priors(default boxes)和ground truth boxes匹配 loc_t = torch.Tensor(num, num_priors, 4) # shape:[batch_size, 8732, 4] conf_t = torch.LongTensor(num, num_priors) # shape:[batch_size, 8732] for idx in range(num): # targets是列表, 列表的长度为batch_size, 列表中每个元素为一个 tensor, # 其 shape 为 [num_objs, 5], 其中 num_objs 为当前图片中物体的数量, 第二维前4个元素为边框坐标, 最后一个元素为类别编号(1~20) truths = targets[idx][:, :-1].data # [num_objs, 4] labels = targets[idx][:, -1].data # [num_objs] 使用的是 -1, 而不是 -1:, 因此, 返回的维度变少了 defaults = priors.data # [8732, 4] # from ..box_utils import match # 关键函数, 实现候选框与真实框之间的匹配, 注意是候选框而不是预测结果框! 这个函数实现较为复杂, 会在后面着重讲解 match(self.threshold, truths, defaults, self.variance, labels, loc_t, conf_t, ) if self.use_gpu: loc_t = loc_t.cuda() conf_t = conf_t.cuda() # wrap targets # 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了 loc_t = Variable(loc_t, requires_grad=False) conf_t = Variable(conf_t, requires_grad=False) pos = conf_t &gt; 0 # 筛选出 &gt;0 的box下标(大部分都是=0的) num_pos = pos.sum(dim=1, keepdim=True) # 求和, 取得满足条件的box的数量, [batch_size, num_gt_threshold] # Localization Loss (Smooth L1) # Shape: [batch,num_priors,4] # 位置(localization)损失函数, 使用 Smooth L1 函数求损失 # loc_data:[batch, num_priors, 4] # pos: [batch, num_priors] # pos_idx: [batch, num_priors, 4], 复制下标成坐标格式, 以便获取坐标值 pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data) loc_p = loc_data[pos_idx].view(-1, 4) # 获取预测结果值 loc_t = loc_t[pos_idx].view(-1, 4) # 获取gt值 loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False) # 计算损失 # Compute max conf across batch for hard negative mining # 计算最大的置信度, 以进行难负样本挖掘 # conf_data: [batch, num_priors, num_classes] # batch_conf: [batch, num_priors, num_classes] batch_conf = conf_data.view(-1, self.num_classes) # conf_t: [batch, num_priors] # loss_c: [batch*num_priors, 1], 计算每个priorbox预测后的损失 loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1, 1)) # 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新 # Hard Negative Mining loss_c[pos] = 0 # filter out pos boxes for now # 将所有的pos下标的box的loss置为0(pos指示的是正样本的下标) # 将 loss_c 的shape 从 [batch*num_priors, 1] 转换成 [batch, num_priors] loss_c = loss_c.view(num, -1) # reshape # 进行降序排序, 并获取到排序的下标 _, loss_idx = loss_c.sort(1, descending=True) # 将下标进行升序排序, 并获取到下标的下标 _, idx_rank = loss_idx.sort(1) # num_pos: [batch, 1], 统计每个样本中的obj个数 num_pos = pos.long().sum(1, keepdim=True) # 根据obj的个数, 确定负样本的个数(正样本的3倍) num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1) # 获取到负样本的下标 neg = idx_rank &lt; num_neg.expand_as(idx_rank) # 计算包括正样本和负样本的置信度损失 # pos: [batch, num_priors] # pos_idx: [batch, num_priors, num_classes] pos_idx = pos.unsqueeze(2).expand_as(conf_data) # neg: [batch, num_priors] # neg_idx: [batch, num_priors, num_classes] neg_idx = neg.unsqueeze(2).expand_as(conf_data) # 按照pos_idx和neg_idx指示的下标筛选参与计算损失的预测数据 conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes) # 按照pos_idx和neg_idx筛选目标数据 targets_weighted = conf_t[(pos+neg).gt(0)] # 计算二者的交叉熵 loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False) # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N # 将损失函数归一化后返回 N = num_pos.data.sum() loss_l /= N loss_c /= N return loss_l, loss_c match函数的解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx): # threshold: (float) 确定是否匹配的交并比阈值 # truths: (tensor: [num_obj, 4]) 存储真实 box 的边框坐标 # priors: (tensor: [num_priors, 4], 即[8732, 4]), 存储推荐框的坐标, 注意, 此时的框是 default box, 而不是 SSD 网络预测出来的框的坐标, 预测的结果存储在 loc_data中, 其 shape 为[num_obj, 8732, 4]. # variances: cfg['variance'], [0.1, 0.2], 用于将坐标转换成方便训练的形式(参考RCNN系列对边框坐标的处理) # labels: (tensor: [num_obj]), 代表了每个真实 box 对应的类别的编号 # loc_t: (tensor: [batches, 8732, 4]), # conf_t: (tensor: [batches, 8732]), # idx: batches 中图片的序号, 标识当前正在处理的 image 在 batches 中的序号 # jaccard index overlaps = jaccard( # [A, B], 返回任意两个box之间的交并比, overlaps[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比. truths, point_form(priors) ) # 二部图匹配(Bipartite Matching) # [num_objs,1], 得到对于每个 gt box 来说的匹配度最高的 prior box, 前者存储交并比, 后者存储prior box在num_priors中的位置 best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True) # keepdim=True, 因此shape为[num_objs,1] # [1,num_priors] best ground truth for each prior # [1, num_priors], 即[1,8732], 同理, 得到对于每个 prior box 来说的匹配度最高的 gt box best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True) best_truth_idx.squeeze_(0) # 上面特意保留了维度(keepdim=True), 这里又都把维度 squeeze/reduce 了, 实际上只需用默认的 keepdim=False 就可以自动 squeeze/reduce 维度. best_truth_overlap.squeeze_(0) best_prior_idx.squeeze_(1) best_prior_overlap.squeeze_(1) best_truth_overlap.index_fill_(0, best_prior_idx, 2) # ensure best prior # 维度压缩后变为[num_priors], best_prior_idx 维度为[num_objs], # 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox. # 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比 # 最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有 # 的priorbox都与G匹配, 为了防止这种情况, 我们将那些对gtbox来说, 具有最高交并比的priorbox, # 强制进行互相匹配, 即令best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环 # TODO refactor: index best_prior_idx with long tensor # ensure every gt matches with its prior of max overlap # 注意!!: 因为 gt box 的数量要远远少于 prior box 的数量, 因此, 同一个 gt box 会与多个 prior box 匹配. for j in range(best_prior_idx.size(0)): best_truth_idx[best_prior_idx[j]] = j # best_prior_idx[j] 代表与box_a的第j个box交并比最高的 prior box 的下标, 将与该 gtbox # 匹配度最好的 prior box 的下标改为j, 由此,完成了该 gtbox 与第j个 prior box 的匹配. # 这里的循环只会进行num_obj次, 剩余的匹配为 best_truth_idx 中原本的值. # 这里处理的情况是, priorbox中第i个box与gtbox中第k个box的交并比最高, # 即 best_truth_idx[i]= k # 但是对于best_prior_idx[k]来说, 它却与priorbox的第l个box有着最高的交并比, # 即best_prior_idx[k]=l # 而对于gtbox的另一个边框gtbox[j]来说, 它与priorbox[i]的交并比最大, # 即但是对于best_prior_idx[j] = i. # 那么, 此时, 我们就应该将best_truth_idx[i]= k 修改成 best_truth_idx[i]= j. # 即令 priorbox[i] 与 gtbox[j]对应. # 这样做的原因: 防止某个gtbox没有匹配的 prior box. matches = truths[best_truth_idx] # Shape: [num_priors,4] # truths 的shape 为[num_objs, 4], 而best_truth_idx是一个指示下标的列表, 列表长度为 8732, # 列表中的下标范围为0~num_objs-1, 代表的是与每个priorbox匹配的gtbox的下标 # 上面的表达式会返回一个shape为 [num_priors, 4], 即 [8732, 4] 的tensor, 代表的就是与每个priorbox匹配的gtbox的坐标值. conf = labels[best_truth_idx] + 1 # 与上面的语句道理差不多, 这里得到的是每个prior box匹配的类别编号, shape 为[8732] conf[best_truth_overlap &lt; threshold] = 0 # 将与gtbox的交并比小于阈值的置为0 , 即认为是非物体框 loc = encode(matches, priors, variances) # 返回编码后的中心坐标和宽高. loc_t[idx] = loc # [num_priors,4] encoded offsets to learn # 设置第idx张图片的gt编码坐标信息 conf_t[idx] = conf # [num_priors] top class label for each prior 设置第idx张图片的编号信息.(大于0即为物体编号, 认为有物体, 小于0认为是背景) 参考文章：https://blog.csdn.net/happyday_d/article/details/86021993 https://hellozhaozheng.github.io/z_post/PyTorch-SSD]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>论文阅读</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib绘制六种可视化图表]]></title>
    <url>%2F2019%2F08%2F24%2Fpythonplot%2F</url>
    <content type="text"><![CDATA[01 折线图1234567891011121314151617import numpy as np import matplotlib.pyplot as pltx = np.linspace(0,2,100)plt.plot(x, x, label='linear')plt.plot(x, x**2, label='quadratic')plt.plot(x, x**3, label='cubic')plt.xlabel('x label')plt.ylabel('y label')plt.title("Simple Plot")plt.legend()plt.show() 02 散点图12345678import numpy as npimport matplotlib.pyplot as pltx = np.arange(0., 5., 0.2)# 红色破折号, 蓝色方块 ，绿色三角块plt.plot(x, x, 'r--', x, x**2, 'bs', x, x**3, 'g^')plt.show() 03 直方图123456789101112131415161718192021222324252627282930import numpy as npimport matplotlib.pyplot as pltnp.random.seed(19680801)mu1, sigma1 = 100, 15mu2, sigma2 = 80, 15x1 = mu1 + sigma1 * np.random.randn(10000)x2 = mu2 + sigma2 * np.random.randn(10000)# the histogram of the data# 50：将数据分成50组# facecolor：颜色；alpha：透明度# density：是密度而不是具体数值n1, bins1, patches1 = plt.hist(x1, 50, density=True, facecolor='g', alpha=1)n2, bins2, patches2 = plt.hist(x2, 50, density=True, facecolor='r', alpha=0.2)# n：概率值；bins：具体数值；patches：直方图对象。plt.xlabel('Smarts')plt.ylabel('Probability')plt.title('Histogram of IQ')plt.text(110, .025, r'$\mu=100,\ \sigma=15$')plt.text(50, .025, r'$\mu=80,\ \sigma=15$')# 设置x，y轴的具体范围plt.axis([40, 160, 0, 0.03])plt.grid(True)plt.show() 04 柱状图4.1 并列柱状图123456789101112131415161718192021import numpy as npimport matplotlib.pyplot as pltsize = 5a = np.random.random(size)b = np.random.random(size)c = np.random.random(size)x = np.arange(size)# 有多少个类型，只需更改n即可total_width, n = 0.8, 3 width = total_width / n# 重新拟定x的坐标x = x - (total_width - width) / 2# 这里使用的是偏移plt.bar(x, a, width=width, label='a')plt.bar(x + width, b, width=width, label='b')plt.bar(x + 2 * width, c, width=width, label='c')plt.legend()plt.show() 4.2 叠加柱状图12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltsize = 5a = np.random.random(size)b = np.random.random(size)c = np.random.random(size)x = np.arange(size)# 这里使用的是偏移plt.bar(x, a, width=0.5, label='a',fc='r')plt.bar(x, b, bottom=a, width=0.5, label='b', fc='g')plt.bar(x, c, bottom=a+b, width=0.5, label='c', fc='b')plt.ylim(0, 2.5)plt.legend()plt.grid(True)plt.show() 05 饼图5.1 普通饼图123456789101112131415import matplotlib.pyplot as pltlabels = 'Frogs', 'Hogs', 'Dogs', 'Logs'sizes = [15, 30, 45, 10]# 设置分离的距离，0表示不分离explode = (0, 0.1, 0, 0) plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)# Equal aspect ratio 保证画出的图是正圆形plt.axis('equal') plt.show() 5.2 嵌套饼图1234567891011121314151617181920212223242526import numpy as npimport matplotlib.pyplot as plt# 设置每环的宽度size = 0.3vals = np.array([[60., 32.], [37., 40.], [29., 10.]])# 通过get_cmap随机获取颜色cmap = plt.get_cmap("tab20c")outer_colors = cmap(np.arange(3)*4)inner_colors = cmap(np.array([1, 2, 5, 6, 9, 10]))print(vals.sum(axis=1))# [92. 77. 39.]plt.pie(vals.sum(axis=1), radius=1, colors=outer_colors, wedgeprops=dict(width=size, edgecolor='w'))print(vals.flatten())# [60. 32. 37. 40. 29. 10.]plt.pie(vals.flatten(), radius=1-size, colors=inner_colors, wedgeprops=dict(width=size, edgecolor='w'))# equal 使得为正圆plt.axis('equal') plt.show() 5.3 极轴饼图12345678910111213141516171819202122import numpy as npimport matplotlib.pyplot as pltnp.random.seed(19680801)N = 10theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)radii = 10 * np.random.rand(N)width = np.pi / 4 * np.random.rand(N)ax = plt.subplot(111, projection='polar')bars = ax.bar(theta, radii, width=width, bottom=0.0)# left表示从哪开始，# radii表示从中心点向边缘绘制的长度（半径）# width表示末端的弧长# 自定义颜色和不透明度for r, bar in zip(radii, bars): bar.set_facecolor(plt.cm.viridis(r / 10.)) bar.set_alpha(0.5)plt.show() 06 三维图6.1 绘制三维散点图1234567891011121314151617import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Ddata = np.random.randint(0, 255, size=[40, 40, 40])x, y, z = data[0], data[1], data[2]ax = plt.subplot(111, projection='3d') # 创建一个三维的绘图工程# 将数据点分成三部分画，在颜色上有区分度ax.scatter(x[:10], y[:10], z[:10], c='y') # 绘制数据点ax.scatter(x[10:20], y[10:20], z[10:20], c='r')ax.scatter(x[30:40], y[30:40], z[30:40], c='g')ax.set_zlabel('Z') # 坐标轴ax.set_ylabel('Y')ax.set_xlabel('X')plt.show() 6.2 绘制三维平面图12345678910111213141516from matplotlib import pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure()ax = Axes3D(fig)X = np.arange(-4, 4, 0.25)Y = np.arange(-4, 4, 0.25)X, Y = np.meshgrid(X, Y)R = np.sqrt(X**2 + Y**2)Z = np.sin(R)# 具体函数方法可用 help(function) 查看，如：help(ax.plot_surface)ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='rainbow')plt.show() 参考链接： https://mp.weixin.qq.com/s/bMvrle-FRvli0pRNi83waQ]]></content>
      <categories>
        <category>programs</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SqueezeNet]]></title>
    <url>%2F2019%2F08%2F20%2Fsqueezenet%2F</url>
    <content type="text"><![CDATA[论文地址: SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size非官方代码: pytorch 介绍这篇文章是DeepScal，加州大学伯克利分校，以及斯坦福大学在ICLR 2017发表的一篇文章。文章的主要目的是为了压缩模型，提高运行速度。这篇文章主要提出了SqueezeNet: 使用少量参数保持精度。 结构设计策略这篇文章的首要目标是在保持准确率 的同时，有几个参数的CNN架构。这篇文章在设计CNN架构的时候采取了三个主要策略。这篇文章的主要模块 是Fire模块。 用1x1的卷积核代替3x3的卷积核，从而减少参数量。1x1 卷积的参数比3x3的卷积核少了 9X. 减少3x3 卷积输入通道的数量。假设有一个卷积层, 它完全由3x3 卷积组成。此层中参数的总数量为：(输入通道数) (过滤器数) (3 * 3)。要在squeeze层中将输入的通道数减少。 在网络中减少下采样(maxpooling)实现, 以便卷积层具有较大的特征图。 Fire ModuleFire Module是将原来一层conv层变成两层：squeeze层+expand层，各自带上Relu激活层。在squeeze层里面全是1x1的卷积kernel，数量记为S11；在expand层里面有1x1和3x3的卷积kernel，expand层之后将1x1和3x3的卷积output feature maps在channel维度cat。 自己手推的一张图，字比较丑，也没时间重现写一下。 fire moudle的pytorch代码很奇怪的是论文中用的是3个1x1，以及expand用的是4个1x1的卷积核和4个 3x3的卷积核，但是pytroch版本的代码并没有体现出来。12345678910111213141516171819202122232425262728293031323334class fire(nn.Module): def __init__(self, inplanes,squeeze_planes, expand_planes): super(fire,self).__init__() self.conv1 = nn.Conv2d(inplanes,squeeze_planes, kernel_size=1, stride=1) self.bn1 = nn.BatchNorm2d(squeeze_planes) self.relu1 = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=1, stride=1) self.bn2 = nn.BatchNorm2d(expand_planes) self.conv3 = nn.Conv2d(squeeze_planes,expand_planes,kernel_size=3, stride=1,padding=1) self.bn3 = nn.BatchNorm2d(expand_planes) self.relu2 = nn.ReLU(inplace=True) # using MSR initialization for m in self.modules(): if isinstance(m,nn.Conv2d): n = m.kernel_size[0]*m.kernel_size[1]*m.in_channels m.weight.data.normal_(0,math.sqrt(2./n)) def forward(self,x): x = self.conv1(x) x = self.bn1(x) x = self.relu1(x) out1 = self.conv2(x) out1 = self.bn2(out1) out2 = self.conv3(x) out2 = self.bn3(out2) out = torch.cat([out1,out2],1) out = self.relu2(out) return out SqueezeNet的具体网络结构 实验结果imagenet数据上比较了alexnet，可以看到准确率差不多的情况下，squeezeNet模型参数数量显著降低了（下表倒数第三行），参数减少50X；如果再加上deep compression技术，压缩比可以达到461X！还是不错的结果。 参考文章：https://blog.csdn.net/xbinworld/article/details/50897870]]></content>
      <categories>
        <category>轻量级网络</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分治算法]]></title>
    <url>%2F2019%2F08%2F19%2F%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[问题： 给定一组数，要求从中找出第k小的元素。分析：这里通过快速排序算法来解决次问题。记一趟快速排序后，左子集中的元素个数为nleft，则选择问题，可能是一下几种情况之一： nleft等于k-1，则枢纽值即为所求； nleft大于k-1,则继续在左子树中找； nleft小于k-1,则继续在右子集中找C++代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344// t5.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include &quot;stdafx.h&quot;#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;#include&lt;math.h&gt;#include&lt;string.h&gt;int quickSelect(int a[], int l, int r, int k)&#123; int p = rand() % (r - l + 1) + l; int pivot = a[p]; &#123;int t = a[p]; a[p] = a[r]; a[r] = t; &#125; int i = l,j = r; while (i &lt; j) &#123; while (i &lt; j&amp;&amp;a[i] &lt; pivot) i++; if (i &lt; j) &#123; a[j] = a[i]; j--; &#125; while (i &lt; j&amp;&amp;a[i] &gt;pivot) j--; if (i &lt; j) &#123; a[i] = a[j]; i++; &#125; &#125; a[i] = pivot; p = i; if (i - l + 1 == k) return a[i]; // j + 1, right, k - (j - left + 1)1) if (i - l + 1 &lt; k) return quickSelect(a, i+1, r, k-i+l-1); else return quickSelect(a, l, i-1, k);&#125;int main()&#123; int a[] = &#123; 1,4,54,8,3,7,45,58,27,8,25,26,21,12 &#125;; printf_s(&quot;%d\n&quot;, quickSelect(a, 0, 14, 6)); system(&quot;pause&quot;); return 0;&#125;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNetsV2]]></title>
    <url>%2F2019%2F08%2F19%2FMobileNetsV2%2F</url>
    <content type="text"><![CDATA[论文地址:MobileNetV2: Inverted Residuals and Linear Bottlenecks 非官方代码:pytorch 介绍这篇文章是谷歌在2019提出来的文章在MobileNets 基础上做的改进。 深度可分离卷积示例 首先在Xception 中被广泛使用 好处： 理论上可以成倍的减少卷积层的时间复杂度和空间复杂度 文章内容与MobileNets 的对比 相同点 都采用 Depth-wise (DW) 卷积搭配 Point-wise (PW) 卷积的方式来提特征 不同点 Linear Bottleneck V2 在 DW 卷积之前新加了一个 PW 卷积。 DW卷积由于本身的计算特性不能改变通道数的能力。若通道数很少的话，DW在提取地低纬特征，效果可能并不会好。 在每个DW之前，增加了PW用于升维，这样DW可以更好的提取特征 V2 去掉了第二个 PW 的激活函数 激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征 第二个 PW 的主要功能就是降维 与ResNet的对比 相同点 MobileNet V2 借鉴 ResNet，都采用了 1x1-&gt;3x3-&gt;1x1的模式 MobileNet V2 借鉴 ResNet，同样使用 Shortcut 将输出与输入相加 不同点 Inverted Residual Block ResNet 使用 标准卷积 提特征，MobileNet 始终使用 DW卷积 提特征 ResNet 先降维 (0.25倍)、卷积、再升维，而 MobileNet V2 则是 先升维 (6倍)、卷积、再降维。直观的形象上来看，ResNet 的微结构是沙漏形，而 MobileNet V2 则是纺锤形，刚好相反。因此论文作者将 MobileNet V2 的结构称为 Inverted Residual Block。使用DW卷积而作的适配，特征提取能够在高维进行 结论 MobileNets 与MobileNets V2在模型结构上的对比 MobileNetsV2 的卷积层数比V1要多，但是时间复杂度，以及空间复杂度，以及在cpu上的推理时间要远远优于MobileNets 参考文章：https://zhuanlan.zhihu.com/p/33075914]]></content>
      <categories>
        <category>轻量级网络</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MobileNets]]></title>
    <url>%2F2019%2F08%2F19%2FMobileNets%2F</url>
    <content type="text"><![CDATA[论文地址:MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications 非官方代码:pytorch/models 前言这篇文章是谷歌在2017针对手机等嵌入式设备提出的一种轻量级深层网络，这篇论文主要的贡献点在于提出了一种深度可分离卷积。 主要解决的问题是注重优化延迟，同时也兼顾了模型的大小，不像有些模型虽然参数量比较小，但是速度也是慢的可以。 MobileNets使用了大量的3 × 3的卷积核，极大地减少了计算量（1/8到1/9之间），同时准确率下降的很少，相比其他的方法确有优势。 深度可分离卷积示例 模型结构和训练MobileNets结构建立在上述深度可分解卷积中（只有第一层是标准卷积）。该网络允许我们探索网络拓扑，找到一个适合的良好网络。其具体架构在表1说明。除了最后的全连接层，所有层后面跟了batchnorm和ReLU，最终输入到softmax进行分类。图3对比了标准卷积和分解卷积的结构，二者都附带了BN和ReLU层。按照作者的计算方法，MobileNets总共28层（1 + 2 × 13 + 1 = 28）]]></content>
      <categories>
        <category>轻量级网络</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多层感知机的反向传播]]></title>
    <url>%2F2019%2F08%2F19%2FMLP-Back-Propagation%2F</url>
    <content type="text"><![CDATA[全连接神经网络是形式上最简单的神经网络，反向传播算法是一种常用的训练神经网络的算法，理解全连接神经网络中的反向传播算法是理解其他更加复杂网络中反向传播算法的重要基础。 参考链接： https://zhuanlan.zhihu.com/p/61863634]]></content>
      <categories>
        <category>Math</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法竞赛入门经典第四章]]></title>
    <url>%2F2019%2F08%2F18%2Falgorithm4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157// t4.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;//素数判断方法2#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;#include&lt;math.h&gt;#include&lt;string.h&gt;#define Max 1000000#define maxn 100int left, chance; //还需要left位置，错chance之后就会输char s[maxn], s2[maxn]; //答案是字符串s, 玩家猜的字母序列是s2int win, lose; // win=1 表示已经赢了; lose=1 表示已经输了long fac(int n) &#123; if (0 == n || 1 == n) &#123; return 1; &#125; else &#123; return fac(n - 1)*n; &#125;&#125;// 非递归的阶乘方法 long fact(int n)&#123; long iRes = 1; for (int i = 1; i &lt;= n; i++) &#123; iRes *= i; &#125; return iRes;&#125;int combination(int m, int n)&#123; long iRes = fac(n) / (fac(m)*fac(n - m)); // long iRes = fact(n) /(fac(m)*fac(n-m)); printf_s(&quot;%ld %.2lf \n&quot;, iRes, (double)clock() / CLOCKS_PER_SEC); return iRes;&#125;// 刽子手游戏---guess函数void guess(char ch)&#123; int bad = 1; for (int i = 0; i &lt; strlen(s); i++) if (s[i] == ch) &#123; left--; s[i] = &apos; &apos;; bad = 0; &#125; if (bad) --chance; if (!chance) lose = 1; if (!left) win = 1;&#125;int main()&#123; /* 关键: 1 用素数筛选法先预处理，默认刚开始全为素数，然后对素数的倍数标记为非素数， for(int j = i*i ; j &lt;= 10000 ; j += i)&#123;iPrimeArr[j] = 1;&#125; 2 通过开根号判断素数时，可以用floor,注意浮点数加上0.5，int iRadical = floor(sqrt(n*1.0) + 0.5); 3 可以用assert()对输入的合法性进行校验，assert(n &gt;= 5 &amp;&amp; n &lt;= 10000);void assert(int exp),如果表达式的值为0则退出。*/ //int sum = 1; //for (int i = 3; i &lt;= Max; i += 2) //&#123; // //因为偶数除了2 都不是质数 // int j; // for (j = 2; j &lt;= (int)sqrt(i); j++)//利用上述结论判断 // if (i%j == 0) break; // if (j &gt; (int)sqrt(i)) // sum++; //&#125; //printf_s(&quot;Time used = %0.2f s\n&quot;, (double)clock() / CLOCKS_PER_SEC); //printf_s(&quot;%d\n&quot;, sum); //int a, b; //scanf_s(&quot;%d %d&quot;, &amp;a, &amp;b); //combination(a, b); //刽子手游戏 /* 游戏规则是这样的：计算机想一个单词让你猜，你每次可以猜一个字母。 如果单词里有那个字母，所有该字母会显示出来；如果没有那个字母，则计算机会在一幅“刽子手”画上填一笔。 这幅画一共需要7笔就能完成，因此你最多只能错6次。 注意，猜一个已经猜过的字母也算错。 在本题中，你的任务是编写一个“裁判”程序，输入单词和玩家的猜测，判断玩家赢了（You win.）、 输了（You lose.）还是放弃了（You chickened out.）。 每组数据包含3行，第1行是游戏编号（-1为输入结束标记），第2行是计算机想的单词，第3行是玩家的猜测。 后两行保证只含小写字母。 */ //char ans[21]; //char gus[28]; //int times, yes; //int chances = 7; //int win = 0; //int lose = 0; //scanf_s(&quot;%d&quot;, &amp;times); //while (times != -1) //&#123; // printf_s(&quot;Round %d\n&quot;, times); // scanf_s(&quot;%s\n %s&quot;, ans, gus); // printf_s(&quot;Round %s &amp;s\n&quot;, ans, gus); // yes = 0; // win = 0, lose = 0, chances = 7; // for (int i = 0; i &lt; strlen(gus); i++) // &#123; // int flag = 0; // for (int j = 0; j &lt; strlen(ans); j++) // &#123; // if (ans[j] == gus[i]) // &#123; // yes++; // flag = 1;//找到之后不退出，因为有一个有相同的字母 // &#125; // if (flag == 0) // &#123; // chances--; // &#125; // if (chances == 0) // &#123; // lose = 1; // printf_s(&quot;You lose.\n&quot;); // &#125; // else if (yes == strlen(ans)) // &#123; // win = 1; // printf_s(&quot;You win.\n&quot;); // break; // &#125; // if (win != 1 &amp;&amp; lose != 1) // &#123; // printf(&quot;You chickened out.\n&quot;); // &#125; // scanf_s(&quot;%d&quot;, &amp;times); // &#125; // &#125; //&#125; int rnd; while (scanf_s(&quot;%d%s%s&quot;, &amp;rnd, &amp;s, &amp;s2) == 3 &amp;&amp; rnd != -1) &#123; printf_s(&quot;%Round %d\n&quot;, rnd); win = lose = 0; left = strlen(s); chance = 7; for (int i = 0; i &lt; strlen(s2); i++) &#123; guess(s2[i]); //猜一个字母 if (win || lose) break; //检查状态 &#125; //根据结果进行输出 if (win) printf_s(&quot;You win.\n&quot;); else if (lose) printf_s(&quot;You lose.\n&quot;); else printf_s(&quot;You chickened out.\n&quot;); &#125; system(&quot;pause&quot;); return 0;&#125;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法竞赛入门经典第三章]]></title>
    <url>%2F2019%2F08%2F16%2Falgorithm3%2F</url>
    <content type="text"><![CDATA[今天心情不好，所以就敲了这一点代码，希望明天的状态能好一点！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// t3.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include &quot;stdio.h&quot;#include &lt;stdlib.h&gt;#include&lt;math.h&gt;#include&lt;time.h&gt;#define maxn 10000000 +10char s[maxn];int main()&#123; //题目1 统计个数 /*int count =0; int temp; while (~scanf_s(&quot;%d&quot;, &amp;temp)) &#123; count++; &#125; printf_s(&quot;%d&quot;, count);*/ //显示不出来 //输入一些数，求最大值、最小值和平均数 //int min, max, n, sum,count = 0; //float avg; //scanf_s(&quot;%d&quot;, &amp;n); //max = n; //min = n; //sum = n; //count++; //while (scanf_s(&quot;%d&quot;, &amp;n)!=EOF) //&#123; // count++; // sum += n; // if (n &gt; max) // max = n; // if (n &lt; min) // min = n; //&#125; //avg = sum*1.0 / count; //printf_s(&quot;%d %d %f\n&quot;, max,min,avg); //5.输入一些数 ，求出他们的方差 /*double ave, sum = 0, varance, psum = 0; int n.a[110], count = 0; while (scanf_s(&quot;%d&quot;, &amp;n) != EOF) &#123; a[count++] = n; sum += n; &#125; avg = sum*1.0 / count; for (int i = 0; i &lt; count; i++) psum += (a[i] - ave)*(a[i] - ave); variance = psum / count; print(&quot;%lf&quot;, variance);*/ scanf_s(&quot;%s&quot;, s); int tot = 0; for (int i = 0;s[i]; i++) &#123; if (s[i] == &apos;1&apos;) tot++; &#125; printf_s(&quot;%d\n&quot;, tot); system(&quot;pause&quot;); return 0;&#125;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMS]]></title>
    <url>%2F2019%2F08%2F16%2FLNMS%2F</url>
    <content type="text"><![CDATA[locality NMSLNMS是在EAST文本检测中提出的．主要原因：文本检测面临的是成千上万个几何体，如果用普通的NMS，其计算复杂度，n是几何体的个数，这是不可接受的．对上述时间复杂度问题，EAST提出了基于行合并几何体的方法，当然这是基于邻近几个几何体是高度相关的假设．注意：这里合并的四边形坐标是通过两个给定四边形的得分进行加权平均的，也就是说这里是“平均”而不是”选择”几何体*,目的是减少计算量．基本步骤1.先对所有的output box集合结合相应的阈值（大于阈值则进行合并，小于阈值则不和并），依次遍历进行加权合并，得到合并后的bbox集合；2.对合并后的bbox集合进行标准的NMS操作1234567891011121314151617181920212223242526272829303132333435363738394041424344def detect(score_map, geo_map, timer, score_map_thresh=1e-5, box_thresh=1e-8, nms_thres=0.1): &apos;&apos;&apos; restore text boxes from score map and geo map :param score_map: bs* 128 * 128 * 1 :param geo_map: ## geo_map = bs * 128 * 128 * 5 :param timer: :param score_map_thresh: threshhold for score map :param box_thresh: threshhold for boxes :param nms_thres: threshold for nms :return: &apos;&apos;&apos; if len(score_map.shape) == 4: score_map = score_map[0, :, :, 0] geo_map = geo_map[0, :, :, ] # filter the score map xy_text = np.argwhere(score_map &gt; score_map_thresh) # sort the text boxes via the y axis xy_text = xy_text[np.argsort(xy_text[:, 0])] # restore start = time.time() text_box_restored = restore_rectangle(xy_text[:, ::-1]*4, geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2 #print(&apos;&#123;&#125; text boxes before nms&apos;.format(text_box_restored.shape[0])) boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32) boxes[:, :8] = text_box_restored.reshape((-1, 8)) boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]] timer[&apos;restore&apos;] = time.time() - start # 得到box 的坐标以及分数 # nms part start = time.time() # boxes = nms_locality.nms_locality(boxes.astype(np.float64), nms_thres) boxes = lanms.merge_quadrangle_n9(boxes.astype(&apos;float32&apos;), nms_thres) timer[&apos;nms&apos;] = time.time() - start if boxes.shape[0] == 0: return None, timer # here we filter some low score boxes by the average score map, this is different from the orginal paper for i, box in enumerate(boxes): mask = np.zeros_like(score_map, dtype=np.uint8) cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32) // 4, 1) boxes[i, 8] = cv2.mean(score_map, mask)[0] boxes = boxes[boxes[:, 8] &gt; box_thresh] return boxes, timer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import numpy as npfrom shapely.geometry import Polygondef intersection(g, p): #取g,p中的几何体信息组成多边形 g = Polygon(g[:8].reshape((4, 2))) p = Polygon(p[:8].reshape((4, 2))) # 判断g,p是否为有效的多边形几何体 if not g.is_valid or not p.is_valid: return 0 # 取两个几何体的交集和并集 inter = Polygon(g).intersection(Polygon(p)).area union = g.area + p.area - inter if union == 0: return 0 else: return inter/uniondef weighted_merge(g, p): # 取g,p两个几何体的加权（权重根据对应的检测得分计算得到） g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8]) #合并后的几何体的得分为两个几何体得分的总和 g[8] = (g[8] + p[8]) return gdef standard_nms(S, thres): #标准NMS order = np.argsort(S[:, 8])[::-1] keep = [] while order.size &gt; 0: i = order[0] keep.append(i) ovr = np.array([intersection(S[i], S[t]) for t in order[1:]]) inds = np.where(ovr &lt;= thres)[0] order = order[inds+1] return S[keep]def nms_locality(polys, thres=0.3): &apos;&apos;&apos; locality aware nms of EAST :param polys: a N*9 numpy array. first 8 coordinates, then prob :return: boxes after nms &apos;&apos;&apos; S = [] #合并后的几何体集合 p = None #合并后的几何体 for g in polys: if p is not None and intersection(g, p) &gt; thres: #若两个几何体的相交面积大于指定的阈值，则进行合并 p = weighted_merge(g, p) else: #反之，则保留当前的几何体 if p is not None: S.append(p) p = g if p is not None: S.append(p) if len(S) == 0: return np.array([]) return standard_nms(np.array(S), thres)if __name__ == &apos;__main__&apos;: # 343,350,448,135,474,143,369,359 print(Polygon(np.array([[343, 350], [448, 135], [474, 143], [369, 359]])).area) 参考博客： https://www.jianshu.com/p/4934875f7eb6]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法竞赛入门经典第二章]]></title>
    <url>%2F2019%2F08%2F15%2Falgorithm2%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187// t2.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include &quot;stdio.h&quot;#include &lt;stdlib.h&gt;#include&lt;math.h&gt;#include&lt;time.h&gt;int main()&#123; ////3n+1问题、 //int n, count = 0; //当n过大的时候 2*n溢出 // //scanf_s(&quot;%d&quot;, &amp;n); //long long n2 = n; //while (n2 &gt; 1) //&#123; // if (n2 % 2 == 1) n2 = n2 * 3 + 1; // else n2 /= 2; // count++; //&#125; //printf_s(&quot;%d\n&quot;, count); //近似计算 /*double sum = 0; for (int i = 0;; i++) &#123; double term = 1.0 / (i * 2 + 1); if (i % 2 == 0) sum += term; else sum -= term; if (term &lt; 1e-6) break; &#125; printf_s(&quot;%.6f\n&quot;, sum);*/ // 阶乘之和 只保存后六位 //int n, S = 0; //scanf_s(&quot;%d&quot;, &amp;n); //for (int i = 1; i &lt;= n; i++) //&#123; // int factorial = 1; // for (int j = 1; j &lt;= i; j++) // factorial *= j; // S += factorial; //&#125; //printf_s(&quot;%d\n&quot;, S % 1000000); // 阶乘之和2, 优化版本 //int n, S = 0; //const int MOD = 1000000; //scanf_s(&quot;%d&quot;, &amp;n); //for (int i = 1; i &lt;= n; i++) //&#123; // int factorial = 1; // for (int j = 1; j &lt;= i; j++) // factorial = (factorial *j)%MOD; // S += factorial; //&#125; //printf_s(&quot;%d\n&quot;, S %MOD); //printf_s(&quot;Time used = %.2f\n&quot;, (double)clock() / CLOCKS_PER_SEC); // 得到程序运行的时间 单位：秒 // 数据统计 //习题2.1 水仙花数目 /*int sum; for (int i = 1; i &lt; 10; i++) for (int k = 0; k &lt; 10; k++) for (int j = 0; j &lt; 10; j++) &#123; sum = i * 100 + 10 * k + j; if(sum == i*i*i+j*j*j + k*k*k) printf_s(&quot;%d &quot;, sum); &#125;*/ //习题2.2 韩信点兵 相传韩信才智过人，从不直接清点自己军队的人数，只要让士兵先后以三人一排、五人一排、七人一排地变换队形， //而他每次只掠一眼队伍的排尾就知道总人数了。输入包含多组数据，每组数据包含3个非负整数a，b，c，表示每种队形排尾的人数（a＜3，b＜5，c＜7）， //输出总人数的最小值（或报告无解）。已知总人数不小于10，不超过100。输入到文件结束为止。 //int i, a, b, c; //scanf_s(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); //for (i = 0; i &lt;= 100; i++) &#123; // if (i % 3 == a &amp;&amp; i % 5 == b &amp;&amp; i % 7 == c) // printf_s(&quot;%d\n&quot;, i); // //&#125; //if (i % 3 != a &amp;&amp; i % 5 != b &amp;&amp; i % 7 != c &amp;&amp; i&gt;100) // printf_s(&quot;No answer\n&quot;); //习题2.3 倒三角形 //int n, /* 输出n行; n&lt;=20 */ // i, /* 打印第i行 */ // j; //scanf_s(&quot;%d&quot;, &amp;n); //for (i = 1; i &lt;= n; i = i + 1) &#123; // /* 在第i行，打印(i-1)个空格 */ // for (j = 1; j &lt;= i - 1; j = j + 1) printf_s(&quot; &quot;); // /* 在第i行，打印(2*n-2*i+1)个# */ // for (j = 1; j &lt;= (2 * n - 2 * i + 1); j = j + 1) printf_s(&quot;#&quot;); // printf_s(&quot;\n&quot;); /* 输出结束后换行，否则所有的#号在同一行输出 */ //&#125; //习题2.4 子序列的和 输入两个正整数n＜m＜10 6 ，输出 ，保留5位小数。输入包含多组数据， 注：陷阱就是在n特别大时如果直接n*n就会溢出，所以只能连除两次 //int count = 0; //while (1) &#123; // int n = 0; // int m = 0; // scanf_s(&quot;%d&quot;, &amp;n); // scanf_s(&quot;%d&quot;, &amp;m); // if (n == m&amp;&amp;n == 0) &#123; // break; // &#125; // count++; // double sum = 0; // for (int i = n; i &lt;= m; i++) &#123; // sum += 1.0 / i / i; // &#125; // printf_s(&quot;Case %d:%.5f\n&quot;, count, sum); //&#125; //习题2.5 分数化小数（decimal） //输入正整数a，b，c，输出a / b的小数形式，精确到小数点后c位。a，b≤10 ^ 6，c≤100。输入包含多组数据，结束标记为a＝b＝c＝0。 // int count = 0; //while (1) &#123; // int a, b, c; // int k, d, i; // scanf_s(&quot;%d&quot;, &amp;a); // scanf_s(&quot;%d&quot;, &amp;b); // scanf_s(&quot;%d&quot;, &amp;c); // if (a == 0&amp;&amp;b == 0 &amp;&amp;c==0 ) &#123; // break; // &#125; // count++; // for (i = 0; i&lt;c - 1; i++) // &#123; // /*机智地把余数放大十倍，使之除以b并取模*/ // k = (k%b) * 10; // printf_s(&quot;Case %d:%.5f\n&quot;, count, k / b); // &#125; // k = (k%b) * 10; // d = (k%b) * 10 / b; // if (d &gt;= 5)//判断第c+1位小数是否大于等于5，if yes,第c位小数要进1 // &#123; // printf_s(&quot;Case %d:%.5f\n&quot;, count, k / b + 1); // &#125; // else // &#123; // printf_s(&quot;Case %d:%.5f\n&quot;, count, k / b); // &#125; // //&#125; int abc,def,ghi; int a[10],count=0; memset(a,0,sizeof(a)); // 将a数组中的值全部设置为0 for (abc = 123;abc &lt; 333;abc ++) &#123; // 基本可以确定abc的最小值和最大值 def = 2 * abc; ghi = 3 * abc; // 设置数组中所有对应的9位数字位置的值1 a[abc/100] = 1; // a a[abc/10%10] = 1; // b a[abc%10] = 1; // c a[def/100] = 1; // d a[def/10%10] = 1; // e a[def%10] = 1; // f a[ghi/100] = 1; // g a[ghi/10%10] = 1; // h a[ghi%10] = 1; // i int i; for (i=1;i&lt;=9;i++) &#123; count += a[i]; &#125; if (count == 9) &#123; printf_s(&quot;%d %d %d\n&quot;,abc,def,ghi); &#125; // 重置count 和a数组 count = 0; memset(a,0,sizeof(a)); &#125; system(&quot;pause&quot;); return 0; &#125;]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法竞赛入门经典第一章]]></title>
    <url>%2F2019%2F08%2F14%2Falgorithm1%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110// t1.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include &quot;stdio.h&quot;#include &lt;stdlib.h&gt;#include&lt;math.h&gt; int main()&#123; //printf(&quot;%.1f\n&quot;, 8.0 / 5.0); // %点后面是保留几位浮点小数1.6 //printf(&quot;%.1f\n&quot;, 8 / 5); // %点后面是保留几位浮点小数 结果为0 //printf(&quot;%d\n&quot;, 8.0 / 5.0); // 整数值用%d输出，实数用%f输出 # int 是2字节 ，float是4字节 溢出 // //整数/整数等与整数，浮点数除以浮点数等于浮点数 //printf(&quot;%.8f\n&quot;, 1 + 2 * sqrt(3) / (5 - 0.1)); //int a, b; //scanf_s(&quot;%d%d&quot;, &amp;a, &amp;b); //scanf_s 中的占位符要和变量的数据类型一一对应，要在变量前面加上“&amp;”符号 //printf(&quot;%d\n&quot;, a+b); //const double pi = acos(-1.0); //double r, h, s1, s2, s; //scanf_s(&quot;%1f%1f&quot;, &amp;r, &amp;h); //s1 = pi*r*r; //s2 = 2 * pi*r*h; //s = s1*2.0 + s2; //printf_s(&quot;Area = %.3f\n&quot;, s); //交换变量 //int a, b, m, n; //scanf_s(&quot;%d%d&quot;, &amp;a, &amp;b); ///*a = a + b; //b = a - b; //a = a - b;*/ //printf_s(&quot;%d %d\n&quot;, b, a); //int a, b, m, n; //scanf_s(&quot;%d%d&quot;, &amp;n, &amp;m); ///*a = a + b; //b = a - b; //a = a - b;*/ //a = (4*n-m) / 2; //b = n - a; //if (m % 2 == 1 || a &lt; 0 || b &lt; 0) // printf_s(&quot;No answer!\n&quot;); //else // printf_s(&quot;Answer is chicken %d rabbit %d\n&quot;, a, b); //exp1 输入三个整数，求出他们的平均数，保留三位小数 //int a, b, c; //scanf_s(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); //printf_s(&quot;%.3f&quot;, (a + b + c) / 3.0); //exp2 输入华氏温度f,输出对应的摄氏温度c,保留3位小数.提示 : c = 5(f-32)/9. //float f, c; //scanf_s(&quot;%f&quot;, &amp;f); //c = 5*(f - 32) / 9.0; //printf_s(&quot;摄制温度为： %.3f&quot;, c); //exp3 //int n; //scanf_s(&quot;%d&quot;, &amp;n); //printf_s(&quot;%d&quot;, n*(n + 1) / 2); //exp4 输入正整数《360 ，输出正弦余弦函数值。提示：使用数学函数 //int n; // #define PI 3.1415926 //scanf_s(&quot;%d&quot;, &amp;n); //if (n &lt; 0 || n&gt;360) // printf_s(&quot;error&quot;); //else //&#123; // printf_s(&quot;%.2f\n&quot;, cos(n*PI/180)); // printf_s(&quot;%.2f&quot;, sin(n*PI / 180)); //&#125; // // exp5 一件衣服95元，若消费满300元可以打85折，输入购买衣服的简书，输出需要支付的金额。保留两位小数 //int n,money; //scanf_s(&quot;%d&quot;, &amp;n); //money = n * 95; //if (money &gt; 300) // printf_s(&quot;%.2f&quot;, money* 0.85); //else // printf_s(&quot;%.2f&quot;, money); // //exp6 判断三个边是否能构成直角三角形 边长均为正整数 //int a, b, c; //scanf_s(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c); //if (((a*a + b*b)== c*c) || ((a*a + c*c) == b*b) || ((c*c + b*b) == a*a)) // printf_s(&quot;yes\n&quot;); //else // printf_s(&quot;not a triangle\n&quot;); //exp7 判断一个年是不是闰年 能被4整除但是不能被100整除的年份 //int n; //scanf_s(&quot;%d&quot;, &amp;n); //if (n % 4 == 0 &amp;&amp; n % 100 != 0) // printf_s(&quot;yes\n&quot;); //else // printf_s(&quot;no\n&quot;); // //q1: int类型的最大值和最小值是多少 2^(n - 1) - 1 -2^(n - 1) //q2; double浮点数能精确到多少位小数？ 遵循IEEE标准的8字节（64位）的double能表示的有效数字的位数是：15 ~ 16 //q3: double类型的最大正数值和最小正数值 //q4: 逻辑运算符号的优先级 system(&quot;pause&quot;); return 0;&#125; 思考题解析： https://blog.csdn.net/panderang/article/details/54096426]]></content>
      <categories>
        <category>programs</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F29%2F%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[文本检测问题，广义上来说可以看做是一个目标检测的问题，但是相当于目标检测要简单的多。因为目标检测往往除了背景还有其他的类，而文本检测，只需要检测背景和文本类两个问题。因此可以采用目标检测或者分割的方法来进行文本检测。而视频中的文本检测，也可以看做是视频中的目标检测中的一种，感觉应该也可以用视频中的目标检测+跟踪来做。 通常目标跟踪面临的极大难点：物体变形、亮度变化、快速移动、背景干扰覆盖。其中最主要的三个难题分别是目标背景的变化，物体本身的变化，光照强度的变化。 光流法帧间差分法背景差分法]]></content>
  </entry>
  <entry>
    <title><![CDATA[c++中级教程 顺序容器的定义]]></title>
    <url>%2F2019%2F07%2F26%2F%E9%A1%BA%E5%BA%8F%E5%AE%B9%E5%99%A8%E7%9A%84%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[顺序容器的定义 顺序容器 vector list deque 顺序容器适配器 stack queue priority_queue]]></content>
      <categories>
        <category>programs</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++中级教程 STL queue]]></title>
    <url>%2F2019%2F07%2F26%2FSTLqueue%2F</url>
    <content type="text"><![CDATA[STL queue 队列： FIFO 先进先出 自适应容器（容器适配器） 栈适配器 STL queue12345678queue&lt;int, deque&lt;int&gt;&gt; q;queue&lt;int, list&lt;int&gt;&gt; q;q.empty()q.size()q.front()q.back()q.pop()q.push(item) 可以用list和deque做queue先进先出，后进后出12345678910111213141516171819202122232425262728293031323334353637383940// queue.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;list&gt;#include&lt;deque&gt;using namespace std;int main()&#123; queue&lt;int, deque&lt;int&gt;&gt; a; queue&lt;int, list&lt;int&gt;&gt; b; //queue&lt;int, vector&lt;int&gt;&gt; c; 不可以，因为vector不能进行两端操作 //队列有什么用途？？？ queue&lt;int&gt; q; q.push(10); q.push(5); q.push(-1); q.push(20); cout &lt;&lt; "现在队列里有" &lt;&lt; q.size() &lt;&lt; "个数据 " &lt;&lt; endl; cout &lt;&lt; "队首的数据：" &lt;&lt; q.front() &lt;&lt; endl; cout &lt;&lt; "队尾的数据：" &lt;&lt; q.back() &lt;&lt; endl; q.pop(); cout &lt;&lt; "新的队首的数据：" &lt;&lt; q.front() &lt;&lt; endl; while (q.size() != 0) &#123; cout &lt;&lt; " 删除" &lt;&lt; a.front() &lt;&lt; endl; q.pop(); &#125; if (q.empty()) &#123; cout &lt;&lt; "队列为空！"&lt;&lt;endl; &#125; system("pause"); return 0;&#125; 优先级队列 priority_queue 自适应容器（容器适配器）：不能使用list 最大值优先级队列、最小值优先级队列(值越大，优先级越高，值越小优先级越高) 优先级队列适配器 STL priority_queue 1234567891011priority_queue&lt;int, deque&lt;int&gt;&gt; pg1;//对队列里的数据进行随机操作，所以不能使用listpriority_queue&lt;int, vector&lt;int&gt;&gt; pg2; //vector是默认的 //谓词priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; pg2; //vector是默认的，最小优先队列pg.empty()pg.size()pg.top()pg.pop()pg.push(item)~~~~~~~~~~ 1234567891011121314151617181920212223242526272829303132333435363738394041// priority_queue.cpp : 定义控制台应用程序的入口点。//#include &quot;stdafx.h&quot;#include&lt;iostream&gt;#include&lt;deque&gt;#include&lt;vector&gt;#include&lt;queue&gt;using namespace std;int main()&#123; priority_queue&lt;int, deque&lt;int&gt;&gt; pg1; //对队列里的数据进行随机操作，所以不能使用list priority_queue&lt;int, vector&lt;int&gt;&gt; pg2; //vector是默认的 //谓词 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; pg2; //vector是默认的，最小优先队列 pg2.push(10); pg2.push(5); pg2.push(-1); pg2.push(20); cout &lt;&lt; &quot;优先级队列一共有： &quot; &lt;&lt; pg2.size() &lt;&lt; &quot;个数据&quot; &lt;&lt; endl; cout &lt;&lt; pg2.top() &lt;&lt; endl; while (!pg2.empty()) &#123; cout &lt;&lt; &quot;从优先级队列里删除： &quot; &lt;&lt; pg2.top() &lt;&lt; endl; pg2.pop(); &#125; system(&quot;pause&quot;); return 0;&#125;优先级队列一共有： 4个数据20从优先级队列里删除： 20从优先级队列里删除： 10从优先级队列里删除： 5从优先级队列里删除： -1请按任意键继续. . .~~]]></content>
      <categories>
        <category>programs</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firstblog]]></title>
    <url>%2F2019%2F07%2F25%2Ffirstblog%2F</url>
    <content type="text"><![CDATA[以上是摘要 Hello World]]></content>
      <categories>
        <category>dailylife</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++中级教程(一)]]></title>
    <url>%2F2019%2F07%2F25%2F%E9%A1%BA%E5%BA%8F%E5%AE%B9%E5%99%A8-STL-deque-%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[顺序容器 STL deque 类 deque是一个动态数组 deque与vector 非常类似 deque可以在数组开头和末尾插入和删除数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// demo3.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include &lt;iostream&gt;#include &lt;deque&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; deque&lt;int&gt; a; a.push_back(3); a.push_back(4); a.push_back(5); a.push_back(6); //vector只能push_back a.push_front(2); a.push_front(1); a.push_front(9); a.push_front(8); for (size_t nCount = 0; nCount &lt; a.size(); ++nCount) &#123; cout &lt;&lt;"a["&lt;&lt;nCount&lt;&lt;"]" &lt;&lt; "= " &lt;&lt; a[nCount] &lt;&lt; endl; &#125; cout &lt;&lt; endl&lt;&lt;endl; a.pop_front();// 前面删除 a.pop_back();// 后面删除 cout &lt;&lt; "删除之后：" &lt;&lt; endl; /*for (size_t nCount = 0; nCount &lt; a.size(); ++nCount) &#123; cout &lt;&lt; "a[" &lt;&lt; nCount &lt;&lt; "]" &lt;&lt; a[nCount] &lt;&lt; endl; &#125;*/ deque&lt;int&gt;::iterator iElementLocater; //这边使用了迭代器 distence 可以计算当前 for (iElementLocater = a.begin(); iElementLocater != a.end(); ++iElementLocater) &#123; size_t nOffset = distance(a.begin(), iElementLocater);//distence 可以计算当前下标与begin开始的，距离正好是下标 cout &lt;&lt; "a[" &lt;&lt; nOffset &lt;&lt; "]" &lt;&lt; "= "&lt;&lt;*iElementLocater &lt;&lt; endl; &#125; system("pause"); return 0;&#125;a[0]= 8a[1]= 9a[2]= 1a[3]= 2a[4]= 3a[5]= 4a[6]= 5a[7]= 6删除之后：a[0]= 9a[1]= 1a[2]= 2a[3]= 3a[4]= 4a[5]= 5请按任意键继续. . . 順序容器 STL list 類 实例化std::list对象 在list开头插入元素 在list末尾插入元素 在list中间插入元素 删除list中的元素 对list中的元素进行反转和排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// list.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include&lt;iostream&gt;#include&lt;list&gt;using namespace std;void PrintListContent(const list&lt;int&gt;&amp; listInput);int main()&#123; list&lt;int&gt; a; list&lt;int&gt; b; b.push_back(100); b.push_back(200); b.push_back(300); b.push_back(400); b.push_back(500); PrintListContent(b); cout &lt;&lt; endl; a.push_front(4); a.push_front(3); a.push_front(2); a.push_front(1); a.push_back(5); //使用链表数据，不能使用下标，只能使用迭代器 list&lt;int&gt;::iterator iter; iter = a.begin(); a.insert(iter, 10);// 在begin前面插入10，第一个参数迭代器，指定插入的位置 a.insert(a.end(),10); PrintListContent(a); //将b插入到a之中 a.insert(a.begin(), b.begin(), b.end()); a.insert(iter,++b.begin(),--b.end()) PrintListContent(a); system("pause"); return 0;&#125;void PrintListContent(const list&lt;int&gt;&amp; listInput)&#123; //会是一个底层 const，即其所指对象可以改变，但不能改变其所指对象的值。 list&lt;int&gt;::const_iterator iter; for (iter = listInput.begin(); iter != listInput.end(); ++iter) &#123; cout &lt;&lt; *iter &lt;&lt; endl; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// listdelet.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include&lt;iostream&gt;#include&lt;list&gt;using namespace std;void PrintListContent(const list&lt;int&gt;&amp; listInput);int main()&#123; list&lt;int&gt; a; a.push_front(4); a.push_front(3); list&lt;int&gt;::iterator iElementValueTwo; iElementValueTwo = a.insert(a.begin(),2); // inset 才返回迭代器迭代器指向这个位置 a.push_front(1); a.push_back(0); cout &lt;&lt; "删除之前" &lt;&lt; endl; PrintListContent(a); // 删除2 cout &lt;&lt; "删除之后" &lt;&lt; endl; a.erase(iElementValueTwo); //a.erase(a.beigin(),iElementValueTwo); 删除从第一个迭代器到第二个迭代器所有的数据 PrintListContent(a); system("pause"); return 0;&#125;void PrintListContent(const list&lt;int&gt;&amp; listInput)&#123; //会是一个底层 const，即其所指对象可以改变，但不能改变其所指对象的值。 cout &lt;&lt; "&#123;"; list&lt;int&gt;::const_iterator iter; for (iter = listInput.begin(); iter != listInput.end(); ++iter) &#123; cout &lt;&lt; *iter &lt;&lt; " "; &#125; cout &lt;&lt; "&#125;" &lt;&lt; endl;&#125;删除之前&#123;1 2 3 4 0 &#125;删除之后&#123;1 3 4 0 &#125;请按任意键继续. . . 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// list3.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include&lt;iostream&gt;#include&lt;list&gt;using namespace std;void PrintListContent(const list&lt;int&gt;&amp; listInput);int main()&#123; list&lt;int&gt; a; a.push_front(4); a.push_front(3); a.push_front(2); a.push_front(1); PrintListContent(a); cout &lt;&lt; "反转之后的数据：" &lt;&lt; endl; a.reverse(); PrintListContent(a); list&lt;int&gt; b; b.push_front(4); b.push_front(53); b.push_front(24); b.push_front(132); PrintListContent(b); cout &lt;&lt; "排序之后的数据：" &lt;&lt; endl; b.sort(); PrintListContent(b); system("pause"); return 0;&#125;void PrintListContent(const list&lt;int&gt;&amp; listInput)&#123; //会是一个底层 const，即其所指对象可以改变，但不能改变其所指对象的值。 cout &lt;&lt; "&#123;"; list&lt;int&gt;::const_iterator iter; for (iter = listInput.begin(); iter != listInput.end(); ++iter) &#123; cout &lt;&lt; *iter &lt;&lt; " "; &#125; cout &lt;&lt; "&#125;" &lt;&lt; endl;&#125;&#123;1 2 3 4 &#125;反转之后的数据：&#123;4 3 2 1 &#125;&#123;132 24 53 4 &#125;排序之后的数据：&#123;4 24 53 132 &#125;请按任意键继续. . .]]></content>
      <categories>
        <category>programs</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++中级教程 STL stack]]></title>
    <url>%2F2019%2F07%2F25%2FSTL-stack%2F</url>
    <content type="text"><![CDATA[STL stack (堆) 栈： LIFO 后进先出 自适应容器（容器适配器） 栈适配器 STL stack1234567stack&lt;int, deque&lt;int&gt;&gt; s;stack&lt;int, vector&lt;int&gt;&gt; s;stack&lt;int, list&lt;int&gt;&gt; s;s.empty()s.size()s.pop()s.push(item) 123456789101112131415161718192021222324252627282930313233343536373839404142434445// stack1.cpp : 定义控制台应用程序的入口点。//#include "stdafx.h"#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;stack&gt;using namespace std;int main()&#123; stack&lt;int, deque&lt;int&gt;&gt; a; stack&lt;int, vector&lt;int&gt;&gt; b; stack&lt;int, list&lt;int&gt;&gt; c; stack&lt;int&gt; d; //默认用deque //什么是堆栈？ 先进后出，后进先出 d.push(25); d.push(10); d.push(1); d.push(5); int x = 0; cout &lt;&lt; "现在栈里一共有：" &lt;&lt; d.size() &lt;&lt; "个数据。" &lt;&lt; endl; while (d.empty() == false) &#123; x = d.top(); //查看数据并且返回 d.pop();//删除，不返回 cout &lt;&lt; x &lt;&lt; endl; &#125; //x = d.top(); //查看数据并且返回 //d.pop();//删除，不返回 //cout &lt;&lt; x &lt;&lt; endl; cout &lt;&lt; "现在栈里一共有：" &lt;&lt; d.size() &lt;&lt; "个数据。" &lt;&lt; endl; system("pause"); return 0;&#125;现在栈里一共有：4个数据。511025现在栈里一共有：0个数据。请按任意键继续. . .]]></content>
      <categories>
        <category>programs</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
</search>
