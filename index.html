<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<script>
(function(){
    if(''){
        if (prompt('请输入文章密码') !== ''){
            alert('密码错误！');
            history.back();
        }
    }
})();
</script>











  <link rel="apple-touch-icon" sizes="180x180" href="/images/icon.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="hello,every body!~">
<meta property="og:type" content="website">
<meta property="og:title" content="一只程序猿的小小博客">
<meta property="og:url" content="https://caius-lu.github.io/index.html">
<meta property="og:site_name" content="一只程序猿的小小博客">
<meta property="og:description" content="hello,every body!~">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一只程序猿的小小博客">
<meta name="twitter:description" content="hello,every body!~">



  <link rel="alternate" href="/atom.xml" title="一只程序猿的小小博客" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://caius-lu.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>一只程序猿的小小博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
<a href="https://github.com/Caius-Lu" class="github-corner" aria-label="View source on GitHub">
<svg width="80" height="80" viewbox="0 0 250 250" style="fill:#64CEAA; 
color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z">
</path>
<path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px)
{.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">一只程序猿的小小博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">努力热爱生活</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/27/SENet-code/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/27/SENet-code/" class="post-title-link" itemprop="url">Attention机制中SEnet CBAM以及Dual pooling的pytorch实现</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-27 21:44:15" itemprop="dateCreated datePublished" datetime="2019-12-27T21:44:15+08:00">2019-12-27</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-12-28 15:56:34" itemprop="dateModified" datetime="2019-12-28T15:56:34+08:00">2019-12-28</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/attention/" itemprop="url" rel="index"><span itemprop="name">attention</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本来自己写了，关于SENet的注意力截止，但是在准备写其他注意力机制代码的时候，看到一篇文章总结的很好，所以对此篇文章进行搬运，以供自己查阅，并加上自己的理解。</p>
</blockquote>
<p>[TOC]</p>
<h2 id="1-SENET中的channel-wise加权的实现"><a href="#1-SENET中的channel-wise加权的实现" class="headerlink" title="1.SENET中的channel-wise加权的实现"></a>1.SENET中的channel-wise加权的实现</h2><p>实现代码参考自：<a href="https://github.com/moskomule/senet.pytorch" target="_blank" rel="noopener">senet.pytorch</a><br><img src="//caius-lu.github.io/2019/12/27/SENet-code/senet.png" alt="senet"><br>代码如下：<br>SEnet 模块<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SELayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, channel, reduction=<span class="number">16</span>)</span>:</span></span><br><span class="line">        super(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y. (x)</span><br></pre></td></tr></table></figure></p>
<p><img src="//caius-lu.github.io/2019/12/27/SENet-code/senet2.png" alt="senet2"><br>以上代码设计到的API：</p>
<ul>
<li>AdaptiveAvgPool2d: 自适应平均池化，参数为（n,m）则将原来的feature（w,h）通过pooling得到（n,m）的feature，如果是（n）,则将原来的feature从（w,h）通过pooling得到（n,n）</li>
<li>Sequential: torch容器，存放网络层等内容。</li>
<li>Linear: 线性层，参数为（in, out）,将原有的in个feature转为out个feature</li>
<li>ReLU: 激活层， inplace进行原地操作，节省内存</li>
<li>Sigmoid: 激活层，将输入压缩到0-1<br>分析forward进行模型的构建：</li>
<li>x是输入的feature,一般各个通道意义如下：（batch size，channel, width , height）,这里获取了batch(b), channel</li>
<li><p>x通过AdaptiveAvgPool2d(1)以后将得到（batch size, channel, 1, 1）, 然后view（b,c）意思是按照b,c进行展开</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> torch</span><br><span class="line">In [<span class="number">2</span>]:  x = torch.zeros((<span class="number">16</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>))</span><br><span class="line">In [<span class="number">3</span>]:  <span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">In [<span class="number">4</span>]: avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">In [<span class="number">5</span>]: avg_pool(x).shape</span><br><span class="line">Out[<span class="number">5</span>]: torch.Size([<span class="number">16</span>, <span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">In [<span class="number">6</span>]: avg_pool(x).view((<span class="number">16</span>,<span class="number">256</span>)).shape</span><br><span class="line">Out[<span class="number">6</span>]: torch.Size([<span class="number">16</span>, <span class="number">256</span>])</span><br><span class="line">In [<span class="number">7</span>]: avg_pool(x).squeeze().shape <span class="comment"># squeeze()函数也可以将所有通道个数为1的进行挤压</span></span><br><span class="line">Out[<span class="number">7</span>]: torch.Size([<span class="number">16</span>, <span class="number">256</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后形状为【16, 256】的tensor经过fc:</p>
</li>
<li>(1) Linear: from 256(channel) to 256/16</li>
<li>(2) ReLu：进行一次激活函数</li>
<li>(3) Linear: from 256/16 to 256(channel)</li>
<li>(4) Sigmoid: 激活到0-1，代表每个通道的重要性</li>
<li>然后通过view操作转化为【16,256,1,1】形状的tensor</li>
<li>现在y得到的是每一个通道对应的分数（0-1），然后需要将其与通道内容相乘，具体操作使用到了tensor的内置函数expand_as(把一个tensor变成和函数括号内一样形状的tensor，用法与expand类似，相当于expand(tensor.size())</li>
<li>x是【16,256,256,256】形状的特征图，y是【16,256,1,1】大小的channel-wise分数，然后需要将其相乘</li>
<li>b.expand_as(a)就是将b进行扩充，扩充到a的维度，需要说明的是a的低维度需要比b大，例如b的shape是3*1，如果a的shape是3*2不会出错，但是是2*2就会报错了。<br>就是必须有一个维度是1，然后用于扩展：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [8]: tensor1 = torch.ones((3,4,1,1))</span><br><span class="line">In [9]: tensor1.expand([3,4,5,5]).shape</span><br><span class="line">Out[9]: torch.Size([3, 4, 5, 5])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>这样通过expand_as就能得到【16,256,256,256】大小的tensor，其中256*256都是对应通道的1分数，然后与原先的feature相乘，就能得到channel-wise分数计算后的feature。</p>
<p>在resetnet中的block插入senet模块<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CifarSEBasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, reduction=<span class="number">16</span>)</span>:</span></span><br><span class="line">       super(CifarSEBasicBlock, self).__init__()</span><br><span class="line">       self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">       self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">       self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">       self.conv2 = conv3x3(planes, planes)</span><br><span class="line">       self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">       self.se = SELayer(planes, reduction)</span><br><span class="line">       <span class="keyword">if</span> inplanes != planes:</span><br><span class="line">           self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                                           nn.BatchNorm2d(planes))</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           self.downsample = <span class="keyword">lambda</span> x: x</span><br><span class="line">       self.stride = stride</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">       residual = self.downsample(x)</span><br><span class="line">       out = self.conv1(x)</span><br><span class="line">       out = self.bn1(out)</span><br><span class="line">       out = self.relu(out)</span><br><span class="line"></span><br><span class="line">       out = self.conv2(out)</span><br><span class="line">       out = self.bn2(out)</span><br><span class="line">       out = self.se(out)</span><br><span class="line"></span><br><span class="line">       out += residual</span><br><span class="line">       out = self.relu(out)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>
<p>正常的resent的BasicBlock<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        <span class="keyword">if</span> inplanes != planes:</span><br><span class="line">            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                                            nn.BatchNorm2d(planes))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.downsample = <span class="keyword">lambda</span> x: x</span><br><span class="line">        self.stride = stride</span><br></pre></td></tr></table></figure></p>
<p>baseline:0.888<br>se+baseline:0.892</p>
<h2 id="2-CBAM中的通道注意力机制"><a href="#2-CBAM中的通道注意力机制" class="headerlink" title="2.CBAM中的通道注意力机制"></a>2.CBAM中的通道注意力机制</h2><p>channel-attention-module跟以上内容想法有一点像，给每个channel进行打分，具体实现如下：<br>参考来源：<a href="https://github.com/luuuyi/CBAM.PyTorch/blob/master/model/resnet_cbam.py" target="_blank" rel="noopener">CBMA.pytorch</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_planes, ratio=<span class="number">16</span>)</span>:</span></span><br><span class="line">        super(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1   = nn.Conv2d(in_planes, in_planes // <span class="number">16</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2   = nn.Conv2d(in_planes // <span class="number">16</span>, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))</span><br><span class="line">        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))</span><br><span class="line">        out = avg_out + max_out</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(out)</span><br></pre></td></tr></table></figure></p>
<p>API跟上边类似，只添加了卷积，也很简单。需要说明的是貌似Linear和Conv2d中的参数很相似，但是实际上，两者还是很不一样的，Linear接受的是线性的2维数组（batch, 一维特征），Con2d接受的是4维数组（batch, 通道，w, h）。<br><img src="//caius-lu.github.io/2019/12/27/SENet-code/ch.png" alt="ch"><br>forward函数：</p>
<ul>
<li>第一行，进行了adaptiveAvgPooling， conv2d, relu, conv2d</li>
<li>第二行，进行了AdaptiveMaxPooling, conv2d, relu, conv2d</li>
<li>第三行，将两个向量进行相加</li>
<li>第四行，将对应结果进行激活，得到通道注意力分数<h2 id="3-CBAM中的空间注意力机制"><a href="#3-CBAM中的空间注意力机制" class="headerlink" title="3.CBAM中的空间注意力机制"></a>3.CBAM中的空间注意力机制</h2>参考来源：<a href="https://github.com/luuuyi/CBAM.PyTorch/blob/master/model/resnet_cbam.py" target="_blank" rel="noopener">CBMA.pytorch</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel_size=<span class="number">7</span>)</span>:</span></span><br><span class="line">        super(SpatialAttention, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">'kernel size must be 3 or 7'</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        max_out, _ = torch.max(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="//caius-lu.github.io/2019/12/27/SENet-code/sa.png" alt="sa"><br>Spatial attention module中支持kernel_size=3或者7，默认设置为7。<br>以上涉及到的API:</p>
<ul>
<li>torch.mean: 求平均值，dim指的是沿着某一个通道进行计算平均值。这里dim=1，说明沿着通道channel进行平均，对所有channel的feature上相应的像素进行求平均值。</li>
<li>torch.max: 同上，进行求最大值。<br>forward函数：</li>
<li>第一行：沿着通道维度进行进行平均，得到一个（batch, 1, w, h）的feature</li>
<li>第二行：沿着通道维度进行求最大值，得到一个（batch, 1, w, h）的feature</li>
<li>第三行：将两个feature通过cat的方式拼接起来，得到一个（batch, 2, w, h）的feature</li>
<li>第四行：对这个feature进行卷积<script type="math/tex; mode=display">
out feature =\frac{\text { in feautre }+2 \times \text { padding - kernel_size }}{\text { stride }}+1</script>之所以设置如果kernel_size=7的时候padding=3是因为需要将out_feature和in_feature相等，可以带入公式进行计算。</li>
<li>第五行：进行激活，将得分约束至[0-1]<h2 id="4-CBAM中的融合"><a href="#4-CBAM中的融合" class="headerlink" title="4.CBAM中的融合"></a>4.CBAM中的融合</h2>参考代码：<a href="https://github.com/luuuyi/CBAM.PyTorch/blob/master/model/resnet_cbam.py" target="_blank" rel="noopener">CBMA.pytorch</a><br>在resnet中主要是用在basicBlock中，代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None)</span>:</span></span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line"></span><br><span class="line">        self.ca = ChannelAttention(planes)</span><br><span class="line">        self.sa = SpatialAttention()</span><br><span class="line"></span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        residual = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        out = self.ca(out) * out <span class="comment"># 广播机制</span></span><br><span class="line">        out = self.sa(out) * out <span class="comment"># 广播机制</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p><img src="//caius-lu.github.io/2019/12/27/SENet-code/cbam.png" alt="cbam"></p>
<h2 id="5-dual-pooling的pytorch实现"><a href="#5-dual-pooling的pytorch实现" class="headerlink" title="5.dual pooling的pytorch实现"></a>5.dual pooling的pytorch实现</h2><p>max pooling更注重重要的局部特征, average pooling更关注全局特征.两者concat可以丰富特征层.<br>参考链接:<a href="https://zhuanlan.zhihu.com/p/93806755" target="_blank" rel="noopener">GaryLIU</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">res18</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes)</span>:</span></span><br><span class="line">        super(res18, self).__init__()</span><br><span class="line">        self.base = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">        self.feature = nn.Sequential(</span><br><span class="line">            self.base.conv1,</span><br><span class="line">            self.base.bn1,</span><br><span class="line">            self.base.relu,</span><br><span class="line">            self.base.maxpool,</span><br><span class="line">            self.base.layer1,</span><br><span class="line">            self.base.layer2,</span><br><span class="line">            self.base.layer3,</span><br><span class="line">            self.base.layer4</span><br><span class="line">        )</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line">        self.reduce_layer = nn.Conv2d(<span class="number">1024</span>, <span class="number">512</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc  = nn.Sequential(</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, num_classes)</span><br><span class="line">            )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        bs = x.shape[<span class="number">0</span>]</span><br><span class="line">        x = self.feature(x)</span><br><span class="line">        x1 = self.avg_pool(x)</span><br><span class="line">        x2 = self.max_pool(x)</span><br><span class="line">        x = torch.cat([x1, x2], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.reduce_layer(x).view(bs, <span class="number">-1</span>)</span><br><span class="line">        logits = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这种是在模型层进行改造的一种小trick了，常见的做法：global max/average pooling + fc layer，这里试concat(global max-pooling, global average pooling) + fc layer，其实就是为了丰富特征层，max pooling更加关注重要的局部特征，而average pooling试更加关注全局的特征。不一定有效，我试过不少次，有效的次数比较少，但不少人喜欢这样用.<br>-gray<br>以上就是dual pooling的实现，具体分析如下：</p>
<ul>
<li>第一行：得到batch-size</li>
<li>第二行：得到feature, gray大佬这里用的是一个sequential将所有的模块装载进来，其实也可以用这种方法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.base_model = nn.Sequential(*list(model_ft.children())[:<span class="number">-3</span>]) <span class="comment"># 取除了后三个全部的层</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<p>children方法里就是返回当前模型子模块的迭代器，可以查看源代码，然后选择将其中一部分去掉，比如fc层等，也可以使用gray大佬的这种方法。<br>查找的过程中找到一个中间层可视化的简单代码：<a href="https://www.jianshu.com/p/0a23db1df55a" target="_blank" rel="noopener">https://www.jianshu.com/p/0a23db1df55a</a></p>
<ul>
<li>第四，五行，通过avg_pool,max_pool得到对应的feature</li>
<li>第六行，进行concate操作，进行拼接</li>
<li>第七行，使用了一个卷积层进行降维通道，并进行view展开成一维向量。</li>
<li>第八层，进行全连接层的分类。<br>参考链接：<br><a href="https://blog.csdn.net/DD_PP_JJ/article/details/103318617" target="_blank" rel="noopener">https://blog.csdn.net/DD_PP_JJ/article/details/103318617</a></li>
</ul>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/27/SpatialSense/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/27/SpatialSense/" class="post-title-link" itemprop="url">SpatialSense</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-27 14:11:38" itemprop="dateCreated datePublished" datetime="2019-12-27T14:11:38+08:00">2019-12-27</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-12-28 13:48:37" itemprop="dateModified" datetime="2019-12-28T13:48:37+08:00">2019-12-28</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/SpatialSense/" itemprop="url" rel="index"><span itemprop="name">SpatialSense</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>理解图像中物体之间的空间关系是一项具有惊人挑战性的任务(图1)。椅子可能“在”一个人的“后面”，即使它出现在人的左边(取决于人面对的方向)。如果有第三个学生在他们之间，那么两个看起来很近的学生实际上可能并不“挨着”。<br>我们介绍了spatial alsense，这是一个专门研究空间关系识别的数据集，它捕捉了广泛的此类挑战，允许对计算机视觉技术进行适当的基准测试。空间感知是通过对抗性的众包来构建的，在众包中，人类注释者的任务是发现空间关系，这些关系很难用简单的线索来预测，比如二维空间结构或语言先验。与现有的数据集相比，对抗性众包大大减少了数据集的偏倚，并在长尾抽取了更有趣的关系样本。在空间感方面，最先进的识别模型与简单的基线相比，表现得更为出色，这表明它们依赖于直接的线索，而不是对这个复杂的任务进行充分的推理。空间感觉基准测试为提高计算机视觉系统的空间推理能力提供了一条途径。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/26/ADVERSARIALAL-AUTOAUGMENT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/26/ADVERSARIALAL-AUTOAUGMENT/" class="post-title-link" itemprop="url">ADVERSARIALAL_AUTOAUGMENT</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-26 15:13:16" itemprop="dateCreated datePublished" datetime="2019-12-26T15:13:16+08:00">2019-12-26</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-12-27 14:11:59" itemprop="dateModified" datetime="2019-12-27T14:11:59+08:00">2019-12-27</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据增广（DA，data augmentation）已被广泛用于改善训练深度神经网络的泛化性。最近，人为设计的数据增广已逐渐被自动学习的增广策略所取代。通过在精心设计的数据增广搜索空间中找到最佳策略，AutoAugment可以显著提高图像分类任务的验证准确性。但是，这种方法在大规模问题上在计算上并不实用。在本文中，我们开发了一种对抗方法，以得出一种计算上可行的解决方案，称为Adversarial AutoAugment（对抗自动增广），可以同时优化目标相关对象和增广策略搜索损失。增广策略网络试图通过生成对抗性增广策略来增加目标网络的训练损失，而目标网络可以从较难的示例中学习更强大的功能，以提高通用性。与先前的工作相反，我们在目标网络训练中重新使用计算以进行策略评估，而无需对目标网络进行再训练。与AutoAugment相比，这使ImageNet的计算成本降低了约12倍，时间开销缩短了11倍。我们在ImageNet上显示了我们在CIFAR-10 / CIFAR-100上的方法的实验结果，并展示了相对于最新技术的显著性能改进。在CIFAR-10上，我们实现了top-1测试误差为1.36％，这是目前表现最佳的单一模型。在ImageNet上，在没有额外数据的情况下，我们在ResNet-50上达到了top-1精度的领先性能，在ResNet-50-D上达到了80.00％。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/25/Scene-Text-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/25/Scene-Text-Detection/" class="post-title-link" itemprop="url">Scene_Text_Detection</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-25 12:05:53" itemprop="dateCreated datePublished" datetime="2019-12-25T12:05:53+08:00">2019-12-25</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/24/Semantic-segmentation-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/24/Semantic-segmentation-overview/" class="post-title-link" itemprop="url">Semantic_segmentation_overview</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-24 14:34:27 / 修改时间：21:07:47" itemprop="dateCreated datePublished" datetime="2019-12-24T14:34:27+08:00">2019-12-24</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/语义分割/" itemprop="url" rel="index"><span itemprop="name">语义分割</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>语义分割是近年来出现的基本问题之一，因此成为计算机视觉和机器学习领域的热门话题。</p>
<h4 id="通用语义分割图像集"><a href="#通用语义分割图像集" class="headerlink" title="通用语义分割图像集"></a>通用语义分割图像集</h4><ul>
<li>PASCAL Visual Object Classes (VOC)</li>
<li>Common Objects in Context (COCO)<br>With 200K labelled images, 1.5 million object instances, and 80<br>object categories</li>
<li>Other General Purpose Semantic Segmentation Image Sets</li>
<li>YouTube-Objects</li>
<li>SIFT-flow<h4 id="Urban-Street-Semantic-Segmentation-Image-Sets"><a href="#Urban-Street-Semantic-Segmentation-Image-Sets" class="headerlink" title="Urban Street Semantic Segmentation Image Sets"></a>Urban Street Semantic Segmentation Image Sets</h4></li>
<li>Cityscapes</li>
<li>CamVid</li>
<li>KITTI</li>
<li>SYNTHIA<h2 id="Before-Fully-Convolutional-Networks"><a href="#Before-Fully-Convolutional-Networks" class="headerlink" title="Before Fully Convolutional Networks"></a>Before Fully Convolutional Networks</h2><h3 id="Pre-Deep-Learning-Approaches"><a href="#Pre-Deep-Learning-Approaches" class="headerlink" title="Pre-Deep Learning Approaches"></a>Pre-Deep Learning Approaches</h3>传统图像分割与语义分割的区别在于语义特征在图像分割过程中的应用。传统的图像分割方法，如阈值、聚类和区域增长等(有关传统图像分割技术的调查，请参阅[29])使用手工制作的低级特征(即在图像中定位物体的边界。因此，在需要图像语义信息进行像素级分割的情况下，例如在相似物体相互遮挡的情况下，这些方法是必要的。<br>关于深度CNNs流行之前的语义分割工作，有多种方法[30,31，<br>32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]使用的图形模型，如马尔可夫随机域(MRF)，条件<br>随机场(CRF)或基于森林(有时被称为“整体”)的方法，以便在像素级找到场景标签。其主要思想是通过观察相邻像素之间的依赖关系来找到一个推论。换句话说，这些方法将图像的语义建模为相邻像素之间的一种“先验”信息。<br>另一组研究，有时被称为“分层模型”[44,45,46]，使用一个预先训练的和独立的对象探测器的组合，以便从图像中提取语义信息。由于单个的对象检测器未能正确地对区域进行分类，或者由于这些方法受到“手工选择”的检测器库所提供的对象类的有限数量的限制，因此与当今最先进的方法相比，它们的性能相对较低。<br>虽然上述的前深度学习时代的方法不再是首选的分割方法，一些图形模型，特别是CRFs，目前正在使用的最先进的方法作为后处理(细化)层，目的是提高语义分割的性能，具体细节将在下一节中讨论<h3 id="Refinement-Methods"><a href="#Refinement-Methods" class="headerlink" title="Refinement Methods"></a>Refinement Methods</h3>深度神经网络具有很强的局部特征提取能力。然而，它们缺乏利用全局上下文信息的能力，因此无法对相邻像素预测之间的交互进行建模。另一方面，前深度学习时代流行的分割方法，图形模型，非常适合这类任务。这就是为什么它们目前被用作许多深度基于cnn的语义分割架构的细化层。<br>正如在前一节中提到的，使用图形模型进行分割背后的思想是通过观察相邻像素之间的低层次关系来寻找一个推论。在图2中，可以看到使用基于图形模型的细分对分割结果的影响。分类器(见图2.b)不能正确分割不同类标签相邻的像素。在本例中，我们使用基于crf的细分[42]来改进像素级的分割结果。基于crf的方法被广泛用于深度语义分割方法的细化<br>CRFs[50]是一种有区别的无向概率图形模型。它们被用来对观测之间已知的关系进行编码，并构建一致的解释。它们用作细化层的原因是，与不考虑相邻像素相似性的离散分类器不同，CRF可以利用这些信息。与其他图形化模型(如隐马尔科夫模型)相比，CRFs的主要优点是它们的条件性质和避免标签偏差[50]问题的能力。尽管有相当数量的方法(见表1)使用CRFs进行细化，但这些模型在相对较新的方法中开始变得不受欢迎，因为它们的速度非常慢，而且非常难以优化。<h2 id="Early-Deep-Learning-Approaches"><a href="#Early-Deep-Learning-Approaches" class="headerlink" title="Early Deep Learning Approaches"></a>Early Deep Learning Approaches</h2>FCN在2014年出现，使用tanh 相较于proposal of a ReLU layer 很难去区分，因此，训练这样的系统被认为是不适合计算的，甚至对大规模数据是不可行的。然而，第一个成熟的方法只是简单地尝试转换分类网络，如AlexNet和VGG通过微调全连接层来细分网络。他们在训练阶段遭受了过度拟合和完全连接层的时间限制。此外，使用的CNNs不够深，无法创建抽象的特征，这与图像的语义有关。在一些早期的深度学习研究中，研究人员拒绝使用完全连接的层来进行决策，而是使用不同的结构，如周期性的架构[57]或使用来自一个单独计算的分段家族的标记。通过提出全连接层FCN这样的结构的必要性的第一个迹象，不出所料，它们被FCN取代。<br>由于他们的分割结果被认为是不令人满意的，这些研究通常使用一个细化的过程，要么作为一个后处理层[52,53,54,56]，或作为一个替代架构，以完全连接的决策层<br>Refinement methods varied such as Markov random fields，nearest neighbour-based approach，使用校准层[54]，使用超级像素[55,56]，或普通CNNs的递归网络。细化层仍然被后fcn方法所使用，其目的是提高类交叉区域的像素级标记性能。<br>tips: 4FCN [11] ] was officially published in 2017. However the same group first shared the idea online as pre-printed literature in 014 [51].</li>
</ul>
<h2 id="Fully-Convolutional-Networks-for-Semantic-Segmentation"><a href="#Fully-Convolutional-Networks-for-Semantic-Segmentation" class="headerlink" title="Fully Convolutional Networks for Semantic Segmentation"></a>Fully Convolutional Networks for Semantic Segmentation</h2><p><img src="//caius-lu.github.io/2019/12/24/Semantic-segmentation-overview/1.png" alt="1"><br>FCN(2017) 提出了从CNNs (DCNN)中拆除全连通层的设想.‘FCN-32s’, ‘FCN16s’, and ‘FCN8s’  all transfer-learnt using the VGG architecture<br>FCN架构在很多方面都被认为是革命性的,</p>
<ol>
<li>FCN不包括全连接层</li>
<li>该结构允许为任何分辨率的图像生成分割图。使用反卷积层，可以将粗深卷积层输出提升到任意分辨率的稠密像素。</li>
<li>提出了DCNNs的skip架构。跳过架构(或连接)在DCNNs中提供不相邻层之间的链接。仅仅通过对未连接层的输出进行求和或连接，这些连接就可以使信息流动，否则，由于体系结构的选择(如最大池化层或辍学)，这些信息就会丢失。最常见的做法是在max-pooling层之前使用skip连接，它通过选择特定区域的最大值对层输出进行采样。池化层有助于架构创建特性层次，但也会导致局部信息的丢失，而这些局部信息对于语义分割是有价值的，特别是在对象边界。跳过连接通过绕过池化层来保存这些信息并将其转发到更深层。实际上，在[11]中使用跳转连接被认为是相当原始的。“FCN-8s”和“FCN-16s”网络在不同的层包含这些跳过连接。对于相同的架构，即“FCN-4s”和“更密集的跳过连接”。“FCN-2s”也被用于各种应用[61,62]。这一思想最终演变为用于语义分割的编码器-解码器结构[63,27]，下文将对此进行介绍。<h2 id="Post-FCN-Approaches"><a href="#Post-FCN-Approaches" class="headerlink" title="Post-FCN Approaches"></a>Post-FCN Approaches</h2>drawbacks of FCNs： 特性层次结构中标签本地化的低效丢失、无法处理全局上下文知识以及缺乏多尺度处理机制。我们还讨论了语义分割上下文中的尺度不变性，最后讨论了基于对象检测的方法，这是一种新的解决方案，旨在解决同时检测对象实例的语义分割问题。<h3 id="Techniques-for-Fine-grained-Localisation"><a href="#Techniques-for-Fine-grained-Localisation" class="headerlink" title="Techniques for Fine-grained Localisation"></a>Techniques for Fine-grained Localisation</h3>根据定义，语义分割是一个密集的过程，因此它需要在像素级对类标签进行细粒度的本地化。例如，在机器人手术中，语义分割中的像素错误可能会导致生存或死亡的情况。层次特性创建的池(即。，最大池)层可以部分失去本地化。此外，由于他们FCNs完全是卷积性质的，它本身并不具备在图像中对全局上下文信息建模的能力，这在类标签本地化方面也非常有效。因此，这两个问题在本质上和本质上是相互交织的下面我们将讨论旨在克服这些问题和提供更好的本地化的不同方法类的标签。<h4 id="Encoder-Decoder-Architecture"><a href="#Encoder-Decoder-Architecture" class="headerlink" title="Encoder-Decoder Architecture"></a>Encoder-Decoder Architecture</h4><img src="//caius-lu.github.io/2019/12/24/Semantic-segmentation-overview/ed.png" alt="ed"><br>编译码器， 类似U-net，具有开创新的研究。编码器使用池化层逐渐缩减输入数据的空间维度，而解码器通过反卷积层等网络层逐步恢复目标的细节和相应的空间维度。从编码器到解码器之间，通常存在直接的信息连接，来帮助解码器更好地恢复目标细节。<br>U-Net，Seg-Net 都是非常出名的网络。在这种结构中，由编码器部分相邻的低分辨率特征映射提供的强相关语义信息必须经过额外的中间层才能到达相同的译码层。这通常会导致一定程度的信息衰减。<br>然而，U-Net架构已经被证明对于不同应用的分割非常有用，例如卫星图像。<h4 id="Spatial-Pyramid-Pooling-空间金字塔池化"><a href="#Spatial-Pyramid-Pooling-空间金字塔池化" class="headerlink" title="Spatial Pyramid Pooling(空间金字塔池化)"></a>Spatial Pyramid Pooling(空间金字塔池化)</h4><img src="//caius-lu.github.io/2019/12/24/Semantic-segmentation-overview/spp.png" alt="spp"><br>Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. 在2006年首次被提出， 为的是解决单词袋系统失去了特征之间的空间关系。首次应用在深度学习是2015年的SPPNet这篇文章。无论输入大小如何，都可以在空间金字塔汇聚网络中创建深度特征的空间金字塔表示。SPP-Net最重要的贡献是它允许输入不同大小的数据。不同大小的图像输入到卷积层中，不可避免地会产生不同大小的特征图。然而,如果池化层刚好在决策层之前，具有与输入大小成比例的步长值，则创建特征映射这一层将被固定。CNN中的SPP层构建了不同层次特征之间的关系。因此，它与ED结构中的跳过连接非常相似，后者也允许特性层次结构之间的信息流。：SPP层用于语义分割最常见的用法是在[67]中提出的，比如SPP层被附加到最后一个卷积层，并反馈给像素级分类器。<h4 id="Feature-Concatenation-特征连接"><a href="#Feature-Concatenation-特征连接" class="headerlink" title="Feature Concatenation(特征连接)"></a>Feature Concatenation(特征连接)</h4>这个想法是基于融合从不同来源提取的特征。<h4 id="Dilated-Convolution-扩张卷积，空洞卷积"><a href="#Dilated-Convolution-扩张卷积，空洞卷积" class="headerlink" title="Dilated Convolution(扩张卷积，空洞卷积)"></a>Dilated Convolution(扩张卷积，空洞卷积)</h4><img src="//caius-lu.github.io/2019/12/24/Semantic-segmentation-overview/dc.png" alt="dc"><br>扩展卷积的思想实际上很简单:使用连续的卷积滤波器，一个有效的接收域只能随层线性增长;然而，如果使用在滤波器中有间隙的膨胀卷积(见图4.c)，有效接受域将增长得更快[70]。因此，在没有池或子采样的情况下，创建了卷积层的矩形棱镜。扩张卷积是一种非常有效和强大的方法来详细保存特征图分辨率。缺点在于对GPU存储和计算的要求更高，因为特征图分辨率不会在特征层次结构中缩小。<h4 id="Conditional-Random-Fields-条件随机场"><a href="#Conditional-Random-Fields-条件随机场" class="headerlink" title="Conditional Random Fields(条件随机场)"></a>Conditional Random Fields(条件随机场)</h4>cnn自然缺乏特别的‘关注’类交叉区域的机制。在这些区域周围，通过观察CNN层的相邻feature maps之间的低层关系，使用图形化模型进行推理。因此，图形模型(主要是crf)被用作深度语义分割架构的细化层。与在[72]中一样，CRFs将低级交互与来自多类交互的输出连接起来，并以这种方式构建全局上下文知识。<br>CRFs作为一种细化层，目前存在多种利用CRFs对CNNs进行深度处理的方法，如卷积CRFs[47]、稠密CRF[42]、CRN-as-RNN等[73]。尽管CRFs有助于构建上下文知识，从而在类标签中更好地本地化，表1显示了在“CRF模型”选项卡下分类的CRFs，以便将它们与实际的CNN架构扩展区分开。<h4 id="Recurrent-Approaches"><a href="#Recurrent-Approaches" class="headerlink" title="Recurrent Approaches"></a>Recurrent Approaches</h4>递归神经网络处理时间信息的能力有助于提高分割精度。例如，[74]使用ConvLSTM层来改进图像序列中的语义分割结果。<br>然而，也有一些方法在静态图像上使用循环结构。在[13]中，研究人员利用LSTMchains来缠绕多个尺度，从而得到像素级的分割改进。也有将CNNs和RNNs融合的混合方法。这方面的一个很好的例子是所谓的ReSeg模型[75]，其中，输入图像被馈送到一个类似于vgg的CNN编码器，然后通过递归层(即ReNet架构)进行处理，以便更好地定位像素标签。据我们所知，语义分割不存在单纯的递归结构，这主要是因为语义分割需要一个初步的基于cnn的特征编码方案。<br>目前，有一种特定类型的RNN，即“注意模块”，有增长的趋势。在这些模块中，RNN在技术上融合了注意力[76]，在预测输出序列的某个部分时，将注意力集中在输入的某个区域。因此，它们也被用于语义分割[77,78,79]。</li>
</ol>
<h3 id="Scale-Invariance-尺度变化"><a href="#Scale-Invariance-尺度变化" class="headerlink" title="Scale-Invariance(尺度变化)"></a>Scale-Invariance(尺度变化)</h3><p>根据定义，尺度不变性是指一个方法处理输入时不依赖于相对尺度的能力。或图像分辨率。尽管它对于某些应用程序来说是极其重要的，但是这种能力通常被忽视，或者与方法包含多尺度信息的能力相混淆。一种方法可以使用多尺度信息来提高其像素级分割能力，但仍然依赖于尺度或分辨率。</p>
<p>文献： A SURVEY ON DEEP LEARNING-BASED ARCHITECTURES FOR SEMANTIC SEGMENTATION ON 2D IMAGES</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/12/19/二叉树打印/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/12/19/二叉树打印/" class="post-title-link" itemprop="url">二叉树打印</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-12-19 10:44:47 / 修改时间：10:54:38" itemprop="dateCreated datePublished" datetime="2019-12-19T10:44:47+08:00">2019-12-19</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="二叉树按层遍历"><a href="#二叉树按层遍历" class="headerlink" title="二叉树按层遍历"></a>二叉树按层遍历</h2><ol>
<li>针对二叉树的宽度优先遍历</li>
<li>宽度优先遍历常使用队列结构</li>
<li>面试中，该类题目常常对换行有所要求<br><img src="//caius-lu.github.io/2019/12/19/二叉树打印/1.png" alt="1"><br>last: 表示正在打印的当前行的最右节点<br>nlast：表示下一行的最右节点<br><img src="//caius-lu.github.io/2019/12/19/二叉树打印/2.png" alt="2"><h2 id="二叉树的序列化和反序列化"><a href="#二叉树的序列化和反序列化" class="headerlink" title="二叉树的序列化和反序列化"></a>二叉树的序列化和反序列化</h2></li>
<li>二叉树-&gt;字符串（序列化</li>
<li>字符串-&gt;二叉树（反序列化<h3 id="序列化的方式："><a href="#序列化的方式：" class="headerlink" title="序列化的方式："></a>序列化的方式：</h3></li>
<li>根据先序遍历序列化</li>
<li>根据中序遍历序列化</li>
<li>根据后序遍历序列化</li>
<li>按层序列化</li>
</ol>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/11/28/HMM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/11/28/HMM/" class="post-title-link" itemprop="url">隐马尔可夫HMM</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-11-28 16:13:34 / 修改时间：22:22:25" itemprop="dateCreated datePublished" datetime="2019-11-28T16:13:34+08:00">2019-11-28</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="马尔科夫模型"><a href="#马尔科夫模型" class="headerlink" title="马尔科夫模型"></a>马尔科夫模型</h4><ul>
<li>状态之间可以发生转换，昨天和今天转换的情况：<script type="math/tex; mode=display">
\begin{array}{c}{\text { Today }} \\ {\text { sun cloud rain }} \\ {\text { sun }\left[\begin{array}{ccc}{0.50} & {0.375} & {0.125} \\ {0.25} & {0.125} & {0.625} \\ {0.25} & {0.375} & {0.375}\end{array}\right]}\end{array}</script></li>
<li>今天能得到明天的情况，明天能得到后天的情况，以此类推可以无限的玩下去<script type="math/tex; mode=display">
\begin{array}{ll}{\text { sun cloud rain }} \\ {\left[\begin{array}{lll}{1.0} & {0.0} & {0.0}\end{array}\right]}\end{array}</script></li>
<li>这里我们就定义好了一个一阶马尔科夫模型：<br>状态：晴天，多云，雷雨<br>状态转换概率：三种天气状态间的转换概率<br>初始概率：晴天</li>
<li>计算今天(t=1)的天气状况：<br>今天为晴天的概率=初始晴天概率X晴天转晴天概率<pre><code>       +初始多云概率X多云转晴天概率
       +初始雷雨概率X雷雨转晴天概率。
</code></pre><script type="math/tex; mode=display">
\begin{array}{|lc|c|c|c|}\hline t=1 & {} & {} & {\text { t= } 2} & {\text { t=3 }} \\ \hline \text { sun } & {0.507} & {\text { sun }} & {0.375} & {\text { Sun }} & {0.344} \\ {\text { Cloud }} & {0.375} & {\text { Cloud }} & {0.281} & {\text { Cloud }} & {0.352} \\ {\text { Rain }} & {0.125} & {\text { Rain }} & {0.344} & {\text { Rain }} & {0.352} \\ \hline\end{array}</script><h4 id="隐马尔科夫模型"><a href="#隐马尔科夫模型" class="headerlink" title="隐马尔科夫模型"></a>隐马尔科夫模型</h4><img src="//caius-lu.github.io/2019/11/28/HMM/HMM.jpg" alt="HMM"></li>
<li>当前的状态只和前一状态有关：<script type="math/tex; mode=display">
\mathrm{P}\left(\mathrm{z}_{\mathrm{t}} | \mathrm{z}_{\mathrm{t}-1}, \mathrm{x}_{\mathrm{t}-1}, \mathrm{z}_{\mathrm{t}-2}, \mathrm{x}_{\mathrm{t}-2}, \ldots, \mathrm{z}_{1}, \mathrm{x}_{1}\right)=\mathrm{P}\left(\mathrm{z}_{\mathrm{t}} | \mathrm{z}_{\mathrm{t}-1}\right)</script></li>
<li>某个观测只和生成它的状态有关：<script type="math/tex; mode=display">
\mathrm{P}\left(\mathrm{x}_{\mathrm{t}} | \mathrm{z}_{\mathrm{t}}, \mathrm{x}_{\mathrm{t}}, \mathrm{z}_{\mathrm{t}-1}, \mathrm{x}_{\mathrm{t}-1}, \mathrm{z}_{\mathrm{t}-2}, \mathrm{x}_{\mathrm{t}-2}, \ldots, \mathrm{z}_{1}, \mathrm{x}_{1}\right)=\mathrm{P}\left(\mathrm{x}_{\mathrm{t}} | \mathrm{z}_{\mathrm{t}}\right)</script><img src="//caius-lu.github.io/2019/11/28/HMM/HMM2.jpg" alt="HMM2"><h5 id="隐马尔科夫模型的组成"><a href="#隐马尔科夫模型的组成" class="headerlink" title="隐马尔科夫模型的组成"></a>隐马尔科夫模型的组成</h5></li>
<li>三个必备：初始概率(π)，隐藏状态转移概率矩阵(A)，生成观测状态概率矩阵(B)。<script type="math/tex; mode=display">
H M M=(\pi, A, B)</script></li>
<li>隐藏状态与观察状态（B矩阵）:<script type="math/tex; mode=display">
\left.\begin{array}{cccc}{\text { Dry }} & {\text { Dryish }} & {\text { Damp }} & {\text { Soggy }} \\ {\text { sun }} & {0.20} & {0.15} & {0.05} \\ {\text { cloud }} & {0.25} & {0.25} & {0.25} & {0.25} \\ {\text { rain }} & {0.05} & {0.10} & {0.35} & {0.50}\end{array}\right]</script><h4 id="要解决的问题-模型为"><a href="#要解决的问题-模型为" class="headerlink" title="要解决的问题: 模型为"></a>要解决的问题: 模型为</h4><script type="math/tex; mode=display">
\lambda=(A, B, \pi)</script></li>
</ul>
<ol>
<li>给定模型<script type="math/tex; mode=display">
(\pi, A, B)</script>及观测序列 <script type="math/tex; mode=display">
O=\left\{o_{1}, o_{2}, \dots o_{T}\right\}</script>计算其出现的概率<script type="math/tex; mode=display">
\mathrm{P}(\mathrm{O} | \lambda)</script></li>
<li>给定观测序列<script type="math/tex; mode=display">
O=\left\{o_{1}, o_{2}, \dots o_{T}\right\}</script>求解参数<script type="math/tex; mode=display">
(\pi, A, B)</script>使得<script type="math/tex; mode=display">
\mathrm{P}(\mathrm{O} | \lambda)</script>最大</li>
<li>已知模型<script type="math/tex; mode=display">
(\pi, A, B)</script>和观测序列<script type="math/tex; mode=display">
O=\left\{o_{1}, o_{2}, \dots o_{T}\right\}</script>求状态序列，使得<script type="math/tex; mode=display">
\mathrm{P}(\mathrm{I} | \mathrm{O}, \lambda)</script>最大<h4 id="求观测序列的概率"><a href="#求观测序列的概率" class="headerlink" title="求观测序列的概率"></a>求观测序列的概率</h4></li>
</ol>
<ul>
<li>暴力求解：我们要求的是在给定模型下观测序列出现的概率，那如果我能把<br>所有的隐藏序列都给列出来，也就可以知道联合概率分布<script type="math/tex; mode=display">
P(O, I | \lambda)</script></li>
<li><script type="math/tex; mode=display">
P(O | \lambda)=\sum_{x} P(O, I | \lambda), \quad P(O, I | \lambda)=P(I | \lambda) P(O | I, \lambda)</script>现在要求的目标就很明确了。<script type="math/tex; mode=display">
P(I | \lambda)</script>在给定模型下，一个隐藏序列出现的概率，那就由初始状态慢慢转换嘛。<script type="math/tex; mode=display">
I=\left\{i_{1}, i_{2}, \ldots, i_{T}\right\}</script>出现的概率为：<script type="math/tex; mode=display">
P(I | \lambda)=\pi_{i_{1}} a_{i_{1} i_{2}} a_{i_{2} i_{3}} \ldots a_{i_{T-1}} i_{T}</script><h5 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h5>给定t时刻的隐藏状态为i，观测序列为o1,o2…ot的概率叫做前向概率：<script type="math/tex; mode=display">
\alpha_{i}(t)=p\left(y_{1}, y_{2}, \ldots y_{t}, q_{t}=i | \lambda\right)</script><img src="//caius-lu.github.io/2019/11/28/HMM/HMM3.jpg" alt="HMM3"></li>
</ul>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/11/26/GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/11/26/GAN/" class="post-title-link" itemprop="url">GAN</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-11-26 22:30:15 / 修改时间：22:41:03" itemprop="dateCreated datePublished" datetime="2019-11-26T22:30:15+08:00">2019-11-26</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/python/GAN/" itemprop="url" rel="index"><span itemprop="name">GAN</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="对抗生成网络-GAN-Generative-Adversarial-Nets"><a href="#对抗生成网络-GAN-Generative-Adversarial-Nets" class="headerlink" title="对抗生成网络 GAN(Generative Adversarial Nets)"></a>对抗生成网络 GAN(Generative Adversarial Nets)</h3><p><img src="//caius-lu.github.io/2019/11/26/GAN/图片1.png" alt="图片1"></p>
<h3 id="Adversarial-Nets-Framework"><a href="#Adversarial-Nets-Framework" class="headerlink" title="Adversarial Nets Framework"></a><strong>Adversarial Nets Framework</strong></h3><p><img src="//caius-lu.github.io/2019/11/26/GAN/图片2.png" alt="图片2"></p>
<p>生成器与判别器状态相等</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><script type="math/tex; mode=display">
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]</script><p>它做的是去最大化 D的区分度，最小化G和real数据集的数据分布</p>
<p>判别模型：</p>
<script type="math/tex; mode=display">
\log \left(D_{1}(x)\right)+\log \left(1-D_{2}(G(z))\right)</script><p>D1 和 D2 相同的，是判别器，G是生成器</p>
<p>生成模型：</p>
<script type="math/tex; mode=display">
\log \left(D_{2}(G(z))\right)</script><p>先训练判别器，在训练生成器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author: Your name</span></span><br><span class="line"><span class="comment"># @Date:   2019-11-26 09:12:52</span></span><br><span class="line"><span class="comment"># @Last Modified by:   Your name</span></span><br><span class="line"><span class="comment"># @Last Modified time: 2019-11-26 09:12:52</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">sns.set(color_codes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">seed = <span class="number">42</span></span><br><span class="line">np.random.seed(seed)</span><br><span class="line">tf.set_random_seed(seed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataDistribution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.mu = <span class="number">4</span></span><br><span class="line">        self.sigma = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, N)</span>:</span></span><br><span class="line">        samples = np.random.normal(self.mu, self.sigma, N) <span class="comment"># 生成高斯分布的概率密度随机数 均值，标准差</span></span><br><span class="line">        samples.sort()</span><br><span class="line">        <span class="keyword">return</span> samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneratorDistribution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, range)</span>:</span></span><br><span class="line">        self.range = range</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, N)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.linspace(-self.range, self.range, N) + \</span><br><span class="line">            np.random.random(N) * <span class="number">0.01</span>  <span class="comment"># 生成随机数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对线性相乘进行初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span><span class="params">(input, output_dim, scope=None, stddev=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    norm = tf.random_normal_initializer(stddev=stddev)</span><br><span class="line">    const = tf.constant_initializer(<span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope <span class="keyword">or</span> <span class="string">'linear'</span>): <span class="comment"># 定义命名空间</span></span><br><span class="line">        w = tf.get_variable(<span class="string">'w'</span>, [input.get_shape()[<span class="number">1</span>], output_dim], initializer=norm)</span><br><span class="line">        b = tf.get_variable(<span class="string">'b'</span>, [output_dim], initializer=const)</span><br><span class="line">        <span class="keyword">return</span> tf.matmul(input, w) + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(input, h_dim)</span>:</span></span><br><span class="line">    <span class="comment"># 这个函数的作用是计算激活函数softplus，即log( exp( features ) + 1)</span></span><br><span class="line">    h0 = tf.nn.softplus(linear(input, h_dim, <span class="string">'g0'</span>))</span><br><span class="line">    h1 = linear(h0, <span class="number">1</span>, <span class="string">'g1'</span>)</span><br><span class="line">    <span class="keyword">return</span> h1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(input, h_dim)</span>:</span></span><br><span class="line">    h0 = tf.tanh(linear(input, h_dim * <span class="number">2</span>, <span class="string">'d0'</span>))</span><br><span class="line">    h1 = tf.tanh(linear(h0, h_dim * <span class="number">2</span>, <span class="string">'d1'</span>))</span><br><span class="line">    h2 = tf.tanh(linear(h1, h_dim * <span class="number">2</span>, scope=<span class="string">'d2'</span>))</span><br><span class="line"></span><br><span class="line">    h3 = tf.sigmoid(linear(h2, <span class="number">1</span>, scope=<span class="string">'d3'</span>))</span><br><span class="line">    <span class="keyword">return</span> h3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimizer</span><span class="params">(loss, var_list, initial_learning_rate)</span>:</span></span><br><span class="line">    decay = <span class="number">0.95</span></span><br><span class="line">    num_decay_steps = <span class="number">150</span></span><br><span class="line">    batch = tf.Variable(<span class="number">0</span>)</span><br><span class="line">    learning_rate = tf.train.exponential_decay(</span><br><span class="line">        initial_learning_rate,</span><br><span class="line">        batch,</span><br><span class="line">        num_decay_steps,</span><br><span class="line">        decay,</span><br><span class="line">        staircase=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(</span><br><span class="line">        loss,</span><br><span class="line">        global_step=batch,</span><br><span class="line">        var_list=var_list</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GAN</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, gen, num_steps, batch_size, log_every)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.gen = gen</span><br><span class="line">        self.num_steps = num_steps</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.log_every = log_every</span><br><span class="line">        self.mlp_hidden_size = <span class="number">4</span></span><br><span class="line">        self.learning_rate = <span class="number">0.03</span></span><br><span class="line"></span><br><span class="line">        self._create_model()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_model</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'D_pre'</span>):</span><br><span class="line">            self.pre_input = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.pre_labels = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            D_pre = discriminator(self.pre_input, self.mlp_hidden_size)</span><br><span class="line">            self.pre_loss = tf.reduce_mean(tf.square(D_pre - self.pre_labels))</span><br><span class="line">            self.pre_opt = optimizer(self.pre_loss, <span class="literal">None</span>, self.learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># This defines the generator network - it takes samples from a noise</span></span><br><span class="line">        <span class="comment"># distribution as input, and passes them through an MLP.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Gen'</span>):</span><br><span class="line">            self.z = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.G = generator(self.z, self.mlp_hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The discriminator tries to tell the difference between samples from the</span></span><br><span class="line">        <span class="comment"># true data distribution (self.x) and the generated samples (self.z).</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Here we create two copies of the discriminator network (that share parameters),</span></span><br><span class="line">        <span class="comment"># as you cannot use the same network with different inputs in TensorFlow.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Disc'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">            self.x = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.D1 = discriminator(self.x, self.mlp_hidden_size)</span><br><span class="line">            scope.reuse_variables()</span><br><span class="line">            self.D2 = discriminator(self.G, self.mlp_hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Define the loss for discriminator and generator networks (see the original</span></span><br><span class="line">        <span class="comment"># paper for details), and create optimizers for both</span></span><br><span class="line">        self.loss_d = tf.reduce_mean(-tf.log(self.D1) - tf.log(<span class="number">1</span> - self.D2))</span><br><span class="line">        self.loss_g = tf.reduce_mean(-tf.log(self.D2))</span><br><span class="line"></span><br><span class="line">        self.d_pre_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'D_pre'</span>)</span><br><span class="line">        self.d_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'Disc'</span>)</span><br><span class="line">        self.g_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'Gen'</span>)</span><br><span class="line"></span><br><span class="line">        self.opt_d = optimizer(self.loss_d, self.d_params, self.learning_rate)</span><br><span class="line">        self.opt_g = optimizer(self.loss_g, self.g_params, self.learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">            tf.global_variables_initializer().run()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># pretraining discriminator</span></span><br><span class="line">            num_pretrain_steps = <span class="number">1000</span></span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(num_pretrain_steps):</span><br><span class="line">                d = (np.random.random(self.batch_size) - <span class="number">0.5</span>) * <span class="number">10.0</span></span><br><span class="line">                labels = norm.pdf(d, loc=self.data.mu, scale=self.data.sigma) <span class="comment"># norm.pdf:正态概率密度函数</span></span><br><span class="line">                pretrain_loss, _ = session.run([self.pre_loss, self.pre_opt], &#123;</span><br><span class="line">                    self.pre_input: np.reshape(d, (self.batch_size, <span class="number">1</span>)),</span><br><span class="line">                    self.pre_labels: np.reshape(labels, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line">            self.weightsD = session.run(self.d_pre_params)</span><br><span class="line">            <span class="comment"># copy weights from pre-training over to new D network</span></span><br><span class="line">            <span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(self.d_params):</span><br><span class="line">                session.run(v.assign(self.weightsD[i]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(self.num_steps):</span><br><span class="line">                <span class="comment"># update discriminator</span></span><br><span class="line">                x = self.data.sample(self.batch_size)</span><br><span class="line">                z = self.gen.sample(self.batch_size)</span><br><span class="line">                loss_d, _ = session.run([self.loss_d, self.opt_d], &#123;</span><br><span class="line">                    self.x: np.reshape(x, (self.batch_size, <span class="number">1</span>)),</span><br><span class="line">                    self.z: np.reshape(z, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># update generator</span></span><br><span class="line">                z = self.gen.sample(self.batch_size)</span><br><span class="line">                loss_g, _ = session.run([self.loss_g, self.opt_g], &#123;</span><br><span class="line">                    self.z: np.reshape(z, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> step % self.log_every == <span class="number">0</span>:</span><br><span class="line">                    print(<span class="string">'&#123;&#125;: &#123;&#125;\t&#123;&#125;'</span>.format(step, loss_d, loss_g))</span><br><span class="line">                <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span> <span class="keyword">or</span> step==<span class="number">0</span> <span class="keyword">or</span> step == self.num_steps <span class="number">-1</span> :</span><br><span class="line">                    self._plot_distributions(session)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_samples</span><span class="params">(self, session, num_points=<span class="number">10000</span>, num_bins=<span class="number">100</span>)</span>:</span></span><br><span class="line">        xs = np.linspace(-self.gen.range, self.gen.range, num_points)</span><br><span class="line">        bins = np.linspace(-self.gen.range, self.gen.range, num_bins)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># data distribution</span></span><br><span class="line">        d = self.data.sample(num_points)</span><br><span class="line">        pd, _ = np.histogram(d, bins=bins, density=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># generated samples</span></span><br><span class="line">        zs = np.linspace(-self.gen.range, self.gen.range, num_points)</span><br><span class="line">        g = np.zeros((num_points, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_points // self.batch_size):</span><br><span class="line">            g[self.batch_size * i:self.batch_size * (i + <span class="number">1</span>)] = session.run(self.G, &#123;</span><br><span class="line">                self.z: np.reshape(</span><br><span class="line">                    zs[self.batch_size * i:self.batch_size * (i + <span class="number">1</span>)],</span><br><span class="line">                    (self.batch_size, <span class="number">1</span>)</span><br><span class="line">                )</span><br><span class="line">            &#125;)</span><br><span class="line">        pg, _ = np.histogram(g, bins=bins, density=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pd, pg</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_plot_distributions</span><span class="params">(self, session)</span>:</span></span><br><span class="line">        pd, pg = self._samples(session)</span><br><span class="line">        p_x = np.linspace(-self.gen.range, self.gen.range, len(pd))</span><br><span class="line">        f, ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">        ax.set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        plt.plot(p_x, pd, label=<span class="string">'real data'</span>)</span><br><span class="line">        plt.plot(p_x, pg, label=<span class="string">'generated data'</span>)</span><br><span class="line">        plt.title(<span class="string">'1D Generative Adversarial Network'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'Data values'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'Probability density'</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(args)</span>:</span></span><br><span class="line">    model = GAN(</span><br><span class="line">        DataDistribution(),</span><br><span class="line">        GeneratorDistribution(range=<span class="number">8</span>),</span><br><span class="line">        args.num_steps,</span><br><span class="line">        args.batch_size,</span><br><span class="line">        args.log_every,</span><br><span class="line">    )</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">'--num-steps'</span>, type=int, default=<span class="number">12000</span>,</span><br><span class="line">                        help=<span class="string">'the number of training steps to take'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--batch-size'</span>, type=int, default=<span class="number">12</span>,</span><br><span class="line">                        help=<span class="string">'the batch size'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--log-every'</span>, type=int, default=<span class="number">10</span>,</span><br><span class="line">                        help=<span class="string">'print loss after this many steps'</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(parse_args())</span><br></pre></td></tr></table></figure>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/myplot.png" alt="myplot"></p>
<h4 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h4><ol>
<li><p>将pooling层convolutions替代  </p>
<ul>
<li><p>对于判别模型：容许网络学习自己的空间下采样</p>
</li>
<li><p>对于生成模型：容许它学习自己的空间上采样  </p>
</li>
</ul>
</li>
<li><p>在generator和discriminator上都使用batchnorm  </p>
<ul>
<li>解决初始化差的问题</li>
<li>帮助梯度传播到每一层</li>
<li>防止generator把所有的样本都收敛到同一个点。</li>
</ul>
</li>
<li><p>在CNN中移除全连接层</p>
</li>
<li><p>在generator的除了输出层外的所有层使用ReLU，输出层采用tanh。</p>
</li>
<li><p>在discriminator的所有层上使用LeakyReLU  </p>
</li>
</ol>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/33.png" alt="33"></p>
<p>100维的向量转为为特征图相似的东西， 再将这个向量reshape 。使用反卷积操作。</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/a22.png" alt="a22"></p>
<p>输入图片，得到一个值是0或者1，这个是判别网络</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/aa1.png" alt="aa1"></p>
<p>这个是生成网络。<br>model.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ops <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_out_size_same</span><span class="params">(size, stride)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> math.ceil(float(size) / float(stride))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DCGAN</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, input_height=<span class="number">108</span>, input_width=<span class="number">108</span>, is_crop=True,</span></span></span><br><span class="line"><span class="function"><span class="params">         batch_size=<span class="number">64</span>, sample_num = <span class="number">64</span>, output_height=<span class="number">64</span>, output_width=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         y_dim=None, z_dim=<span class="number">100</span>, gf_dim=<span class="number">64</span>, df_dim=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         gfc_dim=<span class="number">1024</span>, dfc_dim=<span class="number">1024</span>, c_dim=<span class="number">3</span>, dataset_name=<span class="string">'default'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         input_fname_pattern=<span class="string">'*.jpg'</span>, checkpoint_dir=None, sample_dir=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    # sample number  测试噪音的输出，y代表label</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      sess: TensorFlow session</span></span><br><span class="line"><span class="string">      batch_size: The size of batch. Should be specified before training.</span></span><br><span class="line"><span class="string">      y_dim: (optional) Dimension of dim for y. [None]</span></span><br><span class="line"><span class="string">      z_dim: (optional) Dimension of dim for Z. [100]</span></span><br><span class="line"><span class="string">      gf_dim: (optional) Dimension of gen filters in first conv layer. [64]</span></span><br><span class="line"><span class="string">      df_dim: (optional) Dimension of discrim filters in first conv layer. [64]</span></span><br><span class="line"><span class="string">      gfc_dim: (optional) Dimension of gen units for for fully connected layer. [1024]</span></span><br><span class="line"><span class="string">      dfc_dim: (optional) Dimension of discrim units for fully connected layer. [1024]</span></span><br><span class="line"><span class="string">      c_dim: (optional) Dimension of image color. For grayscale input, set to 1. [3]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self.sess = sess</span><br><span class="line">    self.is_crop = is_crop</span><br><span class="line">    self.is_grayscale = (c_dim == <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    self.batch_size = batch_size</span><br><span class="line">    self.sample_num = sample_num</span><br><span class="line"></span><br><span class="line">    self.input_height = input_height</span><br><span class="line">    self.input_width = input_width</span><br><span class="line">    self.output_height = output_height</span><br><span class="line">    self.output_width = output_width</span><br><span class="line"></span><br><span class="line">    self.y_dim = y_dim <span class="comment"># null</span></span><br><span class="line">    self.z_dim = z_dim <span class="comment"># 噪音点的维度 100</span></span><br><span class="line"></span><br><span class="line">    self.gf_dim = gf_dim <span class="comment"># 最终多少个filter的个数 基数</span></span><br><span class="line">    self.df_dim = df_dim <span class="comment"># 64</span></span><br><span class="line"></span><br><span class="line">    self.gfc_dim = gfc_dim<span class="comment"># 生成和判别的全连接 1024</span></span><br><span class="line">    self.dfc_dim = dfc_dim <span class="comment"># 1024</span></span><br><span class="line"></span><br><span class="line">    self.c_dim = c_dim<span class="comment"># 生成的是彩色图 3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># batch normalization : deals with poor initialization helps gradient flow</span></span><br><span class="line">    self.d_bn1 = batch_norm(name=<span class="string">'d_bn1'</span>)<span class="comment"># bacth在relu之前卷积之后</span></span><br><span class="line">    self.d_bn2 = batch_norm(name=<span class="string">'d_bn2'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">      self.d_bn3 = batch_norm(name=<span class="string">'d_bn3'</span>)</span><br><span class="line"></span><br><span class="line">    self.g_bn0 = batch_norm(name=<span class="string">'g_bn0'</span>)</span><br><span class="line">    self.g_bn1 = batch_norm(name=<span class="string">'g_bn1'</span>)</span><br><span class="line">    self.g_bn2 = batch_norm(name=<span class="string">'g_bn2'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">      self.g_bn3 = batch_norm(name=<span class="string">'g_bn3'</span>)</span><br><span class="line"></span><br><span class="line">    self.dataset_name = dataset_name</span><br><span class="line">    self.input_fname_pattern = input_fname_pattern</span><br><span class="line">    self.checkpoint_dir = checkpoint_dir</span><br><span class="line">    self.build_model()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.y_dim:</span><br><span class="line">      self.y= tf.placeholder(tf.float32, [self.batch_size, self.y_dim], name=<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.is_crop:</span><br><span class="line">      image_dims = [self.output_height, self.output_width, self.c_dim]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      image_dims = [self.input_height, self.input_height, self.c_dim]</span><br><span class="line"></span><br><span class="line">    self.inputs = tf.placeholder(</span><br><span class="line">      tf.float32, [self.batch_size] + image_dims, name=<span class="string">'real_images'</span>)</span><br><span class="line">    self.sample_inputs = tf.placeholder(  <span class="comment"># 64 108 108 3，iamge_dim 108 108 3</span></span><br><span class="line">      tf.float32, [self.sample_num] + image_dims, name=<span class="string">'sample_inputs'</span>)</span><br><span class="line"></span><br><span class="line">    inputs = self.inputs  <span class="comment"># 64 108 108 3</span></span><br><span class="line">    sample_inputs = self.sample_inputs</span><br><span class="line"></span><br><span class="line">    self.z = tf.placeholder(</span><br><span class="line">      tf.float32, [<span class="literal">None</span>, self.z_dim], name=<span class="string">'z'</span>)  <span class="comment">## 生成网络组最开始的输入，float32  # B， 100</span></span><br><span class="line">    self.z_sum = histogram_summary(<span class="string">"z"</span>, self.z)  <span class="comment"># 在训练神经网络时，当需要查看一个张量在训练过程中值的分布情况时，可通过tf.summary.histogram()将其分布情况以直方图的形式在TensorBoard直方图仪表板上显示．</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.y_dim:</span><br><span class="line">      self.G = self.generator(self.z, self.y)</span><br><span class="line">      self.D, self.D_logits = \</span><br><span class="line">          self.discriminator(inputs, self.y, reuse=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">      self.sampler = self.sampler(self.z, self.y)</span><br><span class="line">      self.D_, self.D_logits_ = \</span><br><span class="line">          self.discriminator(self.G, self.y, reuse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.G = self.generator(self.z)  <span class="comment"># 64 64 64 3</span></span><br><span class="line">      self.D, self.D_logits = self.discriminator(inputs)  <span class="comment"># 64 108 108 3</span></span><br><span class="line"></span><br><span class="line">      self.sampler = self.sampler(self.z)</span><br><span class="line">      self.D_, self.D_logits_ = self.discriminator(self.G, reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    self.d_sum = histogram_summary(<span class="string">"d"</span>, self.D)</span><br><span class="line">    self.d__sum = histogram_summary(<span class="string">"d_"</span>, self.D_)</span><br><span class="line">    self.G_sum = image_summary(<span class="string">"G"</span>, self.G)</span><br><span class="line">    <span class="comment"># tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits,l)</span></span><br><span class="line">    self.d_loss_real = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits, labels=tf.ones_like(self.D))) </span><br><span class="line">    self.d_loss_fake = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits_, labels=tf.zeros_like(self.D_)))</span><br><span class="line">    self.g_loss = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits_, labels=tf.ones_like(self.D_)))</span><br><span class="line"></span><br><span class="line">    self.d_loss_real_sum = scalar_summary(<span class="string">"d_loss_real"</span>, self.d_loss_real)</span><br><span class="line">    self.d_loss_fake_sum = scalar_summary(<span class="string">"d_loss_fake"</span>, self.d_loss_fake)</span><br><span class="line">                          </span><br><span class="line">    self.d_loss = self.d_loss_real + self.d_loss_fake</span><br><span class="line"></span><br><span class="line">    self.g_loss_sum = scalar_summary(<span class="string">"g_loss"</span>, self.g_loss)</span><br><span class="line">    self.d_loss_sum = scalar_summary(<span class="string">"d_loss"</span>, self.d_loss)</span><br><span class="line"></span><br><span class="line">    t_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    self.d_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'d_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line">    self.g_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'g_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line"></span><br><span class="line">    self.saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, config)</span>:</span></span><br><span class="line">    <span class="string">"""Train DCGAN"""</span></span><br><span class="line">    <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">      data_X, data_y = self.load_mnist()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      data = glob(os.path.join(<span class="string">"./data"</span>, config.dataset, self.input_fname_pattern))</span><br><span class="line">    <span class="comment">#np.random.shuffle(data)</span></span><br><span class="line"></span><br><span class="line">    d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">              .minimize(self.d_loss, var_list=self.d_vars)</span><br><span class="line">    g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">              .minimize(self.g_loss, var_list=self.g_vars)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      tf.global_variables_initializer().run()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">      tf.initialize_all_variables().run()</span><br><span class="line"></span><br><span class="line">    self.g_sum = merge_summary([self.z_sum, self.d__sum,</span><br><span class="line">      self.G_sum, self.d_loss_fake_sum, self.g_loss_sum])</span><br><span class="line">    self.d_sum = merge_summary(</span><br><span class="line">        [self.z_sum, self.d_sum, self.d_loss_real_sum, self.d_loss_sum])</span><br><span class="line">    self.writer = SummaryWriter(<span class="string">"./logs"</span>, self.sess.graph)</span><br><span class="line"></span><br><span class="line">    sample_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, size=(self.sample_num , self.z_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">      sample_inputs = data_X[<span class="number">0</span>:self.sample_num]</span><br><span class="line">      sample_labels = data_y[<span class="number">0</span>:self.sample_num]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      sample_files = data[<span class="number">0</span>:self.sample_num]</span><br><span class="line">      sample = [</span><br><span class="line">          get_image(sample_file,</span><br><span class="line">                    input_height=self.input_height,</span><br><span class="line">                    input_width=self.input_width,</span><br><span class="line">                    resize_height=self.output_height,</span><br><span class="line">                    resize_width=self.output_width,</span><br><span class="line">                    is_crop=self.is_crop,</span><br><span class="line">                    is_grayscale=self.is_grayscale) <span class="keyword">for</span> sample_file <span class="keyword">in</span> sample_files]</span><br><span class="line">      <span class="keyword">if</span> (self.is_grayscale):</span><br><span class="line">        sample_inputs = np.array(sample).astype(np.float32)[:, :, :, <span class="literal">None</span>]</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        sample_inputs = np.array(sample).astype(np.float32)</span><br><span class="line">  </span><br><span class="line">    counter = <span class="number">1</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.load(self.checkpoint_dir):</span><br><span class="line">      print(<span class="string">" [*] Load SUCCESS"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      print(<span class="string">" [!] Load failed..."</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(config.epoch):</span><br><span class="line">      <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">        batch_idxs = min(len(data_X), config.train_size) // config.batch_size</span><br><span class="line">      <span class="keyword">else</span>:      </span><br><span class="line">        data = glob(os.path.join(</span><br><span class="line">          <span class="string">"./data"</span>, config.dataset, self.input_fname_pattern))</span><br><span class="line">        batch_idxs = min(len(data), config.train_size) // config.batch_size</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(<span class="number">0</span>, batch_idxs):</span><br><span class="line">        <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">          batch_images = data_X[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">          batch_labels = data_y[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          batch_files = data[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">          batch = [</span><br><span class="line">              get_image(batch_file,</span><br><span class="line">                        input_height=self.input_height,</span><br><span class="line">                        input_width=self.input_width,</span><br><span class="line">                        resize_height=self.output_height,</span><br><span class="line">                        resize_width=self.output_width,</span><br><span class="line">                        is_crop=self.is_crop,</span><br><span class="line">                        is_grayscale=self.is_grayscale) <span class="keyword">for</span> batch_file <span class="keyword">in</span> batch_files]</span><br><span class="line">          <span class="keyword">if</span> (self.is_grayscale):</span><br><span class="line">            batch_images = np.array(batch).astype(np.float32)[:, :, :, <span class="literal">None</span>]</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            batch_images = np.array(batch).astype(np.float32)</span><br><span class="line">        <span class="comment">#  一个均匀分布[low,high)中随机采样 从+1和-1之间随才采样</span></span><br><span class="line">        batch_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, [config.batch_size, self.z_dim]) \</span><br><span class="line">          .astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">          <span class="comment"># Update D network</span></span><br><span class="line">          _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; </span><br><span class="line">              self.inputs: batch_images,</span><br><span class="line">              self.z: batch_z,</span><br><span class="line">              self.y:batch_labels,</span><br><span class="line">            &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Update G network</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123;</span><br><span class="line">              self.z: batch_z, </span><br><span class="line">              self.y:batch_labels,</span><br><span class="line">            &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero (different from paper)</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z, self.y:batch_labels &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line">          </span><br><span class="line">          errD_fake = self.d_loss_fake.eval(&#123;</span><br><span class="line">              self.z: batch_z, </span><br><span class="line">              self.y:batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">          errD_real = self.d_loss_real.eval(&#123;</span><br><span class="line">              self.inputs: batch_images,</span><br><span class="line">              self.y:batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">          errG = self.g_loss.eval(&#123;</span><br><span class="line">              self.z: batch_z,</span><br><span class="line">              self.y: batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="comment"># Update D network</span></span><br><span class="line">          _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; self.inputs: batch_images, self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Update G network</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero (different from paper)</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line">          </span><br><span class="line">          errD_fake = self.d_loss_fake.eval(&#123; self.z: batch_z &#125;)</span><br><span class="line">          errD_real = self.d_loss_real.eval(&#123; self.inputs: batch_images &#125;)</span><br><span class="line">          errG = self.g_loss.eval(&#123;self.z: batch_z&#125;)</span><br><span class="line"></span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"</span> \</span><br><span class="line">          % (epoch, idx, batch_idxs,</span><br><span class="line">            time.time() - start_time, errD_fake+errD_real, errG))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> np.mod(counter, <span class="number">100</span>) == <span class="number">1</span>:</span><br><span class="line">          <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">            samples, d_loss, g_loss = self.sess.run(</span><br><span class="line">              [self.sampler, self.d_loss, self.g_loss],</span><br><span class="line">              feed_dict=&#123;</span><br><span class="line">                  self.z: sample_z,</span><br><span class="line">                  self.inputs: sample_inputs,</span><br><span class="line">                  self.y:sample_labels,</span><br><span class="line">              &#125;</span><br><span class="line">            )</span><br><span class="line">            save_images(samples, [<span class="number">8</span>, <span class="number">8</span>],</span><br><span class="line">                  <span class="string">'./&#123;&#125;/train_&#123;:02d&#125;_&#123;:04d&#125;.png'</span>.format(config.sample_dir, epoch, idx))</span><br><span class="line">            print(<span class="string">"[Sample] d_loss: %.8f, g_loss: %.8f"</span> % (d_loss, g_loss)) </span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">              samples, d_loss, g_loss = self.sess.run(</span><br><span class="line">                [self.sampler, self.d_loss, self.g_loss],</span><br><span class="line">                feed_dict=&#123;</span><br><span class="line">                    self.z: sample_z,</span><br><span class="line">                    self.inputs: sample_inputs,</span><br><span class="line">                &#125;,</span><br><span class="line">              )</span><br><span class="line">              save_images(samples, [<span class="number">8</span>, <span class="number">8</span>],</span><br><span class="line">                    <span class="string">'./&#123;&#125;/train_&#123;:02d&#125;_&#123;:04d&#125;.png'</span>.format(config.sample_dir, epoch, idx))</span><br><span class="line">              print(<span class="string">"[Sample] d_loss: %.8f, g_loss: %.8f"</span> % (d_loss, g_loss)) </span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">              print(<span class="string">"one pic error!..."</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> counter//<span class="number">10</span> == <span class="number">2</span>:</span><br><span class="line">          self.save(config.checkpoint_dir, counter)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, image, y=None, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"discriminator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      <span class="keyword">if</span> reuse:</span><br><span class="line">        scope.reuse_variables()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        h0 = lrelu(conv2d(image, self.df_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*<span class="number">2</span>, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">        h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*<span class="number">4</span>, name=<span class="string">'d_h2_conv'</span>)))</span><br><span class="line">        h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*<span class="number">8</span>, name=<span class="string">'d_h3_conv'</span>))) <span class="comment"># 64 14 14 256 -&gt;64 7 7 512</span></span><br><span class="line">        aa = tf.reshape(h3, [self.batch_size, <span class="number">-1</span>])</span><br><span class="line">        h4 = linear(aa, <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        x = conv_cond_concat(image, yb)</span><br><span class="line"></span><br><span class="line">        h0 = lrelu(conv2d(x, self.c_dim + self.y_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">        h0 = conv_cond_concat(h0, yb)</span><br><span class="line"></span><br><span class="line">        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim + self.y_dim, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, <span class="number">-1</span>])      </span><br><span class="line">        h1 = concat([h1, y], <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        h2 = lrelu(self.d_bn2(linear(h1, self.dfc_dim, <span class="string">'d_h2_lin'</span>)))</span><br><span class="line">        h2 = concat([h2, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h3 = linear(h2, <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h3), h3</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self, z, y=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"generator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_w2 = conv_out_size_same(s_h, <span class="number">2</span>), conv_out_size_same(s_w, <span class="number">2</span>) <span class="comment"># 先把特征图大小确定出来</span></span><br><span class="line">        s_h4, s_w4 = conv_out_size_same(s_h2, <span class="number">2</span>), conv_out_size_same(s_w2, <span class="number">2</span>)</span><br><span class="line">        s_h8, s_w8 = conv_out_size_same(s_h4, <span class="number">2</span>), conv_out_size_same(s_w4, <span class="number">2</span>)</span><br><span class="line">        s_h16, s_w16 = conv_out_size_same(s_h8, <span class="number">2</span>), conv_out_size_same(s_w8, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project `z` and reshape</span></span><br><span class="line">        self.z_, self.h0_w, self.h0_b = linear(</span><br><span class="line">            z, self.gf_dim*<span class="number">8</span>*s_h16*s_w16, <span class="string">'g_h0_lin'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.h0 = tf.reshape(</span><br><span class="line">            self.z_, [<span class="number">-1</span>, s_h16, s_w16, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(self.h0))</span><br><span class="line"></span><br><span class="line">        self.h1, self.h1_w, self.h1_b = deconv2d(</span><br><span class="line">            h0, [self.batch_size, s_h8, s_w8, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(self.h1))</span><br><span class="line"></span><br><span class="line">        h2, self.h2_w, self.h2_b = deconv2d(</span><br><span class="line">            h1, [self.batch_size, s_h4, s_w4, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(h2))</span><br><span class="line"></span><br><span class="line">        h3, self.h3_w, self.h3_b = deconv2d(</span><br><span class="line">            h2, [self.batch_size, s_h2, s_w2, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h3 = tf.nn.relu(self.g_bn3(h3))</span><br><span class="line"></span><br><span class="line">        h4, self.h4_w, self.h4_b = deconv2d(</span><br><span class="line">            h3, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h4'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_h4 = int(s_h/<span class="number">2</span>), int(s_h/<span class="number">4</span>)</span><br><span class="line">        s_w2, s_w4 = int(s_w/<span class="number">2</span>), int(s_w/<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yb = tf.expand_dims(tf.expand_dims(y, 1),2)</span></span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        z = concat([z, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h0 = tf.nn.relu(</span><br><span class="line">            self.g_bn0(linear(z, self.gfc_dim, <span class="string">'g_h0_lin'</span>)))</span><br><span class="line">        h0 = concat([h0, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(</span><br><span class="line">            linear(h0, self.gf_dim*<span class="number">2</span>*s_h4*s_w4, <span class="string">'g_h1_lin'</span>)))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        h1 = conv_cond_concat(h1, yb)</span><br><span class="line"></span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(deconv2d(h1,</span><br><span class="line">            [self.batch_size, s_h2, s_w2, self.gf_dim * <span class="number">2</span>], name=<span class="string">'g_h2'</span>)))</span><br><span class="line">        h2 = conv_cond_concat(h2, yb)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(</span><br><span class="line">            deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h3'</span>))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sampler</span><span class="params">(self, z, y=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"generator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      scope.reuse_variables()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_w2 = conv_out_size_same(s_h, <span class="number">2</span>), conv_out_size_same(s_w, <span class="number">2</span>)</span><br><span class="line">        s_h4, s_w4 = conv_out_size_same(s_h2, <span class="number">2</span>), conv_out_size_same(s_w2, <span class="number">2</span>)</span><br><span class="line">        s_h8, s_w8 = conv_out_size_same(s_h4, <span class="number">2</span>), conv_out_size_same(s_w4, <span class="number">2</span>)</span><br><span class="line">        s_h16, s_w16 = conv_out_size_same(s_h8, <span class="number">2</span>), conv_out_size_same(s_w8, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project `z` and reshape</span></span><br><span class="line">        h0 = tf.reshape(</span><br><span class="line">            linear(z, self.gf_dim*<span class="number">8</span>*s_h16*s_w16, <span class="string">'g_h0_lin'</span>),</span><br><span class="line">            [<span class="number">-1</span>, s_h16, s_w16, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(h0, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h1 = deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>)</span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(h1, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h2 = deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>)</span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(h2, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h3 = deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>)</span><br><span class="line">        h3 = tf.nn.relu(self.g_bn3(h3, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h4 = deconv2d(h3, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h4'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_h4 = int(s_h/<span class="number">2</span>), int(s_h/<span class="number">4</span>)</span><br><span class="line">        s_w2, s_w4 = int(s_w/<span class="number">2</span>), int(s_w/<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yb = tf.reshape(y, [-1, 1, 1, self.y_dim])</span></span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        z = concat([z, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(linear(z, self.gfc_dim, <span class="string">'g_h0_lin'</span>)))</span><br><span class="line">        h0 = concat([h0, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(</span><br><span class="line">            linear(h0, self.gf_dim*<span class="number">2</span>*s_h4*s_w4, <span class="string">'g_h1_lin'</span>), train=<span class="literal">False</span>))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * <span class="number">2</span>])</span><br><span class="line">        h1 = conv_cond_concat(h1, yb)</span><br><span class="line"></span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(</span><br><span class="line">            deconv2d(h1, [self.batch_size, s_h2, s_w2, self.gf_dim * <span class="number">2</span>], name=<span class="string">'g_h2'</span>), train=<span class="literal">False</span>))</span><br><span class="line">        h2 = conv_cond_concat(h2, yb)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h3'</span>))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">load_mnist</span><span class="params">(self)</span>:</span></span><br><span class="line">    data_dir = os.path.join(<span class="string">"./data"</span>, self.dataset_name)</span><br><span class="line">    </span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'train-images-idx3-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    trX = loaded[<span class="number">16</span>:].reshape((<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'train-labels-idx1-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    trY = loaded[<span class="number">8</span>:].reshape((<span class="number">60000</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'t10k-images-idx3-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    teX = loaded[<span class="number">16</span>:].reshape((<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'t10k-labels-idx1-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    teY = loaded[<span class="number">8</span>:].reshape((<span class="number">10000</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    trY = np.asarray(trY)</span><br><span class="line">    teY = np.asarray(teY)</span><br><span class="line">    </span><br><span class="line">    X = np.concatenate((trX, teX), axis=<span class="number">0</span>)</span><br><span class="line">    y = np.concatenate((trY, teY), axis=<span class="number">0</span>).astype(np.int)</span><br><span class="line">    </span><br><span class="line">    seed = <span class="number">547</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    np.random.shuffle(X)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line">    </span><br><span class="line">    y_vec = np.zeros((len(y), self.y_dim), dtype=np.float)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(y):</span><br><span class="line">      y_vec[i,y[i]] = <span class="number">1.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X/<span class="number">255.</span>,y_vec</span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">model_dir</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"&#123;&#125;_&#123;&#125;_&#123;&#125;_&#123;&#125;"</span>.format(</span><br><span class="line">        self.dataset_name, self.batch_size,</span><br><span class="line">        self.output_height, self.output_width)</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, checkpoint_dir, step)</span>:</span></span><br><span class="line">    model_name = <span class="string">"DCGAN.model"</span></span><br><span class="line">    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(checkpoint_dir):</span><br><span class="line">      os.makedirs(checkpoint_dir)</span><br><span class="line"></span><br><span class="line">    self.saver.save(self.sess,</span><br><span class="line">            os.path.join(checkpoint_dir, model_name),</span><br><span class="line">            global_step=step)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(self, checkpoint_dir)</span>:</span></span><br><span class="line">    print(<span class="string">" [*] Reading checkpoints..."</span>)</span><br><span class="line">    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)</span><br><span class="line"></span><br><span class="line">    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">      ckpt_name = os.path.basename(ckpt.model_checkpoint_path)</span><br><span class="line">      self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))</span><br><span class="line">      print(<span class="string">" [*] Success to read &#123;&#125;"</span>.format(ckpt_name))</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      print(<span class="string">" [*] Failed to find a checkpoint"</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/11/17/python-learn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/11/17/python-learn/" class="post-title-link" itemprop="url">python_learn</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-11-17 17:39:08" itemprop="dateCreated datePublished" datetime="2019-11-17T17:39:08+08:00">2019-11-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-11-18 13:00:43" itemprop="dateModified" datetime="2019-11-18T13:00:43+08:00">2019-11-18</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/" itemprop="url" rel="index"><span itemprop="name">programs</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/python/dijkstra/" itemprop="url" rel="index"><span itemprop="name">dijkstra</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="查找图中两个节点的最小的距离"><a href="#查找图中两个节点的最小的距离" class="headerlink" title="查找图中两个节点的最小的距离"></a>查找图中两个节点的最小的距离</h2><p>这里面使用了python的优先队列，这里的队列按照后面的数值大小进行排序，而不是像普通的队列一样先进先出。后面的数值，是节点到出发节点的距离长度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 11:50</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : find_min_bfs.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span>  heapq</span><br><span class="line"><span class="keyword">import</span>  math</span><br><span class="line"><span class="comment"># pqueue = []</span></span><br><span class="line"><span class="comment"># heapq.heappush(pqueue,(1,"A"))</span></span><br><span class="line"><span class="comment"># heapq.heappush(pqueue,(7,"B"))</span></span><br><span class="line"><span class="comment"># heapq.heappush(pqueue,(3,"C"))</span></span><br><span class="line"><span class="comment"># heapq.heappush(pqueue,(6,"D"))</span></span><br><span class="line"><span class="comment"># heapq.heappush(pqueue,(2,"E"))</span></span><br><span class="line"></span><br><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">"A"</span>:&#123;<span class="string">"B"</span>: <span class="number">5</span>, <span class="string">"C"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">    <span class="string">"B"</span>:&#123;<span class="string">"A"</span>: <span class="number">5</span>,<span class="string">"C"</span>: <span class="number">2</span>,<span class="string">"D"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">    <span class="string">"C"</span>:&#123;<span class="string">"A"</span>: <span class="number">1</span>,<span class="string">"B"</span>: <span class="number">2</span>,<span class="string">"D"</span>: <span class="number">4</span>,<span class="string">"E"</span>: <span class="number">8</span>&#125;,</span><br><span class="line">    <span class="string">"D"</span>:&#123;<span class="string">"B"</span>: <span class="number">1</span>,<span class="string">"C"</span>: <span class="number">4</span>,<span class="string">"E"</span>: <span class="number">3</span>,<span class="string">"F"</span>: <span class="number">6</span>&#125;,</span><br><span class="line">    <span class="string">"E"</span>:&#123;<span class="string">"C"</span>: <span class="number">8</span>,<span class="string">"D"</span>: <span class="number">3</span>&#125;,</span><br><span class="line">    <span class="string">"F"</span>:&#123;<span class="string">"D"</span>: <span class="number">6</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_distance</span><span class="params">(graph,s)</span>:</span></span><br><span class="line">    distance = &#123;s:<span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> vertex <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> vertex != s:</span><br><span class="line">            distance[vertex] = math.inf</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dijkstra</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    pqueue = []</span><br><span class="line">    heapq.heappush(pqueue,(<span class="number">0</span>,s))</span><br><span class="line">    seen =set()</span><br><span class="line">    parent =&#123;s:<span class="literal">None</span>&#125;</span><br><span class="line">    distance = init_distance(graph,s)</span><br><span class="line">    <span class="keyword">while</span>(len(pqueue)&gt;<span class="number">0</span>):</span><br><span class="line">        pair = heapq.heappop(pqueue) <span class="comment"># 拿到一对点，pair</span></span><br><span class="line">        dist = pair[<span class="number">0</span>]</span><br><span class="line">        vertex = pair[<span class="number">1</span>]</span><br><span class="line">        seen.add(vertex)</span><br><span class="line"></span><br><span class="line">        nodes = graph[vertex].keys()</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                <span class="keyword">if</span> dist+graph[vertex][w] &lt;distance[w]:</span><br><span class="line">                    heapq.heappush(pqueue,(dist+graph[vertex][w],w))</span><br><span class="line">                    parent[w] = vertex</span><br><span class="line">                    distance[w] = dist+graph[vertex][w]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parent,distance</span><br><span class="line"></span><br><span class="line">parent, distance  = dijkstra(graph,<span class="string">"A"</span>)</span><br><span class="line">print(parent)</span><br><span class="line">print(distance)</span><br></pre></td></tr></table></figure></p>
<h3 id="python-装饰器"><a href="#python-装饰器" class="headerlink" title="python 装饰器"></a>python 装饰器</h3><p>装饰器(Decorators)是 Python 的一个重要部分。简单地说：他们是修改其他函数的功能的函数。他们有助于让我们的代码更简短，也更Pythonic（Python范儿）。装饰器可以让你的代码更简洁。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 9:59</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : deco.py.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="keyword">import</span>  time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 装饰器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_time</span><span class="params">(func)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args)</span>:</span></span><br><span class="line">        t1 = time.time()</span><br><span class="line">        result = func(*args)</span><br><span class="line">        t2 = time.time()</span><br><span class="line">        print(<span class="string">"Total time: &#123;:.4&#125; s"</span>.format(t2-t1))</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出质数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_prime</span><span class="params">(num)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> num&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">elif</span> num==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, num):</span><br><span class="line">            <span class="keyword">if</span> num%i ==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@display_time</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prime_nums</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(<span class="number">2</span>,<span class="number">10000</span>):</span><br><span class="line">        <span class="keyword">if</span> is_prime(i):</span><br><span class="line">            print(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@display_time</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_prime_nums</span><span class="params">(maxnum)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, maxnum):</span><br><span class="line">        <span class="keyword">if</span> is_prime(i):</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line">count = count_prime_nums(<span class="number">5000</span>)</span><br><span class="line">print(count)</span><br><span class="line">~</span><br></pre></td></tr></table></figure></p>
<h3 id="用turtle-画图"><a href="#用turtle-画图" class="headerlink" title="用turtle 画图"></a>用turtle 画图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 13:27</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : draw.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="keyword">from</span> turtle <span class="keyword">import</span>  *</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="comment"># turtle 画图</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(90)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(90)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(90)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(90)</span></span><br><span class="line"><span class="comment"># exitonclick()# 不点击窗口的话就不会退出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 画等边三角形</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(120)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(120)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># left(120)</span></span><br><span class="line"><span class="comment"># exitonclick()# 不点击窗口的话就不会退出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画五角星</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># right(180-36)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># right(180-36)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># right(180-36)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># right(180-36)</span></span><br><span class="line"><span class="comment"># forward(100)</span></span><br><span class="line"><span class="comment"># right(180-36)</span></span><br><span class="line"><span class="comment"># for i in range(5):</span></span><br><span class="line"><span class="comment">#     forward(100)</span></span><br><span class="line"><span class="comment">#     right(180-36)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">angle = <span class="number">360</span>/<span class="number">8</span></span><br><span class="line">length = <span class="number">100</span></span><br><span class="line">speed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">if</span> i %<span class="number">2</span>==<span class="number">0</span>:</span><br><span class="line">        color(<span class="string">'yellow'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        color(<span class="string">'red'</span>)</span><br><span class="line">    begin_fill()</span><br><span class="line">    forward(<span class="number">100</span>)</span><br><span class="line">    left(angle)</span><br><span class="line">    forward(length)</span><br><span class="line">    left(<span class="number">180</span>-angle)</span><br><span class="line">    forward(length)</span><br><span class="line">    left(angle)</span><br><span class="line">    forward(length)</span><br><span class="line">    left(<span class="number">180</span>-angle)</span><br><span class="line">    end_fill()</span><br><span class="line">    left(angle)</span><br><span class="line">forward(length)</span><br><span class="line">left(<span class="number">180</span>-(<span class="number">180</span>-angle)/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">alpha = angle*<span class="number">3.1415926536</span> /<span class="number">180</span></span><br><span class="line">step = <span class="number">2</span>*length*math.sin(alpha/<span class="number">2</span>)</span><br><span class="line">color(<span class="string">'blue'</span>)</span><br><span class="line">begin_fill()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    forward(step)</span><br><span class="line">    left(angle)</span><br><span class="line">end_fill()</span><br><span class="line"></span><br><span class="line">exitonclick()<span class="comment"># 不点击窗口的话就不会退出</span></span><br></pre></td></tr></table></figure>
<p><img src="//caius-lu.github.io/2019/11/17/python-learn/h1.png" alt="h1"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 14:20</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : Lsystem2.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="keyword">from</span> turtle <span class="keyword">import</span>  *</span><br><span class="line">length = <span class="number">7</span></span><br><span class="line">angle = <span class="number">60</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_path</span><span class="params">(path)</span>:</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    list = []</span><br><span class="line">    <span class="keyword">while</span> i &lt;len(path):</span><br><span class="line">        <span class="keyword">if</span> path[i] == <span class="string">"F"</span>:</span><br><span class="line">            list.append(path[i:i+<span class="number">2</span>])</span><br><span class="line">            i = i+<span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            list.append(path[i])</span><br><span class="line">            i = i+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_rule</span><span class="params">(path, rules)</span>:</span></span><br><span class="line">    lst = split_path(path)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(lst)):</span><br><span class="line">        symbol = lst[i]</span><br><span class="line">        <span class="keyword">if</span> symbol <span class="keyword">in</span> rules:</span><br><span class="line">            lst[i] = rules[symbol]</span><br><span class="line">    path =<span class="string">""</span>.join(symbol <span class="keyword">for</span> symbol <span class="keyword">in</span> lst)</span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line">rules=&#123;</span><br><span class="line">    <span class="string">"Fl"</span>: <span class="string">"Fr+Fl+Fr"</span>,</span><br><span class="line">    <span class="string">"Fr"</span>:<span class="string">"Fl-Fr-Fl"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_patj</span><span class="params">(path)</span>:</span></span><br><span class="line">    lst = split_path(path)</span><br><span class="line">    <span class="keyword">for</span> symbol <span class="keyword">in</span> lst:</span><br><span class="line">        <span class="keyword">if</span> symbol ==<span class="string">"Fl"</span>  <span class="keyword">or</span> symbol==<span class="string">'Fr'</span>:</span><br><span class="line">            forward(length)</span><br><span class="line">        <span class="keyword">elif</span> symbol==<span class="string">"-"</span>:</span><br><span class="line">            left(angle)</span><br><span class="line">        <span class="keyword">elif</span> symbol==<span class="string">'+'</span>:</span><br><span class="line">            right(angle)</span><br><span class="line"></span><br><span class="line">speed(<span class="number">0</span>)</span><br><span class="line">path = <span class="string">'Fr'</span></span><br><span class="line"><span class="comment"># speed(0)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#lst = split_path(path)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    path = apply_rule(path,rules)</span><br><span class="line">print(path)</span><br><span class="line">draw_patj(path)</span><br><span class="line">exitonclick()</span><br><span class="line">~</span><br></pre></td></tr></table></figure></p>
<p><img src="//caius-lu.github.io/2019/11/17/python-learn/h2.png" alt="h2"></p>
<h3 id="python-类的构造"><a href="#python-类的构造" class="headerlink" title="python 类的构造"></a>python 类的构造</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 14:52</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : Bank.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BankAccount</span>:</span></span><br><span class="line">    <span class="comment"># Constructor 构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,accountNumber, accountName, balance)</span>:</span></span><br><span class="line">        self.accountNumber = accountNumber</span><br><span class="line">        self.accountName = accountName</span><br><span class="line">        self.balance = balance</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"(name: &#123;&#125;,  balance: &#123;&#125;)"</span>.format(self.accountName,self.balance)</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 14:56</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : main.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="keyword">from</span> Bank <span class="keyword">import</span> BankAccount</span><br><span class="line"></span><br><span class="line">b1 = BankAccount(<span class="string">"56789"</span>,<span class="string">"Tony"</span>, <span class="number">100.0</span>)</span><br><span class="line">print((b1))</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/11/17/DFS-BFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/11/17/DFS-BFS/" class="post-title-link" itemprop="url">DFS_BFS</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-11-17 16:48:21 / 修改时间：16:49:05" itemprop="dateCreated datePublished" datetime="2019-11-17T16:48:21+08:00">2019-11-17</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/" itemprop="url" rel="index"><span itemprop="name">programs</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/algorithm/" itemprop="url" rel="index"><span itemprop="name">algorithm</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/programs/algorithm/dp/" itemprop="url" rel="index"><span itemprop="name">dp</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2019/11/17 10:28</span></span><br><span class="line"><span class="comment"># @Author : caius</span></span><br><span class="line"><span class="comment"># @Site : </span></span><br><span class="line"><span class="comment"># @File : BFS.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"></span><br><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">"A"</span>:&#123;<span class="string">"B"</span>, <span class="string">"C"</span>&#125;,</span><br><span class="line">    <span class="string">"B"</span>:&#123;<span class="string">"A"</span>,<span class="string">"C"</span>,<span class="string">"D"</span>&#125;,</span><br><span class="line">    <span class="string">"C"</span>:&#123;<span class="string">"A"</span>,<span class="string">"B"</span>,<span class="string">"D"</span>,<span class="string">"E"</span>&#125;,</span><br><span class="line">    <span class="string">"D"</span>:&#123;<span class="string">"B"</span>,<span class="string">"C"</span>,<span class="string">"E"</span>,<span class="string">"F"</span>&#125;,</span><br><span class="line">    <span class="string">"E"</span>:&#123;<span class="string">"C"</span>,<span class="string">"D"</span>&#125;,</span><br><span class="line">    <span class="string">"F"</span>:&#123;<span class="string">"D"</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 字典的基本用法</span></span><br><span class="line"><span class="comment"># keys: A B C D E F</span></span><br><span class="line"><span class="comment"># graph["E"&#125; "c". "D"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BFS</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    <span class="comment"># 队列先进先出</span></span><br><span class="line">    queue=[]</span><br><span class="line">    queue.append(s)</span><br><span class="line">    seen = set()<span class="comment"># 代表这个东西是个set</span></span><br><span class="line">    seen.add(s)</span><br><span class="line">    parrent =&#123;&#125;</span><br><span class="line">    parrent=&#123;s:<span class="literal">None</span>&#125;</span><br><span class="line">    <span class="keyword">while</span>(len(queue)&gt;<span class="number">0</span>):</span><br><span class="line">        vertex = queue.pop(<span class="number">0</span>)</span><br><span class="line">        nodes = graph[vertex]</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                queue.append(w)</span><br><span class="line">                seen.add(w)</span><br><span class="line">                parrent[w] = vertex</span><br><span class="line">        print(vertex)</span><br><span class="line">    <span class="keyword">return</span> parrent</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFS</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    <span class="comment"># 队列先进先出</span></span><br><span class="line">    stack=[]</span><br><span class="line">    stack.append(s)</span><br><span class="line">    seen = set()<span class="comment"># 代表这个东西是个set</span></span><br><span class="line">    seen.add(s)</span><br><span class="line">    <span class="keyword">while</span>(len(stack)&gt;<span class="number">0</span>):</span><br><span class="line">        vertex = stack.pop()</span><br><span class="line">        nodes = graph[vertex]</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                stack.append(w)</span><br><span class="line">                seen.add(w)</span><br><span class="line">        print(vertex)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DFS(graph,<span class="string">"E"</span>)</span><br><span class="line">parrent = BFS(graph,<span class="string">'E'</span>)</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> parrent:</span><br><span class="line">    print(key,parrent[key])</span><br><span class="line">v = <span class="string">"B"</span></span><br><span class="line">count=<span class="number">-1</span></span><br><span class="line"><span class="keyword">while</span> v!= <span class="literal">None</span>:</span><br><span class="line">    print(v)</span><br><span class="line">    v = parrent[v]</span><br><span class="line">    count+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"count: &#123;&#125; 次"</span>.format(count))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/touxiang.jpg" alt="Chao Lu">
  
  <p class="site-author-name" itemprop="name">Chao Lu</p>
  <div class="site-description motion-element" itemprop="description">hello,every body!~</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">86</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/archives/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>



  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>











          
          
        </div>
      </div>

      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chao Lu</span>

  

  
</div>


  <div class="powered-by">
   由 caius creat
  </div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">
   eilot
  </div> 




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


















  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>














<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->








  

</body>
</html>
