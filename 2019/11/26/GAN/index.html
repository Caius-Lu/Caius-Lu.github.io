<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<script>
(function(){
    if(''){
        if (prompt('请输入文章密码') !== ''){
            alert('密码错误！');
            history.back();
        }
    }
})();
</script>











  <link rel="apple-touch-icon" sizes="180x180" href="/images/icon.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="对抗生成网络 GAN(Generative Adversarial Nets) Adversarial Nets Framework生成器与判别器状态相等 损失函数 \min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})">
<meta name="keywords" content="tensorflow,GAN">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN">
<meta property="og:url" content="https://caius-lu.github.io/2019/11/26/GAN/index.html">
<meta property="og:site_name" content="一只程序猿的小小博客">
<meta property="og:description" content="对抗生成网络 GAN(Generative Adversarial Nets) Adversarial Nets Framework生成器与判别器状态相等 损失函数 \min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/图片1.png">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/图片2.png">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/PycharmProjects/GAN/myplot.png">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/33.png">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/a22.png">
<meta property="og:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/aa1.png">
<meta property="og:updated_time" content="2019-11-26T14:37:13.587Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GAN">
<meta name="twitter:description" content="对抗生成网络 GAN(Generative Adversarial Nets) Adversarial Nets Framework生成器与判别器状态相等 损失函数 \min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})">
<meta name="twitter:image" content="https://caius-lu.github.io/2019/11/26/GAN/Users/caius/Desktop/图片1.png">



  <link rel="alternate" href="/atom.xml" title="一只程序猿的小小博客" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://caius-lu.github.io/2019/11/26/GAN/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>GAN | 一只程序猿的小小博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://github.com/Caius-Lu" class="github-corner" aria-label="View source on GitHub">
<svg width="80" height="80" viewbox="0 0 250 250" style="fill:#64CEAA; 
color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z">
</path>
<path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px)
{.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">一只程序猿的小小博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">努力热爱生活</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://caius-lu.github.io/2019/11/26/GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chao Lu">
      <meta itemprop="description" content="hello,every body!~">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一只程序猿的小小博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">GAN

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-11-26 22:30:15 / 修改时间：22:37:13" itemprop="dateCreated datePublished" datetime="2019-11-26T22:30:15+08:00">2019-11-26</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/tensorflow/python/GAN/" itemprop="url" rel="index"><span itemprop="name">GAN</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="对抗生成网络-GAN-Generative-Adversarial-Nets"><a href="#对抗生成网络-GAN-Generative-Adversarial-Nets" class="headerlink" title="对抗生成网络 GAN(Generative Adversarial Nets)"></a>对抗生成网络 GAN(Generative Adversarial Nets)</h3><p><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\Desktop\图片1.png" alt="图片1"></p>
<h3 id="Adversarial-Nets-Framework"><a href="#Adversarial-Nets-Framework" class="headerlink" title="Adversarial Nets Framework"></a><strong>Adversarial Nets Framework</strong><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\Desktop\图片2.png" alt="图片2"></h3><p>生成器与判别器状态相等</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><script type="math/tex; mode=display">
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]</script><p>它做的是去最大化 D的区分度，最小化G和real数据集的数据分布</p>
<p>判别模型：</p>
<script type="math/tex; mode=display">
\log \left(D_{1}(x)\right)+\log \left(1-D_{2}(G(z))\right)</script><p>D1 和 D2 相同的，是判别器，G是生成器</p>
<p>生成模型：</p>
<script type="math/tex; mode=display">
\log \left(D_{2}(G(z))\right)</script><p>先训练判别器，在训练生成器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author: Your name</span></span><br><span class="line"><span class="comment"># @Date:   2019-11-26 09:12:52</span></span><br><span class="line"><span class="comment"># @Last Modified by:   Your name</span></span><br><span class="line"><span class="comment"># @Last Modified time: 2019-11-26 09:12:52</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">sns.set(color_codes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">seed = <span class="number">42</span></span><br><span class="line">np.random.seed(seed)</span><br><span class="line">tf.set_random_seed(seed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataDistribution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.mu = <span class="number">4</span></span><br><span class="line">        self.sigma = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, N)</span>:</span></span><br><span class="line">        samples = np.random.normal(self.mu, self.sigma, N) <span class="comment"># 生成高斯分布的概率密度随机数 均值，标准差</span></span><br><span class="line">        samples.sort()</span><br><span class="line">        <span class="keyword">return</span> samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneratorDistribution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, range)</span>:</span></span><br><span class="line">        self.range = range</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, N)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.linspace(-self.range, self.range, N) + \</span><br><span class="line">            np.random.random(N) * <span class="number">0.01</span>  <span class="comment"># 生成随机数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对线性相乘进行初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span><span class="params">(input, output_dim, scope=None, stddev=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    norm = tf.random_normal_initializer(stddev=stddev)</span><br><span class="line">    const = tf.constant_initializer(<span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope <span class="keyword">or</span> <span class="string">'linear'</span>): <span class="comment"># 定义命名空间</span></span><br><span class="line">        w = tf.get_variable(<span class="string">'w'</span>, [input.get_shape()[<span class="number">1</span>], output_dim], initializer=norm)</span><br><span class="line">        b = tf.get_variable(<span class="string">'b'</span>, [output_dim], initializer=const)</span><br><span class="line">        <span class="keyword">return</span> tf.matmul(input, w) + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(input, h_dim)</span>:</span></span><br><span class="line">    <span class="comment"># 这个函数的作用是计算激活函数softplus，即log( exp( features ) + 1)</span></span><br><span class="line">    h0 = tf.nn.softplus(linear(input, h_dim, <span class="string">'g0'</span>))</span><br><span class="line">    h1 = linear(h0, <span class="number">1</span>, <span class="string">'g1'</span>)</span><br><span class="line">    <span class="keyword">return</span> h1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(input, h_dim)</span>:</span></span><br><span class="line">    h0 = tf.tanh(linear(input, h_dim * <span class="number">2</span>, <span class="string">'d0'</span>))</span><br><span class="line">    h1 = tf.tanh(linear(h0, h_dim * <span class="number">2</span>, <span class="string">'d1'</span>))</span><br><span class="line">    h2 = tf.tanh(linear(h1, h_dim * <span class="number">2</span>, scope=<span class="string">'d2'</span>))</span><br><span class="line"></span><br><span class="line">    h3 = tf.sigmoid(linear(h2, <span class="number">1</span>, scope=<span class="string">'d3'</span>))</span><br><span class="line">    <span class="keyword">return</span> h3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimizer</span><span class="params">(loss, var_list, initial_learning_rate)</span>:</span></span><br><span class="line">    decay = <span class="number">0.95</span></span><br><span class="line">    num_decay_steps = <span class="number">150</span></span><br><span class="line">    batch = tf.Variable(<span class="number">0</span>)</span><br><span class="line">    learning_rate = tf.train.exponential_decay(</span><br><span class="line">        initial_learning_rate,</span><br><span class="line">        batch,</span><br><span class="line">        num_decay_steps,</span><br><span class="line">        decay,</span><br><span class="line">        staircase=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(</span><br><span class="line">        loss,</span><br><span class="line">        global_step=batch,</span><br><span class="line">        var_list=var_list</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GAN</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, gen, num_steps, batch_size, log_every)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.gen = gen</span><br><span class="line">        self.num_steps = num_steps</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.log_every = log_every</span><br><span class="line">        self.mlp_hidden_size = <span class="number">4</span></span><br><span class="line">        self.learning_rate = <span class="number">0.03</span></span><br><span class="line"></span><br><span class="line">        self._create_model()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_model</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'D_pre'</span>):</span><br><span class="line">            self.pre_input = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.pre_labels = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            D_pre = discriminator(self.pre_input, self.mlp_hidden_size)</span><br><span class="line">            self.pre_loss = tf.reduce_mean(tf.square(D_pre - self.pre_labels))</span><br><span class="line">            self.pre_opt = optimizer(self.pre_loss, <span class="literal">None</span>, self.learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># This defines the generator network - it takes samples from a noise</span></span><br><span class="line">        <span class="comment"># distribution as input, and passes them through an MLP.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Gen'</span>):</span><br><span class="line">            self.z = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.G = generator(self.z, self.mlp_hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The discriminator tries to tell the difference between samples from the</span></span><br><span class="line">        <span class="comment"># true data distribution (self.x) and the generated samples (self.z).</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># Here we create two copies of the discriminator network (that share parameters),</span></span><br><span class="line">        <span class="comment"># as you cannot use the same network with different inputs in TensorFlow.</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">'Disc'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">            self.x = tf.placeholder(tf.float32, shape=(self.batch_size, <span class="number">1</span>))</span><br><span class="line">            self.D1 = discriminator(self.x, self.mlp_hidden_size)</span><br><span class="line">            scope.reuse_variables()</span><br><span class="line">            self.D2 = discriminator(self.G, self.mlp_hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Define the loss for discriminator and generator networks (see the original</span></span><br><span class="line">        <span class="comment"># paper for details), and create optimizers for both</span></span><br><span class="line">        self.loss_d = tf.reduce_mean(-tf.log(self.D1) - tf.log(<span class="number">1</span> - self.D2))</span><br><span class="line">        self.loss_g = tf.reduce_mean(-tf.log(self.D2))</span><br><span class="line"></span><br><span class="line">        self.d_pre_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'D_pre'</span>)</span><br><span class="line">        self.d_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'Disc'</span>)</span><br><span class="line">        self.g_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=<span class="string">'Gen'</span>)</span><br><span class="line"></span><br><span class="line">        self.opt_d = optimizer(self.loss_d, self.d_params, self.learning_rate)</span><br><span class="line">        self.opt_g = optimizer(self.loss_g, self.g_params, self.learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">            tf.global_variables_initializer().run()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># pretraining discriminator</span></span><br><span class="line">            num_pretrain_steps = <span class="number">1000</span></span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(num_pretrain_steps):</span><br><span class="line">                d = (np.random.random(self.batch_size) - <span class="number">0.5</span>) * <span class="number">10.0</span></span><br><span class="line">                labels = norm.pdf(d, loc=self.data.mu, scale=self.data.sigma) <span class="comment"># norm.pdf:正态概率密度函数</span></span><br><span class="line">                pretrain_loss, _ = session.run([self.pre_loss, self.pre_opt], &#123;</span><br><span class="line">                    self.pre_input: np.reshape(d, (self.batch_size, <span class="number">1</span>)),</span><br><span class="line">                    self.pre_labels: np.reshape(labels, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line">            self.weightsD = session.run(self.d_pre_params)</span><br><span class="line">            <span class="comment"># copy weights from pre-training over to new D network</span></span><br><span class="line">            <span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(self.d_params):</span><br><span class="line">                session.run(v.assign(self.weightsD[i]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(self.num_steps):</span><br><span class="line">                <span class="comment"># update discriminator</span></span><br><span class="line">                x = self.data.sample(self.batch_size)</span><br><span class="line">                z = self.gen.sample(self.batch_size)</span><br><span class="line">                loss_d, _ = session.run([self.loss_d, self.opt_d], &#123;</span><br><span class="line">                    self.x: np.reshape(x, (self.batch_size, <span class="number">1</span>)),</span><br><span class="line">                    self.z: np.reshape(z, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># update generator</span></span><br><span class="line">                z = self.gen.sample(self.batch_size)</span><br><span class="line">                loss_g, _ = session.run([self.loss_g, self.opt_g], &#123;</span><br><span class="line">                    self.z: np.reshape(z, (self.batch_size, <span class="number">1</span>))</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> step % self.log_every == <span class="number">0</span>:</span><br><span class="line">                    print(<span class="string">'&#123;&#125;: &#123;&#125;\t&#123;&#125;'</span>.format(step, loss_d, loss_g))</span><br><span class="line">                <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span> <span class="keyword">or</span> step==<span class="number">0</span> <span class="keyword">or</span> step == self.num_steps <span class="number">-1</span> :</span><br><span class="line">                    self._plot_distributions(session)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_samples</span><span class="params">(self, session, num_points=<span class="number">10000</span>, num_bins=<span class="number">100</span>)</span>:</span></span><br><span class="line">        xs = np.linspace(-self.gen.range, self.gen.range, num_points)</span><br><span class="line">        bins = np.linspace(-self.gen.range, self.gen.range, num_bins)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># data distribution</span></span><br><span class="line">        d = self.data.sample(num_points)</span><br><span class="line">        pd, _ = np.histogram(d, bins=bins, density=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># generated samples</span></span><br><span class="line">        zs = np.linspace(-self.gen.range, self.gen.range, num_points)</span><br><span class="line">        g = np.zeros((num_points, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_points // self.batch_size):</span><br><span class="line">            g[self.batch_size * i:self.batch_size * (i + <span class="number">1</span>)] = session.run(self.G, &#123;</span><br><span class="line">                self.z: np.reshape(</span><br><span class="line">                    zs[self.batch_size * i:self.batch_size * (i + <span class="number">1</span>)],</span><br><span class="line">                    (self.batch_size, <span class="number">1</span>)</span><br><span class="line">                )</span><br><span class="line">            &#125;)</span><br><span class="line">        pg, _ = np.histogram(g, bins=bins, density=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pd, pg</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_plot_distributions</span><span class="params">(self, session)</span>:</span></span><br><span class="line">        pd, pg = self._samples(session)</span><br><span class="line">        p_x = np.linspace(-self.gen.range, self.gen.range, len(pd))</span><br><span class="line">        f, ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">        ax.set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        plt.plot(p_x, pd, label=<span class="string">'real data'</span>)</span><br><span class="line">        plt.plot(p_x, pg, label=<span class="string">'generated data'</span>)</span><br><span class="line">        plt.title(<span class="string">'1D Generative Adversarial Network'</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'Data values'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'Probability density'</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(args)</span>:</span></span><br><span class="line">    model = GAN(</span><br><span class="line">        DataDistribution(),</span><br><span class="line">        GeneratorDistribution(range=<span class="number">8</span>),</span><br><span class="line">        args.num_steps,</span><br><span class="line">        args.batch_size,</span><br><span class="line">        args.log_every,</span><br><span class="line">    )</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">'--num-steps'</span>, type=int, default=<span class="number">12000</span>,</span><br><span class="line">                        help=<span class="string">'the number of training steps to take'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--batch-size'</span>, type=int, default=<span class="number">12</span>,</span><br><span class="line">                        help=<span class="string">'the batch size'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--log-every'</span>, type=int, default=<span class="number">10</span>,</span><br><span class="line">                        help=<span class="string">'print loss after this many steps'</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(parse_args())</span><br></pre></td></tr></table></figure>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\PycharmProjects\GAN\myplot.png" alt="myplot"></p>
<h4 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h4><ol>
<li><p>将pooling层convolutions替代  </p>
<ul>
<li><p>对于判别模型：容许网络学习自己的空间下采样</p>
</li>
<li><p>对于生成模型：容许它学习自己的空间上采样  </p>
</li>
</ul>
</li>
<li><p>在generator和discriminator上都使用batchnorm  </p>
<ul>
<li>解决初始化差的问题</li>
<li>帮助梯度传播到每一层</li>
<li>防止generator把所有的样本都收敛到同一个点。</li>
</ul>
</li>
<li><p>在CNN中移除全连接层</p>
</li>
<li><p>在generator的除了输出层外的所有层使用ReLU，输出层采用tanh。</p>
</li>
<li><p>在discriminator的所有层上使用LeakyReLU  </p>
</li>
</ol>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\Desktop\33.png" alt="33"></p>
<p>100维的向量转为为特征图相似的东西， 再将这个向量reshape 。使用反卷积操作。</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\Desktop\a22.png" alt="a22"></p>
<p>输入图片，得到一个值是0或者1，这个是判别网络</p>
<p><img src="//caius-lu.github.io/2019/11/26/GAN/Users\caius\Desktop\aa1.png" alt="aa1"></p>
<p>这个是生成网络。<br>model.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ops <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_out_size_same</span><span class="params">(size, stride)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> math.ceil(float(size) / float(stride))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DCGAN</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sess, input_height=<span class="number">108</span>, input_width=<span class="number">108</span>, is_crop=True,</span></span></span><br><span class="line"><span class="function"><span class="params">         batch_size=<span class="number">64</span>, sample_num = <span class="number">64</span>, output_height=<span class="number">64</span>, output_width=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         y_dim=None, z_dim=<span class="number">100</span>, gf_dim=<span class="number">64</span>, df_dim=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         gfc_dim=<span class="number">1024</span>, dfc_dim=<span class="number">1024</span>, c_dim=<span class="number">3</span>, dataset_name=<span class="string">'default'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         input_fname_pattern=<span class="string">'*.jpg'</span>, checkpoint_dir=None, sample_dir=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    # sample number  测试噪音的输出，y代表label</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      sess: TensorFlow session</span></span><br><span class="line"><span class="string">      batch_size: The size of batch. Should be specified before training.</span></span><br><span class="line"><span class="string">      y_dim: (optional) Dimension of dim for y. [None]</span></span><br><span class="line"><span class="string">      z_dim: (optional) Dimension of dim for Z. [100]</span></span><br><span class="line"><span class="string">      gf_dim: (optional) Dimension of gen filters in first conv layer. [64]</span></span><br><span class="line"><span class="string">      df_dim: (optional) Dimension of discrim filters in first conv layer. [64]</span></span><br><span class="line"><span class="string">      gfc_dim: (optional) Dimension of gen units for for fully connected layer. [1024]</span></span><br><span class="line"><span class="string">      dfc_dim: (optional) Dimension of discrim units for fully connected layer. [1024]</span></span><br><span class="line"><span class="string">      c_dim: (optional) Dimension of image color. For grayscale input, set to 1. [3]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self.sess = sess</span><br><span class="line">    self.is_crop = is_crop</span><br><span class="line">    self.is_grayscale = (c_dim == <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    self.batch_size = batch_size</span><br><span class="line">    self.sample_num = sample_num</span><br><span class="line"></span><br><span class="line">    self.input_height = input_height</span><br><span class="line">    self.input_width = input_width</span><br><span class="line">    self.output_height = output_height</span><br><span class="line">    self.output_width = output_width</span><br><span class="line"></span><br><span class="line">    self.y_dim = y_dim <span class="comment"># null</span></span><br><span class="line">    self.z_dim = z_dim <span class="comment"># 噪音点的维度 100</span></span><br><span class="line"></span><br><span class="line">    self.gf_dim = gf_dim <span class="comment"># 最终多少个filter的个数 基数</span></span><br><span class="line">    self.df_dim = df_dim <span class="comment"># 64</span></span><br><span class="line"></span><br><span class="line">    self.gfc_dim = gfc_dim<span class="comment"># 生成和判别的全连接 1024</span></span><br><span class="line">    self.dfc_dim = dfc_dim <span class="comment"># 1024</span></span><br><span class="line"></span><br><span class="line">    self.c_dim = c_dim<span class="comment"># 生成的是彩色图 3</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># batch normalization : deals with poor initialization helps gradient flow</span></span><br><span class="line">    self.d_bn1 = batch_norm(name=<span class="string">'d_bn1'</span>)<span class="comment"># bacth在relu之前卷积之后</span></span><br><span class="line">    self.d_bn2 = batch_norm(name=<span class="string">'d_bn2'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">      self.d_bn3 = batch_norm(name=<span class="string">'d_bn3'</span>)</span><br><span class="line"></span><br><span class="line">    self.g_bn0 = batch_norm(name=<span class="string">'g_bn0'</span>)</span><br><span class="line">    self.g_bn1 = batch_norm(name=<span class="string">'g_bn1'</span>)</span><br><span class="line">    self.g_bn2 = batch_norm(name=<span class="string">'g_bn2'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">      self.g_bn3 = batch_norm(name=<span class="string">'g_bn3'</span>)</span><br><span class="line"></span><br><span class="line">    self.dataset_name = dataset_name</span><br><span class="line">    self.input_fname_pattern = input_fname_pattern</span><br><span class="line">    self.checkpoint_dir = checkpoint_dir</span><br><span class="line">    self.build_model()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self.y_dim:</span><br><span class="line">      self.y= tf.placeholder(tf.float32, [self.batch_size, self.y_dim], name=<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.is_crop:</span><br><span class="line">      image_dims = [self.output_height, self.output_width, self.c_dim]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      image_dims = [self.input_height, self.input_height, self.c_dim]</span><br><span class="line"></span><br><span class="line">    self.inputs = tf.placeholder(</span><br><span class="line">      tf.float32, [self.batch_size] + image_dims, name=<span class="string">'real_images'</span>)</span><br><span class="line">    self.sample_inputs = tf.placeholder(  <span class="comment"># 64 108 108 3，iamge_dim 108 108 3</span></span><br><span class="line">      tf.float32, [self.sample_num] + image_dims, name=<span class="string">'sample_inputs'</span>)</span><br><span class="line"></span><br><span class="line">    inputs = self.inputs  <span class="comment"># 64 108 108 3</span></span><br><span class="line">    sample_inputs = self.sample_inputs</span><br><span class="line"></span><br><span class="line">    self.z = tf.placeholder(</span><br><span class="line">      tf.float32, [<span class="literal">None</span>, self.z_dim], name=<span class="string">'z'</span>)  <span class="comment">## 生成网络组最开始的输入，float32  # B， 100</span></span><br><span class="line">    self.z_sum = histogram_summary(<span class="string">"z"</span>, self.z)  <span class="comment"># 在训练神经网络时，当需要查看一个张量在训练过程中值的分布情况时，可通过tf.summary.histogram()将其分布情况以直方图的形式在TensorBoard直方图仪表板上显示．</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.y_dim:</span><br><span class="line">      self.G = self.generator(self.z, self.y)</span><br><span class="line">      self.D, self.D_logits = \</span><br><span class="line">          self.discriminator(inputs, self.y, reuse=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">      self.sampler = self.sampler(self.z, self.y)</span><br><span class="line">      self.D_, self.D_logits_ = \</span><br><span class="line">          self.discriminator(self.G, self.y, reuse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.G = self.generator(self.z)  <span class="comment"># 64 64 64 3</span></span><br><span class="line">      self.D, self.D_logits = self.discriminator(inputs)  <span class="comment"># 64 108 108 3</span></span><br><span class="line"></span><br><span class="line">      self.sampler = self.sampler(self.z)</span><br><span class="line">      self.D_, self.D_logits_ = self.discriminator(self.G, reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    self.d_sum = histogram_summary(<span class="string">"d"</span>, self.D)</span><br><span class="line">    self.d__sum = histogram_summary(<span class="string">"d_"</span>, self.D_)</span><br><span class="line">    self.G_sum = image_summary(<span class="string">"G"</span>, self.G)</span><br><span class="line">    <span class="comment"># tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D_logits,l)</span></span><br><span class="line">    self.d_loss_real = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits, labels=tf.ones_like(self.D))) </span><br><span class="line">    self.d_loss_fake = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits_, labels=tf.zeros_like(self.D_)))</span><br><span class="line">    self.g_loss = tf.reduce_mean(</span><br><span class="line">      tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">        logits=self.D_logits_, labels=tf.ones_like(self.D_)))</span><br><span class="line"></span><br><span class="line">    self.d_loss_real_sum = scalar_summary(<span class="string">"d_loss_real"</span>, self.d_loss_real)</span><br><span class="line">    self.d_loss_fake_sum = scalar_summary(<span class="string">"d_loss_fake"</span>, self.d_loss_fake)</span><br><span class="line">                          </span><br><span class="line">    self.d_loss = self.d_loss_real + self.d_loss_fake</span><br><span class="line"></span><br><span class="line">    self.g_loss_sum = scalar_summary(<span class="string">"g_loss"</span>, self.g_loss)</span><br><span class="line">    self.d_loss_sum = scalar_summary(<span class="string">"d_loss"</span>, self.d_loss)</span><br><span class="line"></span><br><span class="line">    t_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    self.d_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'d_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line">    self.g_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> t_vars <span class="keyword">if</span> <span class="string">'g_'</span> <span class="keyword">in</span> var.name]</span><br><span class="line"></span><br><span class="line">    self.saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, config)</span>:</span></span><br><span class="line">    <span class="string">"""Train DCGAN"""</span></span><br><span class="line">    <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">      data_X, data_y = self.load_mnist()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      data = glob(os.path.join(<span class="string">"./data"</span>, config.dataset, self.input_fname_pattern))</span><br><span class="line">    <span class="comment">#np.random.shuffle(data)</span></span><br><span class="line"></span><br><span class="line">    d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">              .minimize(self.d_loss, var_list=self.d_vars)</span><br><span class="line">    g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \</span><br><span class="line">              .minimize(self.g_loss, var_list=self.g_vars)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      tf.global_variables_initializer().run()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">      tf.initialize_all_variables().run()</span><br><span class="line"></span><br><span class="line">    self.g_sum = merge_summary([self.z_sum, self.d__sum,</span><br><span class="line">      self.G_sum, self.d_loss_fake_sum, self.g_loss_sum])</span><br><span class="line">    self.d_sum = merge_summary(</span><br><span class="line">        [self.z_sum, self.d_sum, self.d_loss_real_sum, self.d_loss_sum])</span><br><span class="line">    self.writer = SummaryWriter(<span class="string">"./logs"</span>, self.sess.graph)</span><br><span class="line"></span><br><span class="line">    sample_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, size=(self.sample_num , self.z_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">      sample_inputs = data_X[<span class="number">0</span>:self.sample_num]</span><br><span class="line">      sample_labels = data_y[<span class="number">0</span>:self.sample_num]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      sample_files = data[<span class="number">0</span>:self.sample_num]</span><br><span class="line">      sample = [</span><br><span class="line">          get_image(sample_file,</span><br><span class="line">                    input_height=self.input_height,</span><br><span class="line">                    input_width=self.input_width,</span><br><span class="line">                    resize_height=self.output_height,</span><br><span class="line">                    resize_width=self.output_width,</span><br><span class="line">                    is_crop=self.is_crop,</span><br><span class="line">                    is_grayscale=self.is_grayscale) <span class="keyword">for</span> sample_file <span class="keyword">in</span> sample_files]</span><br><span class="line">      <span class="keyword">if</span> (self.is_grayscale):</span><br><span class="line">        sample_inputs = np.array(sample).astype(np.float32)[:, :, :, <span class="literal">None</span>]</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        sample_inputs = np.array(sample).astype(np.float32)</span><br><span class="line">  </span><br><span class="line">    counter = <span class="number">1</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.load(self.checkpoint_dir):</span><br><span class="line">      print(<span class="string">" [*] Load SUCCESS"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      print(<span class="string">" [!] Load failed..."</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(config.epoch):</span><br><span class="line">      <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">        batch_idxs = min(len(data_X), config.train_size) // config.batch_size</span><br><span class="line">      <span class="keyword">else</span>:      </span><br><span class="line">        data = glob(os.path.join(</span><br><span class="line">          <span class="string">"./data"</span>, config.dataset, self.input_fname_pattern))</span><br><span class="line">        batch_idxs = min(len(data), config.train_size) // config.batch_size</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(<span class="number">0</span>, batch_idxs):</span><br><span class="line">        <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">          batch_images = data_X[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">          batch_labels = data_y[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          batch_files = data[idx*config.batch_size:(idx+<span class="number">1</span>)*config.batch_size]</span><br><span class="line">          batch = [</span><br><span class="line">              get_image(batch_file,</span><br><span class="line">                        input_height=self.input_height,</span><br><span class="line">                        input_width=self.input_width,</span><br><span class="line">                        resize_height=self.output_height,</span><br><span class="line">                        resize_width=self.output_width,</span><br><span class="line">                        is_crop=self.is_crop,</span><br><span class="line">                        is_grayscale=self.is_grayscale) <span class="keyword">for</span> batch_file <span class="keyword">in</span> batch_files]</span><br><span class="line">          <span class="keyword">if</span> (self.is_grayscale):</span><br><span class="line">            batch_images = np.array(batch).astype(np.float32)[:, :, :, <span class="literal">None</span>]</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            batch_images = np.array(batch).astype(np.float32)</span><br><span class="line">        <span class="comment">#  一个均匀分布[low,high)中随机采样 从+1和-1之间随才采样</span></span><br><span class="line">        batch_z = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, [config.batch_size, self.z_dim]) \</span><br><span class="line">          .astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">          <span class="comment"># Update D network</span></span><br><span class="line">          _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; </span><br><span class="line">              self.inputs: batch_images,</span><br><span class="line">              self.z: batch_z,</span><br><span class="line">              self.y:batch_labels,</span><br><span class="line">            &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Update G network</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123;</span><br><span class="line">              self.z: batch_z, </span><br><span class="line">              self.y:batch_labels,</span><br><span class="line">            &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero (different from paper)</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z, self.y:batch_labels &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line">          </span><br><span class="line">          errD_fake = self.d_loss_fake.eval(&#123;</span><br><span class="line">              self.z: batch_z, </span><br><span class="line">              self.y:batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">          errD_real = self.d_loss_real.eval(&#123;</span><br><span class="line">              self.inputs: batch_images,</span><br><span class="line">              self.y:batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">          errG = self.g_loss.eval(&#123;</span><br><span class="line">              self.z: batch_z,</span><br><span class="line">              self.y: batch_labels</span><br><span class="line">          &#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="comment"># Update D network</span></span><br><span class="line">          _, summary_str = self.sess.run([d_optim, self.d_sum],</span><br><span class="line">            feed_dict=&#123; self.inputs: batch_images, self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Update G network</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># Run g_optim twice to make sure that d_loss does not go to zero (different from paper)</span></span><br><span class="line">          _, summary_str = self.sess.run([g_optim, self.g_sum],</span><br><span class="line">            feed_dict=&#123; self.z: batch_z &#125;)</span><br><span class="line">          self.writer.add_summary(summary_str, counter)</span><br><span class="line">          </span><br><span class="line">          errD_fake = self.d_loss_fake.eval(&#123; self.z: batch_z &#125;)</span><br><span class="line">          errD_real = self.d_loss_real.eval(&#123; self.inputs: batch_images &#125;)</span><br><span class="line">          errG = self.g_loss.eval(&#123;self.z: batch_z&#125;)</span><br><span class="line"></span><br><span class="line">        counter += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"</span> \</span><br><span class="line">          % (epoch, idx, batch_idxs,</span><br><span class="line">            time.time() - start_time, errD_fake+errD_real, errG))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> np.mod(counter, <span class="number">100</span>) == <span class="number">1</span>:</span><br><span class="line">          <span class="keyword">if</span> config.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">            samples, d_loss, g_loss = self.sess.run(</span><br><span class="line">              [self.sampler, self.d_loss, self.g_loss],</span><br><span class="line">              feed_dict=&#123;</span><br><span class="line">                  self.z: sample_z,</span><br><span class="line">                  self.inputs: sample_inputs,</span><br><span class="line">                  self.y:sample_labels,</span><br><span class="line">              &#125;</span><br><span class="line">            )</span><br><span class="line">            save_images(samples, [<span class="number">8</span>, <span class="number">8</span>],</span><br><span class="line">                  <span class="string">'./&#123;&#125;/train_&#123;:02d&#125;_&#123;:04d&#125;.png'</span>.format(config.sample_dir, epoch, idx))</span><br><span class="line">            print(<span class="string">"[Sample] d_loss: %.8f, g_loss: %.8f"</span> % (d_loss, g_loss)) </span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">              samples, d_loss, g_loss = self.sess.run(</span><br><span class="line">                [self.sampler, self.d_loss, self.g_loss],</span><br><span class="line">                feed_dict=&#123;</span><br><span class="line">                    self.z: sample_z,</span><br><span class="line">                    self.inputs: sample_inputs,</span><br><span class="line">                &#125;,</span><br><span class="line">              )</span><br><span class="line">              save_images(samples, [<span class="number">8</span>, <span class="number">8</span>],</span><br><span class="line">                    <span class="string">'./&#123;&#125;/train_&#123;:02d&#125;_&#123;:04d&#125;.png'</span>.format(config.sample_dir, epoch, idx))</span><br><span class="line">              print(<span class="string">"[Sample] d_loss: %.8f, g_loss: %.8f"</span> % (d_loss, g_loss)) </span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">              print(<span class="string">"one pic error!..."</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> counter//<span class="number">10</span> == <span class="number">2</span>:</span><br><span class="line">          self.save(config.checkpoint_dir, counter)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(self, image, y=None, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"discriminator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      <span class="keyword">if</span> reuse:</span><br><span class="line">        scope.reuse_variables()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        h0 = lrelu(conv2d(image, self.df_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*<span class="number">2</span>, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">        h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*<span class="number">4</span>, name=<span class="string">'d_h2_conv'</span>)))</span><br><span class="line">        h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*<span class="number">8</span>, name=<span class="string">'d_h3_conv'</span>))) <span class="comment"># 64 14 14 256 -&gt;64 7 7 512</span></span><br><span class="line">        aa = tf.reshape(h3, [self.batch_size, <span class="number">-1</span>])</span><br><span class="line">        h4 = linear(aa, <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h4), h4</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        x = conv_cond_concat(image, yb)</span><br><span class="line"></span><br><span class="line">        h0 = lrelu(conv2d(x, self.c_dim + self.y_dim, name=<span class="string">'d_h0_conv'</span>))</span><br><span class="line">        h0 = conv_cond_concat(h0, yb)</span><br><span class="line"></span><br><span class="line">        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim + self.y_dim, name=<span class="string">'d_h1_conv'</span>)))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, <span class="number">-1</span>])      </span><br><span class="line">        h1 = concat([h1, y], <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        h2 = lrelu(self.d_bn2(linear(h1, self.dfc_dim, <span class="string">'d_h2_lin'</span>)))</span><br><span class="line">        h2 = concat([h2, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h3 = linear(h2, <span class="number">1</span>, <span class="string">'d_h3_lin'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h3), h3</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self, z, y=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"generator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_w2 = conv_out_size_same(s_h, <span class="number">2</span>), conv_out_size_same(s_w, <span class="number">2</span>) <span class="comment"># 先把特征图大小确定出来</span></span><br><span class="line">        s_h4, s_w4 = conv_out_size_same(s_h2, <span class="number">2</span>), conv_out_size_same(s_w2, <span class="number">2</span>)</span><br><span class="line">        s_h8, s_w8 = conv_out_size_same(s_h4, <span class="number">2</span>), conv_out_size_same(s_w4, <span class="number">2</span>)</span><br><span class="line">        s_h16, s_w16 = conv_out_size_same(s_h8, <span class="number">2</span>), conv_out_size_same(s_w8, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project `z` and reshape</span></span><br><span class="line">        self.z_, self.h0_w, self.h0_b = linear(</span><br><span class="line">            z, self.gf_dim*<span class="number">8</span>*s_h16*s_w16, <span class="string">'g_h0_lin'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.h0 = tf.reshape(</span><br><span class="line">            self.z_, [<span class="number">-1</span>, s_h16, s_w16, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(self.h0))</span><br><span class="line"></span><br><span class="line">        self.h1, self.h1_w, self.h1_b = deconv2d(</span><br><span class="line">            h0, [self.batch_size, s_h8, s_w8, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(self.h1))</span><br><span class="line"></span><br><span class="line">        h2, self.h2_w, self.h2_b = deconv2d(</span><br><span class="line">            h1, [self.batch_size, s_h4, s_w4, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(h2))</span><br><span class="line"></span><br><span class="line">        h3, self.h3_w, self.h3_b = deconv2d(</span><br><span class="line">            h2, [self.batch_size, s_h2, s_w2, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line">        h3 = tf.nn.relu(self.g_bn3(h3))</span><br><span class="line"></span><br><span class="line">        h4, self.h4_w, self.h4_b = deconv2d(</span><br><span class="line">            h3, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h4'</span>, with_w=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_h4 = int(s_h/<span class="number">2</span>), int(s_h/<span class="number">4</span>)</span><br><span class="line">        s_w2, s_w4 = int(s_w/<span class="number">2</span>), int(s_w/<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yb = tf.expand_dims(tf.expand_dims(y, 1),2)</span></span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        z = concat([z, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h0 = tf.nn.relu(</span><br><span class="line">            self.g_bn0(linear(z, self.gfc_dim, <span class="string">'g_h0_lin'</span>)))</span><br><span class="line">        h0 = concat([h0, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(</span><br><span class="line">            linear(h0, self.gf_dim*<span class="number">2</span>*s_h4*s_w4, <span class="string">'g_h1_lin'</span>)))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        h1 = conv_cond_concat(h1, yb)</span><br><span class="line"></span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(deconv2d(h1,</span><br><span class="line">            [self.batch_size, s_h2, s_w2, self.gf_dim * <span class="number">2</span>], name=<span class="string">'g_h2'</span>)))</span><br><span class="line">        h2 = conv_cond_concat(h2, yb)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(</span><br><span class="line">            deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h3'</span>))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sampler</span><span class="params">(self, z, y=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"generator"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">      scope.reuse_variables()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> self.y_dim:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_w2 = conv_out_size_same(s_h, <span class="number">2</span>), conv_out_size_same(s_w, <span class="number">2</span>)</span><br><span class="line">        s_h4, s_w4 = conv_out_size_same(s_h2, <span class="number">2</span>), conv_out_size_same(s_w2, <span class="number">2</span>)</span><br><span class="line">        s_h8, s_w8 = conv_out_size_same(s_h4, <span class="number">2</span>), conv_out_size_same(s_w4, <span class="number">2</span>)</span><br><span class="line">        s_h16, s_w16 = conv_out_size_same(s_h8, <span class="number">2</span>), conv_out_size_same(s_w8, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># project `z` and reshape</span></span><br><span class="line">        h0 = tf.reshape(</span><br><span class="line">            linear(z, self.gf_dim*<span class="number">8</span>*s_h16*s_w16, <span class="string">'g_h0_lin'</span>),</span><br><span class="line">            [<span class="number">-1</span>, s_h16, s_w16, self.gf_dim * <span class="number">8</span>])</span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(h0, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h1 = deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_dim*<span class="number">4</span>], name=<span class="string">'g_h1'</span>)</span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(h1, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h2 = deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_dim*<span class="number">2</span>], name=<span class="string">'g_h2'</span>)</span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(h2, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h3 = deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_dim*<span class="number">1</span>], name=<span class="string">'g_h3'</span>)</span><br><span class="line">        h3 = tf.nn.relu(self.g_bn3(h3, train=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">        h4 = deconv2d(h3, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h4'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.tanh(h4)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        s_h, s_w = self.output_height, self.output_width</span><br><span class="line">        s_h2, s_h4 = int(s_h/<span class="number">2</span>), int(s_h/<span class="number">4</span>)</span><br><span class="line">        s_w2, s_w4 = int(s_w/<span class="number">2</span>), int(s_w/<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yb = tf.reshape(y, [-1, 1, 1, self.y_dim])</span></span><br><span class="line">        yb = tf.reshape(y, [self.batch_size, <span class="number">1</span>, <span class="number">1</span>, self.y_dim])</span><br><span class="line">        z = concat([z, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h0 = tf.nn.relu(self.g_bn0(linear(z, self.gfc_dim, <span class="string">'g_h0_lin'</span>)))</span><br><span class="line">        h0 = concat([h0, y], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h1 = tf.nn.relu(self.g_bn1(</span><br><span class="line">            linear(h0, self.gf_dim*<span class="number">2</span>*s_h4*s_w4, <span class="string">'g_h1_lin'</span>), train=<span class="literal">False</span>))</span><br><span class="line">        h1 = tf.reshape(h1, [self.batch_size, s_h4, s_w4, self.gf_dim * <span class="number">2</span>])</span><br><span class="line">        h1 = conv_cond_concat(h1, yb)</span><br><span class="line"></span><br><span class="line">        h2 = tf.nn.relu(self.g_bn2(</span><br><span class="line">            deconv2d(h1, [self.batch_size, s_h2, s_w2, self.gf_dim * <span class="number">2</span>], name=<span class="string">'g_h2'</span>), train=<span class="literal">False</span>))</span><br><span class="line">        h2 = conv_cond_concat(h2, yb)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(deconv2d(h2, [self.batch_size, s_h, s_w, self.c_dim], name=<span class="string">'g_h3'</span>))</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">load_mnist</span><span class="params">(self)</span>:</span></span><br><span class="line">    data_dir = os.path.join(<span class="string">"./data"</span>, self.dataset_name)</span><br><span class="line">    </span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'train-images-idx3-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    trX = loaded[<span class="number">16</span>:].reshape((<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'train-labels-idx1-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    trY = loaded[<span class="number">8</span>:].reshape((<span class="number">60000</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'t10k-images-idx3-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    teX = loaded[<span class="number">16</span>:].reshape((<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    fd = open(os.path.join(data_dir,<span class="string">'t10k-labels-idx1-ubyte'</span>))</span><br><span class="line">    loaded = np.fromfile(file=fd,dtype=np.uint8)</span><br><span class="line">    teY = loaded[<span class="number">8</span>:].reshape((<span class="number">10000</span>)).astype(np.float)</span><br><span class="line"></span><br><span class="line">    trY = np.asarray(trY)</span><br><span class="line">    teY = np.asarray(teY)</span><br><span class="line">    </span><br><span class="line">    X = np.concatenate((trX, teX), axis=<span class="number">0</span>)</span><br><span class="line">    y = np.concatenate((trY, teY), axis=<span class="number">0</span>).astype(np.int)</span><br><span class="line">    </span><br><span class="line">    seed = <span class="number">547</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    np.random.shuffle(X)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line">    </span><br><span class="line">    y_vec = np.zeros((len(y), self.y_dim), dtype=np.float)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(y):</span><br><span class="line">      y_vec[i,y[i]] = <span class="number">1.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X/<span class="number">255.</span>,y_vec</span><br><span class="line"></span><br><span class="line"><span class="meta">  @property</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">model_dir</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"&#123;&#125;_&#123;&#125;_&#123;&#125;_&#123;&#125;"</span>.format(</span><br><span class="line">        self.dataset_name, self.batch_size,</span><br><span class="line">        self.output_height, self.output_width)</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self, checkpoint_dir, step)</span>:</span></span><br><span class="line">    model_name = <span class="string">"DCGAN.model"</span></span><br><span class="line">    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(checkpoint_dir):</span><br><span class="line">      os.makedirs(checkpoint_dir)</span><br><span class="line"></span><br><span class="line">    self.saver.save(self.sess,</span><br><span class="line">            os.path.join(checkpoint_dir, model_name),</span><br><span class="line">            global_step=step)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(self, checkpoint_dir)</span>:</span></span><br><span class="line">    print(<span class="string">" [*] Reading checkpoints..."</span>)</span><br><span class="line">    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)</span><br><span class="line"></span><br><span class="line">    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">      ckpt_name = os.path.basename(ckpt.model_checkpoint_path)</span><br><span class="line">      self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))</span><br><span class="line">      print(<span class="string">" [*] Success to read &#123;&#125;"</span>.format(ckpt_name))</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      print(<span class="string">" [*] Failed to find a checkpoint"</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/tensorflow/" rel="tag"> <i class="fa fa-tag"></i>tensorflow</a>
          
            <a href="/tags/GAN/" rel="tag"> <i class="fa fa-tag"></i>GAN</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/17/python-learn/" rel="next" title="python_learn">
                <i class="fa fa-chevron-left"></i> python_learn
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NTU1Ni8yMjA2Nw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/touxiang.jpg" alt="Chao Lu">
  
  <p class="site-author-name" itemprop="name">Chao Lu</p>
  <div class="site-description motion-element" itemprop="description">hello,every body!~</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">79</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/archives/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>



  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>











          
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#对抗生成网络-GAN-Generative-Adversarial-Nets"><span class="nav-text">对抗生成网络 GAN(Generative Adversarial Nets)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adversarial-Nets-Framework"><span class="nav-text">Adversarial Nets Framework</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数"><span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DCGAN"><span class="nav-text">DCGAN</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chao Lu</span>

  

  
</div>


  <div class="powered-by">
   由 caius creat
  </div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">
   eilot
  </div> 




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  
  

  
  

  











  
    


<script>
  window.livereOptions = {
    refer: '2019/11/26/GAN/'
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>

  








  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>














<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->








  

</body>
</html>
